No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded
Number of samples in training set: 11603
Number of samples in test set: 2901

=== SAN ===
[I 2020-09-29 13:38:39,087] A new study created in memory with name: no-name-597bd4ce-419e-473b-90a9-d1a6dae4ccd6
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.83 Avg loss: 0.42 Avg F1: 0.88
validation Results - Epoch: 2  Avg accuracy: 0.83 Avg loss: 0.42 Avg F1: 0.88
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
[I 2020-09-29 13:56:39,101] Trial 0 finished with value: 0.9229166666666667 and parameters: {'block_num': 4, 'layer_size_hop': 5, 'kernel_size': 7}. Best is trial 0 with value: 0.9229166666666667.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.80 Avg loss: 0.46 Avg F1: 0.82
validation Results - Epoch: 1  Avg accuracy: 0.78 Avg loss: 0.47 Avg F1: 0.81
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
[I 2020-09-29 14:00:33,124] Trial 1 finished with value: 0.9329284393979403 and parameters: {'block_num': 1, 'layer_size_hop': 2, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.82 Avg loss: 0.41 Avg F1: 0.84
validation Results - Epoch: 1  Avg accuracy: 0.81 Avg loss: 0.42 Avg F1: 0.83
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
[I 2020-09-29 14:02:43,619] Trial 2 finished with value: 0.92214063636965 and parameters: {'block_num': 1, 'layer_size_hop': 2, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 2048, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
[I 2020-09-29 14:14:56,507] Trial 3 finished with value: 0.920405982905983 and parameters: {'block_num': 5, 'layer_size_hop': 2, 'kernel_size': 5}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 2048, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.33 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.33 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
[I 2020-09-29 14:39:21,103] Trial 4 finished with value: 0.9198001577701814 and parameters: {'block_num': 5, 'layer_size_hop': 3, 'kernel_size': 5}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.68 Avg loss: 0.53 Avg F1: 0.66
validation Results - Epoch: 1  Avg accuracy: 0.68 Avg loss: 0.53 Avg F1: 0.66
training Results - Epoch: 2  Avg accuracy: 0.78 Avg loss: 0.48 Avg F1: 0.80
validation Results - Epoch: 2  Avg accuracy: 0.76 Avg loss: 0.47 Avg F1: 0.78
training Results - Epoch: 3  Avg accuracy: 0.84 Avg loss: 0.32 Avg F1: 0.86
validation Results - Epoch: 3  Avg accuracy: 0.83 Avg loss: 0.33 Avg F1: 0.85
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.89
validation Results - Epoch: 5  Avg accuracy: 0.85 Avg loss: 0.31 Avg F1: 0.88
training Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.90
validation Results - Epoch: 6  Avg accuracy: 0.86 Avg loss: 0.30 Avg F1: 0.88
[I 2020-09-29 14:42:54,859] Trial 5 finished with value: 0.9209084836339344 and parameters: {'block_num': 2, 'layer_size_hop': 4, 'kernel_size': 3}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 12800, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 14:47:03,803] Trial 6 finished with value: 0.9138339920948617 and parameters: {'block_num': 3, 'layer_size_hop': 3, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 12800, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.36 Avg F1: 0.89
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.35 Avg F1: 0.89
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 13  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 13  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 14  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 14  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 15  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 15  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
[I 2020-09-29 15:07:35,141] Trial 7 finished with value: 0.922710428798306 and parameters: {'block_num': 3, 'layer_size_hop': 5, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 12800, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.34 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.34 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.85 Avg loss: 0.35 Avg F1: 0.90
validation Results - Epoch: 3  Avg accuracy: 0.86 Avg loss: 0.34 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
[I 2020-09-29 15:14:20,103] Trial 8 finished with value: 0.9199167966718669 and parameters: {'block_num': 3, 'layer_size_hop': 5, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
[I 2020-09-29 15:25:17,250] Trial 9 finished with value: 0.9176289453425712 and parameters: {'block_num': 4, 'layer_size_hop': 5, 'kernel_size': 7}. Best is trial 1 with value: 0.9329284393979403.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.37 Avg F1: 0.88
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.36 Avg F1: 0.88
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.33 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.33 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.90
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.22 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.33 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.92 Avg loss: 0.21 Avg F1: 0.94
validation Results - Epoch: 13  Avg accuracy: 0.89 Avg loss: 0.34 Avg F1: 0.92
training Results - Epoch: 14  Avg accuracy: 0.92 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.88 Avg loss: 0.35 Avg F1: 0.91
training Results - Epoch: 15  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 15  Avg accuracy: 0.89 Avg loss: 0.37 Avg F1: 0.91
training Results - Epoch: 16  Avg accuracy: 0.93 Avg loss: 0.17 Avg F1: 0.94
validation Results - Epoch: 16  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.91
training Results - Epoch: 17  Avg accuracy: 0.94 Avg loss: 0.15 Avg F1: 0.95
validation Results - Epoch: 17  Avg accuracy: 0.88 Avg loss: 0.39 Avg F1: 0.91
training Results - Epoch: 18  Avg accuracy: 0.93 Avg loss: 0.17 Avg F1: 0.95
validation Results - Epoch: 18  Avg accuracy: 0.88 Avg loss: 0.45 Avg F1: 0.91
training Results - Epoch: 19  Avg accuracy: 0.94 Avg loss: 0.16 Avg F1: 0.95
validation Results - Epoch: 19  Avg accuracy: 0.88 Avg loss: 0.39 Avg F1: 0.91
training Results - Epoch: 20  Avg accuracy: 0.95 Avg loss: 0.15 Avg F1: 0.96
validation Results - Epoch: 20  Avg accuracy: 0.88 Avg loss: 0.42 Avg F1: 0.91
training Results - Epoch: 21  Avg accuracy: 0.94 Avg loss: 0.15 Avg F1: 0.96
validation Results - Epoch: 21  Avg accuracy: 0.88 Avg loss: 0.50 Avg F1: 0.90
training Results - Epoch: 22  Avg accuracy: 0.95 Avg loss: 0.13 Avg F1: 0.96
validation Results - Epoch: 22  Avg accuracy: 0.88 Avg loss: 0.56 Avg F1: 0.91
training Results - Epoch: 23  Avg accuracy: 0.95 Avg loss: 0.14 Avg F1: 0.96
validation Results - Epoch: 23  Avg accuracy: 0.88 Avg loss: 0.44 Avg F1: 0.91
training Results - Epoch: 24  Avg accuracy: 0.95 Avg loss: 0.13 Avg F1: 0.96
validation Results - Epoch: 24  Avg accuracy: 0.88 Avg loss: 0.44 Avg F1: 0.91
[I 2020-09-29 15:32:31,238] Trial 10 finished with value: 0.9620218948506556 and parameters: {'block_num': 1, 'layer_size_hop': 2, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.82 Avg loss: 0.41 Avg F1: 0.85
validation Results - Epoch: 1  Avg accuracy: 0.82 Avg loss: 0.40 Avg F1: 0.84
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.92 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.94
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.33 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.92
validation Results - Epoch: 13  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.89
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.87 Avg loss: 0.37 Avg F1: 0.90
[I 2020-09-29 15:36:41,740] Trial 11 finished with value: 0.936409981218138 and parameters: {'block_num': 1, 'layer_size_hop': 2, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.41 Avg F1: 0.89
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.39 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.67 Avg loss: 0.82 Avg F1: 0.66
validation Results - Epoch: 2  Avg accuracy: 0.66 Avg loss: 0.84 Avg F1: 0.63
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.90
validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.89
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 12  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 14  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
[I 2020-09-29 15:40:51,186] Trial 12 finished with value: 0.939755838641189 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 5  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.89
[I 2020-09-29 15:43:37,482] Trial 13 finished with value: 0.9175250791085976 and parameters: {'block_num': 2, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.25 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
[I 2020-09-29 15:47:44,362] Trial 14 finished with value: 0.9201803235216124 and parameters: {'block_num': 2, 'layer_size_hop': 4, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.92
training Results - Epoch: 12  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.94
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.94
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.86 Avg loss: 0.36 Avg F1: 0.89
[I 2020-09-29 15:52:01,746] Trial 15 finished with value: 0.9365684112024597 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.84 Avg loss: 0.36 Avg F1: 0.86
validation Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.37 Avg F1: 0.85
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.90
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.90
validation Results - Epoch: 8  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.89
training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
[I 2020-09-29 15:57:24,295] Trial 16 finished with value: 0.9226471566345195 and parameters: {'block_num': 2, 'layer_size_hop': 4, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.41 Avg F1: 0.88
validation Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.40 Avg F1: 0.89
training Results - Epoch: 2  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
[I 2020-09-29 16:00:18,264] Trial 17 finished with value: 0.9228049499116088 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.82 Avg loss: 0.42 Avg F1: 0.84
validation Results - Epoch: 1  Avg accuracy: 0.81 Avg loss: 0.41 Avg F1: 0.83
training Results - Epoch: 2  Avg accuracy: 0.78 Avg loss: 0.44 Avg F1: 0.80
validation Results - Epoch: 2  Avg accuracy: 0.77 Avg loss: 0.43 Avg F1: 0.78
training Results - Epoch: 3  Avg accuracy: 0.86 Avg loss: 0.30 Avg F1: 0.88
validation Results - Epoch: 3  Avg accuracy: 0.84 Avg loss: 0.30 Avg F1: 0.87
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
[I 2020-09-29 16:05:39,143] Trial 18 finished with value: 0.9201295196977873 and parameters: {'block_num': 2, 'layer_size_hop': 2, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.89
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.29 Avg F1: 0.88
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.33 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.80 Avg loss: 0.55 Avg F1: 0.82
validation Results - Epoch: 3  Avg accuracy: 0.78 Avg loss: 0.59 Avg F1: 0.80
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.90
[I 2020-09-29 16:07:25,149] Trial 19 finished with value: 0.9181959162574308 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.33 Avg F1: 0.90
validation Results - Epoch: 3  Avg accuracy: 0.87 Avg loss: 0.34 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.25 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.90
validation Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.89
training Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 7  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.89
[I 2020-09-29 16:11:08,156] Trial 20 finished with value: 0.9184063310137809 and parameters: {'block_num': 2, 'layer_size_hop': 2, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.45 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.44 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.82 Avg loss: 0.41 Avg F1: 0.85
validation Results - Epoch: 2  Avg accuracy: 0.82 Avg loss: 0.40 Avg F1: 0.85
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 15  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 15  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.92
training Results - Epoch: 16  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 16  Avg accuracy: 0.88 Avg loss: 0.35 Avg F1: 0.91
training Results - Epoch: 17  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 17  Avg accuracy: 0.88 Avg loss: 0.36 Avg F1: 0.90
[I 2020-09-29 16:16:22,453] Trial 21 finished with value: 0.9344695468357775 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.43 Avg F1: 0.86
validation Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.43 Avg F1: 0.85
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.30 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.93
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
[I 2020-09-29 16:18:26,993] Trial 22 finished with value: 0.9256133464180569 and parameters: {'block_num': 1, 'layer_size_hop': 4, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.37 Avg F1: 0.87
validation Results - Epoch: 1  Avg accuracy: 0.84 Avg loss: 0.36 Avg F1: 0.86
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.89
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 10  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 12  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.36 Avg F1: 0.90
[I 2020-09-29 16:22:08,358] Trial 23 finished with value: 0.9367650023519923 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.46 Avg loss: 1.13 Avg F1: 0.26
validation Results - Epoch: 1  Avg accuracy: 0.47 Avg loss: 1.15 Avg F1: 0.27
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.89
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.90
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.90
[I 2020-09-29 16:27:06,708] Trial 24 finished with value: 0.9210420303477911 and parameters: {'block_num': 2, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.35 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.35 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.33 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.37 Avg F1: 0.90
validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.38 Avg F1: 0.89
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
[I 2020-09-29 16:28:39,153] Trial 25 finished with value: 0.9177248677248677 and parameters: {'block_num': 1, 'layer_size_hop': 4, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.50 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.50 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 16:30:31,813] Trial 26 finished with value: 0.9189224447198487 and parameters: {'block_num': 1, 'layer_size_hop': 2, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 25600, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.81 Avg loss: 0.48 Avg F1: 0.83
validation Results - Epoch: 1  Avg accuracy: 0.79 Avg loss: 0.47 Avg F1: 0.81
training Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.89
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 16:36:07,455] Trial 27 finished with value: 0.9249233579022894 and parameters: {'block_num': 2, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
[I 2020-09-29 16:49:42,555] Trial 28 finished with value: 0.9226269609146504 and parameters: {'block_num': 4, 'layer_size_hop': 2, 'kernel_size': 5}. Best is trial 10 with value: 0.9620218948506556.
spatial feature len: 51200, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.46 Avg F1: 0.89
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.44 Avg F1: 0.89
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.40 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.40 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 3  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 15  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 15  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 16  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 16  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.91
training Results - Epoch: 17  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 17  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 18  Avg accuracy: 0.92 Avg loss: 0.19 Avg F1: 0.94
validation Results - Epoch: 18  Avg accuracy: 0.89 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 19  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.94
validation Results - Epoch: 19  Avg accuracy: 0.88 Avg loss: 0.35 Avg F1: 0.91
training Results - Epoch: 20  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 20  Avg accuracy: 0.87 Avg loss: 0.39 Avg F1: 0.90
[I 2020-09-29 16:55:47,543] Trial 29 finished with value: 0.93971140541609 and parameters: {'block_num': 1, 'layer_size_hop': 3, 'kernel_size': 3}. Best is trial 10 with value: 0.9620218948506556.

=== LSTM ===
[I 2020-09-29 16:55:47,544] A new study created in memory with name: no-name-02b3599d-43dd-40af-af12-99e069b50939
spatial feature len: 6400, temporal feature len: 150
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.86 Avg loss: 0.35 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.86 Avg loss: 0.34 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
validation Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.90
[I 2020-09-29 16:56:47,441] Trial 0 finished with value: 0.9196499602227526 and parameters: {'t_hidden_dim': 150, 't_output_dim': 150}. Best is trial 0 with value: 0.9196499602227526.
spatial feature len: 6400, temporal feature len: 50
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
[I 2020-09-29 16:58:12,036] Trial 1 finished with value: 0.9233435541927743 and parameters: {'t_hidden_dim': 300, 't_output_dim': 50}. Best is trial 1 with value: 0.9233435541927743.
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
[I 2020-09-29 16:59:14,524] Trial 2 finished with value: 0.9216662300235787 and parameters: {'t_hidden_dim': 300, 't_output_dim': 300}. Best is trial 1 with value: 0.9233435541927743.
spatial feature len: 6400, temporal feature len: 450
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:00:06,527] Trial 3 finished with value: 0.918525261720528 and parameters: {'t_hidden_dim': 250, 't_output_dim': 450}. Best is trial 1 with value: 0.9233435541927743.
spatial feature len: 6400, temporal feature len: 150
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.33 Avg F1: 0.88
validation Results - Epoch: 1  Avg accuracy: 0.84 Avg loss: 0.33 Avg F1: 0.87
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:01:27,329] Trial 4 finished with value: 0.9233463559207867 and parameters: {'t_hidden_dim': 250, 't_output_dim': 150}. Best is trial 4 with value: 0.9233463559207867.
spatial feature len: 6400, temporal feature len: 500
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 9  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
[I 2020-09-29 17:02:58,562] Trial 5 finished with value: 0.9225261735900033 and parameters: {'t_hidden_dim': 150, 't_output_dim': 500}. Best is trial 4 with value: 0.9233463559207867.
spatial feature len: 6400, temporal feature len: 450
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.90
training Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 12  Avg accuracy: 0.85 Avg loss: 0.38 Avg F1: 0.88
[I 2020-09-29 17:04:56,688] Trial 6 finished with value: 0.9292682926829268 and parameters: {'t_hidden_dim': 100, 't_output_dim': 450}. Best is trial 6 with value: 0.9292682926829268.
spatial feature len: 6400, temporal feature len: 450
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
[I 2020-09-29 17:05:48,949] Trial 7 finished with value: 0.9181961195595177 and parameters: {'t_hidden_dim': 450, 't_output_dim': 450}. Best is trial 6 with value: 0.9292682926829268.
spatial feature len: 6400, temporal feature len: 200
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
[I 2020-09-29 17:06:22,299] Trial 8 finished with value: 0.9134487350199734 and parameters: {'t_hidden_dim': 350, 't_output_dim': 200}. Best is trial 6 with value: 0.9292682926829268.
spatial feature len: 6400, temporal feature len: 500
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 13  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
[I 2020-09-29 17:08:38,936] Trial 9 finished with value: 0.9339289285952397 and parameters: {'t_hidden_dim': 350, 't_output_dim': 500}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 350
training Results - Epoch: 1  Avg accuracy: 0.46 Avg loss: 1.35 Avg F1: 0.27
validation Results - Epoch: 1  Avg accuracy: 0.46 Avg loss: 1.33 Avg F1: 0.27
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.83 Avg loss: 0.51 Avg F1: 0.88
validation Results - Epoch: 4  Avg accuracy: 0.84 Avg loss: 0.51 Avg F1: 0.89
training Results - Epoch: 5  Avg accuracy: 0.86 Avg loss: 0.34 Avg F1: 0.90
validation Results - Epoch: 5  Avg accuracy: 0.86 Avg loss: 0.34 Avg F1: 0.90
[I 2020-09-29 17:09:30,405] Trial 10 finished with value: 0.9197215777262181 and parameters: {'t_hidden_dim': 500, 't_output_dim': 350}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 400
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
[I 2020-09-29 17:11:12,448] Trial 11 finished with value: 0.9256922770436283 and parameters: {'t_hidden_dim': 50, 't_output_dim': 400}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 500
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:12:27,703] Trial 12 finished with value: 0.9220546215695395 and parameters: {'t_hidden_dim': 400, 't_output_dim': 500}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 500
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:13:38,294] Trial 13 finished with value: 0.9261482254697286 and parameters: {'t_hidden_dim': 50, 't_output_dim': 500}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 400
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.90
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
[I 2020-09-29 17:14:27,951] Trial 14 finished with value: 0.9178317066737008 and parameters: {'t_hidden_dim': 150, 't_output_dim': 400}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
[I 2020-09-29 17:15:18,552] Trial 15 finished with value: 0.9141259122842915 and parameters: {'t_hidden_dim': 400, 't_output_dim': 300}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 400
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.89
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.30 Avg F1: 0.88
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.90
[I 2020-09-29 17:16:19,387] Trial 16 finished with value: 0.9195248003221692 and parameters: {'t_hidden_dim': 200, 't_output_dim': 400}. Best is trial 9 with value: 0.9339289285952397.
spatial feature len: 6400, temporal feature len: 450
training Results - Epoch: 1  Avg accuracy: 0.84 Avg loss: 0.35 Avg F1: 0.86
validation Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.36 Avg F1: 0.85
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.90
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.92 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.92 Avg loss: 0.20 Avg F1: 0.94
validation Results - Epoch: 14  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 15  Avg accuracy: 0.91 Avg loss: 0.21 Avg F1: 0.93
validation Results - Epoch: 15  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.89
training Results - Epoch: 16  Avg accuracy: 0.91 Avg loss: 0.20 Avg F1: 0.93
validation Results - Epoch: 16  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.89
[I 2020-09-29 17:18:55,978] Trial 17 finished with value: 0.9358565737051794 and parameters: {'t_hidden_dim': 100, 't_output_dim': 450}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 250
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 13  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 13  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 14  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 15  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 15  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92
training Results - Epoch: 16  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 16  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
training Results - Epoch: 17  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 17  Avg accuracy: 0.89 Avg loss: 0.32 Avg F1: 0.91
training Results - Epoch: 18  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 18  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.90
training Results - Epoch: 19  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 19  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.91
[I 2020-09-29 17:22:12,948] Trial 18 finished with value: 0.9343915343915344 and parameters: {'t_hidden_dim': 350, 't_output_dim': 250}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 250
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
[I 2020-09-29 17:23:46,673] Trial 19 finished with value: 0.9245583742860939 and parameters: {'t_hidden_dim': 500, 't_output_dim': 250}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 250
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.90
training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91
validation Results - Epoch: 6  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.90
[I 2020-09-29 17:24:50,501] Trial 20 finished with value: 0.9100851387831383 and parameters: {'t_hidden_dim': 200, 't_output_dim': 250}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 350
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.39 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.38 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:26:27,076] Trial 21 finished with value: 0.9267316161750968 and parameters: {'t_hidden_dim': 350, 't_output_dim': 350}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 150
training Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
[I 2020-09-29 17:27:40,115] Trial 22 finished with value: 0.9234906548339384 and parameters: {'t_hidden_dim': 350, 't_output_dim': 150}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 350
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.33 Avg F1: 0.88
validation Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.34 Avg F1: 0.87
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.87 Avg loss: 0.31 Avg F1: 0.89
validation Results - Epoch: 3  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.89
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
validation Results - Epoch: 4  Avg accuracy: 0.86 Avg loss: 0.30 Avg F1: 0.89
[I 2020-09-29 17:28:21,958] Trial 23 finished with value: 0.9186372223307928 and parameters: {'t_hidden_dim': 400, 't_output_dim': 350}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 50
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.92
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.90
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
[I 2020-09-29 17:29:44,289] Trial 24 finished with value: 0.9260823653643083 and parameters: {'t_hidden_dim': 450, 't_output_dim': 50}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 250
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
[I 2020-09-29 17:31:07,155] Trial 25 finished with value: 0.9239812429826301 and parameters: {'t_hidden_dim': 300, 't_output_dim': 250}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 200
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90
validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.32 Avg F1: 0.89
[I 2020-09-29 17:31:46,828] Trial 26 finished with value: 0.9157273215244229 and parameters: {'t_hidden_dim': 350, 't_output_dim': 200}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 200
training Results - Epoch: 1  Avg accuracy: 0.86 Avg loss: 0.32 Avg F1: 0.88
validation Results - Epoch: 1  Avg accuracy: 0.85 Avg loss: 0.33 Avg F1: 0.87
training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 8  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.92
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
[I 2020-09-29 17:33:33,425] Trial 27 finished with value: 0.9271612425038743 and parameters: {'t_hidden_dim': 450, 't_output_dim': 200}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 450
training Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91
validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 6  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93
validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 8  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 9  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91
training Results - Epoch: 10  Avg accuracy: 0.91 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 10  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.28 Avg F1: 0.91
training Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.22 Avg F1: 0.93
validation Results - Epoch: 12  Avg accuracy: 0.88 Avg loss: 0.29 Avg F1: 0.91
[I 2020-09-29 17:35:37,587] Trial 28 finished with value: 0.9321709266230763 and parameters: {'t_hidden_dim': 250, 't_output_dim': 450}. Best is trial 17 with value: 0.9358565737051794.
spatial feature len: 6400, temporal feature len: 300
training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.90
validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.29 Avg F1: 0.90
training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92
validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
training Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.26 Avg F1: 0.91
validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92
[I 2020-09-29 17:36:28,262] Trial 29 finished with value: 0.917507111455909 and parameters: {'t_hidden_dim': 200, 't_output_dim': 300}. Best is trial 17 with value: 0.9358565737051794.
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded
Number of samples in training set: 11603
Number of samples in test set: 2901
Training and test data loaded

======== ResNet ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.23Epoch[1] Iteration[100/363] Loss: 0.22Epoch[1] Iteration[150/363] Loss: 0.29Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.29Epoch[1] Iteration[300/363] Loss: 0.52Epoch[1] Iteration[350/363] Loss: 0.28Epoch[2] Iteration[50/363] Loss: 0.22Epoch[2] Iteration[100/363] Loss: 0.08Epoch[2] Iteration[150/363] Loss: 0.26Epoch[2] Iteration[200/363] Loss: 0.26Epoch[2] Iteration[250/363] Loss: 0.30Epoch[2] Iteration[300/363] Loss: 0.57Epoch[2] Iteration[350/363] Loss: 0.29Epoch[3] Iteration[50/363] Loss: 0.20Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.26Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.28Epoch[3] Iteration[300/363] Loss: 0.54Epoch[3] Iteration[350/363] Loss: 0.31Epoch[4] Iteration[50/363] Loss: 0.21Epoch[4] Iteration[100/363] Loss: 0.11Epoch[4] Iteration[150/363] Loss: 0.25Epoch[4] Iteration[200/363] Loss: 0.23Epoch[4] Iteration[250/363] Loss: 0.31Epoch[4] Iteration[300/363] Loss: 0.63Epoch[4] Iteration[350/363] Loss: 0.28Epoch[5] Iteration[50/363] Loss: 0.20Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.23Epoch[5] Iteration[250/363] Loss: 0.26Epoch[5] Iteration[300/363] Loss: 0.51Epoch[5] Iteration[350/363] Loss: 0.29Epoch[6] Iteration[50/363] Loss: 0.21Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.23Epoch[6] Iteration[300/363] Loss: 0.51Epoch[6] Iteration[350/363] Loss: 0.26Epoch[7] Iteration[50/363] Loss: 0.24Epoch[7] Iteration[100/363] Loss: 0.09Epoch[7] Iteration[150/363] Loss: 0.20Epoch[7] Iteration[200/363] Loss: 0.22Epoch[7] Iteration[250/363] Loss: 0.21Epoch[7] Iteration[300/363] Loss: 0.47Epoch[7] Iteration[350/363] Loss: 0.24Epoch[8] Iteration[50/363] Loss: 0.20Epoch[8] Iteration[100/363] Loss: 0.08Epoch[8] Iteration[150/363] Loss: 0.19Epoch[8] Iteration[200/363] Loss: 0.22Epoch[8] Iteration[250/363] Loss: 0.22Epoch[8] Iteration[300/363] Loss: 0.40Epoch[8] Iteration[350/363] Loss: 0.23Epoch[9] Iteration[50/363] Loss: 0.25Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.15Epoch[9] Iteration[200/363] Loss: 0.22Epoch[9] Iteration[250/363] Loss: 0.23Epoch[9] Iteration[300/363] Loss: 0.35Epoch[9] Iteration[350/363] Loss: 0.20Epoch[10] Iteration[50/363] Loss: 0.25Epoch[10] Iteration[100/363] Loss: 0.08Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.23Epoch[10] Iteration[250/363] Loss: 0.20Epoch[10] Iteration[300/363] Loss: 0.36Epoch[10] Iteration[350/363] Loss: 0.22Epoch[11] Iteration[50/363] Loss: 0.20Epoch[11] Iteration[100/363] Loss: 0.06Epoch[11] Iteration[150/363] Loss: 0.15Epoch[11] Iteration[200/363] Loss: 0.23Epoch[11] Iteration[250/363] Loss: 0.25Epoch[11] Iteration[300/363] Loss: 0.32Epoch[11] Iteration[350/363] Loss: 0.20Epoch[12] Iteration[50/363] Loss: 0.21Epoch[12] Iteration[100/363] Loss: 0.09Epoch[12] Iteration[150/363] Loss: 0.15Epoch[12] Iteration[200/363] Loss: 0.24Epoch[12] Iteration[250/363] Loss: 0.18Epoch[12] Iteration[300/363] Loss: 0.29Epoch[12] Iteration[350/363] Loss: 0.23Epoch[13] Iteration[50/363] Loss: 0.27Epoch[13] Iteration[100/363] Loss: 0.05Epoch[13] Iteration[150/363] Loss: 0.13Epoch[13] Iteration[200/363] Loss: 0.25Epoch[13] Iteration[250/363] Loss: 0.20Epoch[13] Iteration[300/363] Loss: 0.25Epoch[13] Iteration[350/363] Loss: 0.22Epoch[14] Iteration[50/363] Loss: 0.18Epoch[14] Iteration[100/363] Loss: 0.06Epoch[14] Iteration[150/363] Loss: 0.10Epoch[14] Iteration[200/363] Loss: 0.23Epoch[14] Iteration[250/363] Loss: 0.19Epoch[14] Iteration[300/363] Loss: 0.21Epoch[14] Iteration[350/363] Loss: 0.21Epoch[15] Iteration[50/363] Loss: 0.18Epoch[15] Iteration[100/363] Loss: 0.08Epoch[15] Iteration[150/363] Loss: 0.16Epoch[15] Iteration[200/363] Loss: 0.18Epoch[15] Iteration[250/363] Loss: 0.15Epoch[15] Iteration[300/363] Loss: 0.26Epoch[15] Iteration[350/363] Loss: 0.18Epoch[16] Iteration[50/363] Loss: 0.17Epoch[16] Iteration[100/363] Loss: 0.07Epoch[16] Iteration[150/363] Loss: 0.14Epoch[16] Iteration[200/363] Loss: 0.21Epoch[16] Iteration[250/363] Loss: 0.15Epoch[16] Iteration[300/363] Loss: 0.23Epoch[16] Iteration[350/363] Loss: 0.20Epoch[17] Iteration[50/363] Loss: 0.18Epoch[17] Iteration[100/363] Loss: 0.07Epoch[17] Iteration[150/363] Loss: 0.08Epoch[17] Iteration[200/363] Loss: 0.21Epoch[17] Iteration[250/363] Loss: 0.12Epoch[17] Iteration[300/363] Loss: 0.26Epoch[17] Iteration[350/363] Loss: 0.19Epoch[18] Iteration[50/363] Loss: 0.20Epoch[18] Iteration[100/363] Loss: 0.09Epoch[18] Iteration[150/363] Loss: 0.12Epoch[18] Iteration[200/363] Loss: 0.20Epoch[18] Iteration[250/363] Loss: 0.14Epoch[18] Iteration[300/363] Loss: 0.22Epoch[18] Iteration[350/363] Loss: 0.15
======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.40Epoch[1] Iteration[100/363] Loss: 0.10Epoch[1] Iteration[150/363] Loss: 0.36Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.33Epoch[1] Iteration[300/363] Loss: 0.32Epoch[1] Iteration[350/363] Loss: 0.28Epoch[2] Iteration[50/363] Loss: 0.32Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.21Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.30Epoch[2] Iteration[350/363] Loss: 0.23Epoch[3] Iteration[50/363] Loss: 0.21Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.22Epoch[3] Iteration[300/363] Loss: 0.25Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.16Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.18
======== resnet18 ========

spatial feature len: 4608, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.30Epoch[1] Iteration[100/363] Loss: 0.10Epoch[1] Iteration[150/363] Loss: 0.33Epoch[1] Iteration[200/363] Loss: 0.25Epoch[1] Iteration[250/363] Loss: 0.35Epoch[1] Iteration[300/363] Loss: 0.40Epoch[1] Iteration[350/363] Loss: 0.34Epoch[2] Iteration[50/363] Loss: 0.18Epoch[2] Iteration[100/363] Loss: 0.12Epoch[2] Iteration[150/363] Loss: 0.30Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.29Epoch[2] Iteration[300/363] Loss: 0.41Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.20Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.26Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.29Epoch[3] Iteration[300/363] Loss: 0.26Epoch[3] Iteration[350/363] Loss: 0.23Epoch[4] Iteration[50/363] Loss: 0.15Epoch[4] Iteration[100/363] Loss: 0.15Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.25Epoch[4] Iteration[250/363] Loss: 0.27Epoch[4] Iteration[300/363] Loss: 0.29Epoch[4] Iteration[350/363] Loss: 0.24Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.17Epoch[5] Iteration[150/363] Loss: 0.24Epoch[5] Iteration[200/363] Loss: 0.17Epoch[5] Iteration[250/363] Loss: 0.27Epoch[5] Iteration[300/363] Loss: 0.16Epoch[5] Iteration[350/363] Loss: 0.22Epoch[6] Iteration[50/363] Loss: 0.10Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.22Epoch[6] Iteration[200/363] Loss: 0.24Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.42Epoch[6] Iteration[350/363] Loss: 0.40
======== squeezenet1_1 ========

spatial feature len: 8192, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 37.50Epoch[1] Iteration[100/363] Loss: 37.50Epoch[1] Iteration[150/363] Loss: 37.50Epoch[1] Iteration[200/363] Loss: 34.38Epoch[1] Iteration[250/363] Loss: 37.50Epoch[1] Iteration[300/363] Loss: 21.88Epoch[1] Iteration[350/363] Loss: 37.50Epoch[2] Iteration[50/363] Loss: 37.50Epoch[2] Iteration[100/363] Loss: 37.50Epoch[2] Iteration[150/363] Loss: 37.50Epoch[2] Iteration[200/363] Loss: 34.38Epoch[2] Iteration[250/363] Loss: 37.50Epoch[2] Iteration[300/363] Loss: 21.88Epoch[2] Iteration[350/363] Loss: 37.50Epoch[3] Iteration[50/363] Loss: 37.50Epoch[3] Iteration[100/363] Loss: 37.50Epoch[3] Iteration[150/363] Loss: 37.50Epoch[3] Iteration[200/363] Loss: 34.38Epoch[3] Iteration[250/363] Loss: 37.50Epoch[3] Iteration[300/363] Loss: 21.88Epoch[3] Iteration[350/363] Loss: 37.50
======== densenet121 ========

spatial feature len: 4096, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.22Epoch[1] Iteration[100/363] Loss: 0.13Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.42Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.29Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.28Epoch[2] Iteration[200/363] Loss: 0.20Epoch[2] Iteration[250/363] Loss: 0.32Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.25Epoch[3] Iteration[50/363] Loss: 0.19Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.22Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.37Epoch[3] Iteration[350/363] Loss: 0.21Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.08Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.20Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.07Epoch[5] Iteration[150/363] Loss: 0.19Epoch[5] Iteration[200/363] Loss: 0.23Epoch[5] Iteration[250/363] Loss: 0.22Epoch[5] Iteration[300/363] Loss: 0.25Epoch[5] Iteration[350/363] Loss: 0.19
======== mnasnet1_0 ========

spatial feature len: 11520, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.30Epoch[1] Iteration[100/363] Loss: 0.16Epoch[1] Iteration[150/363] Loss: 0.24Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.34Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.25Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.12Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.18Epoch[3] Iteration[50/363] Loss: 0.19Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.21Epoch[3] Iteration[200/363] Loss: 0.15Epoch[3] Iteration[250/363] Loss: 0.21Epoch[3] Iteration[300/363] Loss: 0.24Epoch[3] Iteration[350/363] Loss: 0.18Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.13Epoch[4] Iteration[200/363] Loss: 0.10Epoch[4] Iteration[250/363] Loss: 0.20Epoch[4] Iteration[300/363] Loss: 0.26Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.08Epoch[5] Iteration[150/363] Loss: 0.13Epoch[5] Iteration[200/363] Loss: 0.17Epoch[5] Iteration[250/363] Loss: 0.19Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.13
======== vgg16 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.55Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.36Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.35Epoch[1] Iteration[350/363] Loss: 0.25Epoch[2] Iteration[50/363] Loss: 0.24Epoch[2] Iteration[100/363] Loss: 0.08Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.25Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.19Epoch[3] Iteration[50/363] Loss: 0.23Epoch[3] Iteration[100/363] Loss: 0.08Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.27Epoch[3] Iteration[300/363] Loss: 0.35Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.19Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.27Epoch[4] Iteration[300/363] Loss: 0.40Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.17Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.22Epoch[5] Iteration[200/363] Loss: 0.16Epoch[5] Iteration[250/363] Loss: 0.22Epoch[5] Iteration[300/363] Loss: 0.38Epoch[5] Iteration[350/363] Loss: 0.19Epoch[6] Iteration[50/363] Loss: 0.19Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.24Epoch[6] Iteration[200/363] Loss: 0.16Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.32Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.17Epoch[7] Iteration[100/363] Loss: 0.09Epoch[7] Iteration[150/363] Loss: 0.23Epoch[7] Iteration[200/363] Loss: 0.16Epoch[7] Iteration[250/363] Loss: 0.21Epoch[7] Iteration[300/363] Loss: 0.30Epoch[7] Iteration[350/363] Loss: 0.16No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded
Number of samples in training set: 11603
Number of samples in test set: 2901
Training and test data loaded

======== resnet50 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.19Epoch[1] Iteration[100/363] Loss: 0.21Epoch[1] Iteration[150/363] Loss: 0.35Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.35Epoch[1] Iteration[300/363] Loss: 0.54Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.14Epoch[2] Iteration[150/363] Loss: 0.28Epoch[2] Iteration[200/363] Loss: 0.25Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.36Epoch[2] Iteration[350/363] Loss: 0.30Epoch[3] Iteration[50/363] Loss: 0.20Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.25Epoch[3] Iteration[200/363] Loss: 0.24Epoch[3] Iteration[250/363] Loss: 0.27Epoch[3] Iteration[300/363] Loss: 0.36Epoch[3] Iteration[350/363] Loss: 0.28Epoch[4] Iteration[50/363] Loss: 0.12Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.22Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.29Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.10Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.25Epoch[5] Iteration[250/363] Loss: 0.22Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.13Epoch[6] Iteration[50/363] Loss: 0.10Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.20Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.23Epoch[6] Iteration[350/363] Loss: 0.14Epoch[7] Iteration[50/363] Loss: 0.07Epoch[7] Iteration[100/363] Loss: 0.07Epoch[7] Iteration[150/363] Loss: 0.23Epoch[7] Iteration[200/363] Loss: 0.24Epoch[7] Iteration[250/363] Loss: 0.15Epoch[7] Iteration[300/363] Loss: 0.15Epoch[7] Iteration[350/363] Loss: 0.10Epoch[8] Iteration[50/363] Loss: 0.08Epoch[8] Iteration[100/363] Loss: 0.08Epoch[8] Iteration[150/363] Loss: 0.25Epoch[8] Iteration[200/363] Loss: 0.26Epoch[8] Iteration[250/363] Loss: 0.16Epoch[8] Iteration[300/363] Loss: 0.20Epoch[8] Iteration[350/363] Loss: 0.11
======== resnet101 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.15Epoch[1] Iteration[100/363] Loss: 0.15Epoch[1] Iteration[150/363] Loss: 0.33Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.29Epoch[1] Iteration[300/363] Loss: 0.58Epoch[1] Iteration[350/363] Loss: 0.29Epoch[2] Iteration[50/363] Loss: 0.15Epoch[2] Iteration[100/363] Loss: 0.14Epoch[2] Iteration[150/363] Loss: 0.30Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.28Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.44Epoch[3] Iteration[300/363] Loss: 0.28Epoch[3] Iteration[350/363] Loss: 0.18Epoch[4] Iteration[50/363] Loss: 0.12Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.27Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.17No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded
Number of samples in training set: 11603
Number of samples in test set: 2901
Training and test data loaded

======== resnet34 ========

spatial feature len: 4608, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.17Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.39Epoch[1] Iteration[350/363] Loss: 0.34Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.28Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.25Epoch[2] Iteration[300/363] Loss: 0.36Epoch[2] Iteration[350/363] Loss: 0.27Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.14Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.26Epoch[3] Iteration[350/363] Loss: 0.23Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.15Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.23Epoch[4] Iteration[250/363] Loss: 0.20Epoch[4] Iteration[300/363] Loss: 0.27Epoch[4] Iteration[350/363] Loss: 0.26Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.15Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.17Epoch[5] Iteration[300/363] Loss: 0.25Epoch[5] Iteration[350/363] Loss: 0.19Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.13Epoch[6] Iteration[150/363] Loss: 0.16Epoch[6] Iteration[200/363] Loss: 0.26Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.23Epoch[6] Iteration[350/363] Loss: 0.17Epoch[7] Iteration[50/363] Loss: 0.10Epoch[7] Iteration[100/363] Loss: 0.14Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.29Epoch[7] Iteration[250/363] Loss: 0.19Epoch[7] Iteration[300/363] Loss: 0.19Epoch[7] Iteration[350/363] Loss: 0.25
======== resnet152 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.24Epoch[1] Iteration[100/363] Loss: 0.13Epoch[1] Iteration[150/363] Loss: 0.38Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.32Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.12Epoch[2] Iteration[150/363] Loss: 0.34Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.25Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.26Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.36Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.14Epoch[4] Iteration[150/363] Loss: 0.26Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.25Epoch[4] Iteration[300/363] Loss: 0.26Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.24Epoch[5] Iteration[200/363] Loss: 0.21Epoch[5] Iteration[250/363] Loss: 0.27Epoch[5] Iteration[300/363] Loss: 0.26Epoch[5] Iteration[350/363] Loss: 0.19
======== resnext50_32x4d ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.18Epoch[1] Iteration[100/363] Loss: 0.15Epoch[1] Iteration[150/363] Loss: 0.29Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.38Epoch[1] Iteration[350/363] Loss: 0.32Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.26Epoch[2] Iteration[200/363] Loss: 0.19Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.16Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.24Epoch[3] Iteration[250/363] Loss: 0.28Epoch[3] Iteration[300/363] Loss: 0.31Epoch[3] Iteration[350/363] Loss: 0.32Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.16Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.20Epoch[5] Iteration[300/363] Loss: 0.30Epoch[5] Iteration[350/363] Loss: 0.13Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.09Epoch[6] Iteration[150/363] Loss: 0.23Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.26Epoch[6] Iteration[300/363] Loss: 0.25Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.10Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.21Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.26Epoch[7] Iteration[300/363] Loss: 0.22Epoch[7] Iteration[350/363] Loss: 0.13Epoch[8] Iteration[50/363] Loss: 0.21Epoch[8] Iteration[100/363] Loss: 0.04Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.15Epoch[8] Iteration[250/363] Loss: 0.23Epoch[8] Iteration[300/363] Loss: 0.19Epoch[8] Iteration[350/363] Loss: 0.14Epoch[9] Iteration[50/363] Loss: 0.15Epoch[9] Iteration[100/363] Loss: 0.09Epoch[9] Iteration[150/363] Loss: 0.21Epoch[9] Iteration[200/363] Loss: 0.39Epoch[9] Iteration[250/363] Loss: 0.18Epoch[9] Iteration[300/363] Loss: 0.22Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.05Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.16Epoch[10] Iteration[200/363] Loss: 0.16Epoch[10] Iteration[250/363] Loss: 0.16Epoch[10] Iteration[300/363] Loss: 0.23Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.09Epoch[11] Iteration[100/363] Loss: 0.07Epoch[11] Iteration[150/363] Loss: 0.17Epoch[11] Iteration[200/363] Loss: 0.13Epoch[11] Iteration[250/363] Loss: 0.14Epoch[11] Iteration[300/363] Loss: 0.09Epoch[11] Iteration[350/363] Loss: 0.14
======== resnext101_32x8d ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.28Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.32Epoch[1] Iteration[200/363] Loss: 0.35Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.53Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.18Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.20Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.46Epoch[2] Iteration[350/363] Loss: 0.29Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.18Epoch[3] Iteration[300/363] Loss: 0.41Epoch[3] Iteration[350/363] Loss: 0.30Epoch[4] Iteration[50/363] Loss: 0.15Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.18Epoch[4] Iteration[200/363] Loss: 0.22Epoch[4] Iteration[250/363] Loss: 0.18Epoch[4] Iteration[300/363] Loss: 0.34Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.11Epoch[5] Iteration[150/363] Loss: 0.16Traceback (most recent call last):
  File "conpare_deep_models.py", line 94, in <module>
    main()
  File "conpare_deep_models.py", line 54, in main
    fix_seed(0)
  File "conpare_deep_models.py", line 45, in fix_seed
    random.seed(seed)
NameError: name 'random' is not defined
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded
Number of samples in training set: 11603
Number of samples in test set: 2901
Training and test data loaded

======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.34Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.29Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.22Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.18Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.21Epoch[6] Iteration[350/363] Loss: 0.16
======== vgg11 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.40Epoch[1] Iteration[100/363] Loss: 0.07Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.29Epoch[1] Iteration[300/363] Loss: 0.31Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.21Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.22Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.32Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.23Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.20Epoch[5] Iteration[300/363] Loss: 0.34Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.23Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.36Epoch[6] Iteration[350/363] Loss: 0.16
======== vgg16 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.56Epoch[1] Iteration[100/363] Loss: 0.26Epoch[1] Iteration[150/363] Loss: 0.33Epoch[1] Iteration[200/363] Loss: 0.33Epoch[1] Iteration[250/363] Loss: 0.42Epoch[1] Iteration[300/363] Loss: 0.32Epoch[1] Iteration[350/363] Loss: 0.35Epoch[2] Iteration[50/363] Loss: 0.25Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.28Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.30Epoch[3] Iteration[100/363] Loss: 0.07Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.18Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.19Epoch[4] Iteration[100/363] Loss: 0.08Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.15Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.20Epoch[5] Iteration[50/363] Loss: 0.19Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.14Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.26Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.19Epoch[6] Iteration[100/363] Loss: 0.12Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.15Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.26Epoch[6] Iteration[350/363] Loss: 0.15
======== squeezenet1_1 ========

spatial feature len: 8192, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.68Epoch[1] Iteration[100/363] Loss: 0.66Epoch[1] Iteration[150/363] Loss: 0.66Epoch[1] Iteration[200/363] Loss: 0.64Epoch[1] Iteration[250/363] Loss: 0.64Epoch[1] Iteration[300/363] Loss: 0.56Epoch[1] Iteration[350/363] Loss: 0.52Epoch[2] Iteration[50/363] Loss: 0.42Epoch[2] Iteration[100/363] Loss: 0.30Epoch[2] Iteration[150/363] Loss: 0.47Epoch[2] Iteration[200/363] Loss: 0.46Epoch[2] Iteration[250/363] Loss: 0.44Epoch[2] Iteration[300/363] Loss: 0.35Epoch[2] Iteration[350/363] Loss: 0.31Epoch[3] Iteration[50/363] Loss: 0.40Epoch[3] Iteration[100/363] Loss: 0.23Epoch[3] Iteration[150/363] Loss: 0.45Epoch[3] Iteration[200/363] Loss: 0.45Epoch[3] Iteration[250/363] Loss: 0.42Epoch[3] Iteration[300/363] Loss: 0.33Epoch[3] Iteration[350/363] Loss: 0.30Epoch[4] Iteration[50/363] Loss: 0.40Epoch[4] Iteration[100/363] Loss: 0.22Epoch[4] Iteration[150/363] Loss: 0.44Epoch[4] Iteration[200/363] Loss: 0.44Epoch[4] Iteration[250/363] Loss: 0.40Epoch[4] Iteration[300/363] Loss: 0.32Epoch[4] Iteration[350/363] Loss: 0.29Epoch[5] Iteration[50/363] Loss: 0.41Epoch[5] Iteration[100/363] Loss: 0.20Epoch[5] Iteration[150/363] Loss: 0.44Epoch[5] Iteration[200/363] Loss: 0.43Epoch[5] Iteration[250/363] Loss: 0.39Epoch[5] Iteration[300/363] Loss: 0.31Epoch[5] Iteration[350/363] Loss: 0.29Epoch[6] Iteration[50/363] Loss: 0.41Epoch[6] Iteration[100/363] Loss: 0.19Epoch[6] Iteration[150/363] Loss: 0.44Epoch[6] Iteration[200/363] Loss: 0.42Epoch[6] Iteration[250/363] Loss: 0.38Epoch[6] Iteration[300/363] Loss: 0.29Epoch[6] Iteration[350/363] Loss: 0.29Epoch[7] Iteration[50/363] Loss: 0.40Epoch[7] Iteration[100/363] Loss: 0.18Epoch[7] Iteration[150/363] Loss: 0.44Epoch[7] Iteration[200/363] Loss: 0.40Epoch[7] Iteration[250/363] Loss: 0.37Epoch[7] Iteration[300/363] Loss: 0.27Epoch[7] Iteration[350/363] Loss: 0.27Epoch[8] Iteration[50/363] Loss: 0.39Epoch[8] Iteration[100/363] Loss: 0.17Epoch[8] Iteration[150/363] Loss: 0.44Epoch[8] Iteration[200/363] Loss: 0.40Epoch[8] Iteration[250/363] Loss: 0.36Epoch[8] Iteration[300/363] Loss: 0.26Epoch[8] Iteration[350/363] Loss: 0.26Epoch[9] Iteration[50/363] Loss: 0.38Epoch[9] Iteration[100/363] Loss: 0.15Epoch[9] Iteration[150/363] Loss: 0.44Epoch[9] Iteration[200/363] Loss: 0.39Epoch[9] Iteration[250/363] Loss: 0.34Epoch[9] Iteration[300/363] Loss: 0.25Epoch[9] Iteration[350/363] Loss: 0.25Epoch[10] Iteration[50/363] Loss: 0.38Epoch[10] Iteration[100/363] Loss: 0.14Epoch[10] Iteration[150/363] Loss: 0.43Epoch[10] Iteration[200/363] Loss: 0.38Epoch[10] Iteration[250/363] Loss: 0.31Epoch[10] Iteration[300/363] Loss: 0.24Epoch[10] Iteration[350/363] Loss: 0.24Epoch[11] Iteration[50/363] Loss: 0.38Epoch[11] Iteration[100/363] Loss: 0.13Epoch[11] Iteration[150/363] Loss: 0.42Epoch[11] Iteration[200/363] Loss: 0.38Epoch[11] Iteration[250/363] Loss: 0.29Epoch[11] Iteration[300/363] Loss: 0.23Epoch[11] Iteration[350/363] Loss: 0.24Epoch[12] Iteration[50/363] Loss: 0.37Epoch[12] Iteration[100/363] Loss: 0.12Epoch[12] Iteration[150/363] Loss: 0.40Epoch[12] Iteration[200/363] Loss: 0.38Epoch[12] Iteration[250/363] Loss: 0.28Epoch[12] Iteration[300/363] Loss: 0.23Epoch[12] Iteration[350/363] Loss: 0.24Epoch[13] Iteration[50/363] Loss: 0.35Epoch[13] Iteration[100/363] Loss: 0.12Epoch[13] Iteration[150/363] Loss: 0.39Epoch[13] Iteration[200/363] Loss: 0.38Epoch[13] Iteration[250/363] Loss: 0.27Epoch[13] Iteration[300/363] Loss: 0.22Epoch[13] Iteration[350/363] Loss: 0.25Epoch[14] Iteration[50/363] Loss: 0.35Epoch[14] Iteration[100/363] Loss: 0.11Epoch[14] Iteration[150/363] Loss: 0.37Epoch[14] Iteration[200/363] Loss: 0.38Epoch[14] Iteration[250/363] Loss: 0.26Epoch[14] Iteration[300/363] Loss: 0.22Epoch[14] Iteration[350/363] Loss: 0.25Epoch[15] Iteration[50/363] Loss: 0.33Epoch[15] Iteration[100/363] Loss: 0.11Epoch[15] Iteration[150/363] Loss: 0.36Epoch[15] Iteration[200/363] Loss: 0.39Epoch[15] Iteration[250/363] Loss: 0.25Epoch[15] Iteration[300/363] Loss: 0.21Epoch[15] Iteration[350/363] Loss: 0.25Epoch[16] Iteration[50/363] Loss: 0.31Epoch[16] Iteration[100/363] Loss: 0.10Epoch[16] Iteration[150/363] Loss: 0.34Epoch[16] Iteration[200/363] Loss: 0.39Epoch[16] Iteration[250/363] Loss: 0.24Epoch[16] Iteration[300/363] Loss: 0.21Epoch[16] Iteration[350/363] Loss: 0.26Epoch[17] Iteration[50/363] Loss: 0.31Epoch[17] Iteration[100/363] Loss: 0.10Epoch[17] Iteration[150/363] Loss: 0.32Epoch[17] Iteration[200/363] Loss: 0.37Epoch[17] Iteration[250/363] Loss: 0.23Epoch[17] Iteration[300/363] Loss: 0.21Epoch[17] Iteration[350/363] Loss: 0.26Epoch[18] Iteration[50/363] Loss: 0.29Epoch[18] Iteration[100/363] Loss: 0.10Epoch[18] Iteration[150/363] Loss: 0.30Epoch[18] Iteration[200/363] Loss: 0.37Epoch[18] Iteration[250/363] Loss: 0.23Epoch[18] Iteration[300/363] Loss: 0.20Epoch[18] Iteration[350/363] Loss: 0.25Epoch[19] Iteration[50/363] Loss: 0.24Epoch[19] Iteration[100/363] Loss: 0.10Epoch[19] Iteration[150/363] Loss: 0.29Epoch[19] Iteration[200/363] Loss: 0.34Epoch[19] Iteration[250/363] Loss: 0.22Epoch[19] Iteration[300/363] Loss: 0.21Epoch[19] Iteration[350/363] Loss: 0.25Epoch[20] Iteration[50/363] Loss: 0.23Epoch[20] Iteration[100/363] Loss: 0.10Epoch[20] Iteration[150/363] Loss: 0.26Epoch[20] Iteration[200/363] Loss: 0.32Epoch[20] Iteration[250/363] Loss: 0.19Epoch[20] Iteration[300/363] Loss: 0.20Epoch[20] Iteration[350/363] Loss: 0.20Epoch[21] Iteration[50/363] Loss: 0.21Epoch[21] Iteration[100/363] Loss: 0.09Epoch[21] Iteration[150/363] Loss: 0.26Epoch[21] Iteration[200/363] Loss: 0.35Epoch[21] Iteration[250/363] Loss: 0.18Epoch[21] Iteration[300/363] Loss: 0.20Epoch[21] Iteration[350/363] Loss: 0.20Epoch[22] Iteration[50/363] Loss: 0.22Epoch[22] Iteration[100/363] Loss: 0.09Epoch[22] Iteration[150/363] Loss: 0.21Epoch[22] Iteration[200/363] Loss: 0.30Epoch[22] Iteration[250/363] Loss: 0.15Epoch[22] Iteration[300/363] Loss: 0.20Epoch[22] Iteration[350/363] Loss: 0.18Epoch[23] Iteration[50/363] Loss: 0.23Epoch[23] Iteration[100/363] Loss: 0.09Epoch[23] Iteration[150/363] Loss: 0.24Epoch[23] Iteration[200/363] Loss: 0.32Epoch[23] Iteration[250/363] Loss: 0.12Epoch[23] Iteration[300/363] Loss: 0.19Epoch[23] Iteration[350/363] Loss: 0.21Epoch[24] Iteration[50/363] Loss: 0.18Epoch[24] Iteration[100/363] Loss: 0.08Epoch[24] Iteration[150/363] Loss: 0.21Epoch[24] Iteration[200/363] Loss: 0.27Epoch[24] Iteration[250/363] Loss: 0.13Epoch[24] Iteration[300/363] Loss: 0.20Epoch[24] Iteration[350/363] Loss: 0.15Epoch[25] Iteration[50/363] Loss: 0.21Epoch[25] Iteration[100/363] Loss: 0.07Epoch[25] Iteration[150/363] Loss: 0.23Epoch[25] Iteration[200/363] Loss: 0.30Epoch[25] Iteration[250/363] Loss: 0.09Epoch[25] Iteration[300/363] Loss: 0.15Epoch[25] Iteration[350/363] Loss: 0.16Epoch[26] Iteration[50/363] Loss: 0.15Epoch[26] Iteration[100/363] Loss: 0.07Epoch[26] Iteration[150/363] Loss: 0.22Epoch[26] Iteration[200/363] Loss: 0.40Epoch[26] Iteration[250/363] Loss: 0.07Epoch[26] Iteration[300/363] Loss: 0.15Epoch[26] Iteration[350/363] Loss: 0.12Epoch[27] Iteration[50/363] Loss: 0.17Epoch[27] Iteration[100/363] Loss: 0.07Epoch[27] Iteration[150/363] Loss: 0.12Epoch[27] Iteration[200/363] Loss: 0.28Epoch[27] Iteration[250/363] Loss: 0.15Epoch[27] Iteration[300/363] Loss: 0.15Epoch[27] Iteration[350/363] Loss: 0.08Epoch[28] Iteration[50/363] Loss: 0.12Epoch[28] Iteration[100/363] Loss: 0.15Epoch[28] Iteration[150/363] Loss: 0.18Epoch[28] Iteration[200/363] Loss: 0.24Epoch[28] Iteration[250/363] Loss: 0.09Epoch[28] Iteration[300/363] Loss: 0.15Epoch[28] Iteration[350/363] Loss: 0.10Epoch[29] Iteration[50/363] Loss: 0.13Epoch[29] Iteration[100/363] Loss: 0.08Epoch[29] Iteration[150/363] Loss: 0.16Epoch[29] Iteration[200/363] Loss: 0.43Epoch[29] Iteration[250/363] Loss: 0.11Epoch[29] Iteration[300/363] Loss: 0.15Epoch[29] Iteration[350/363] Loss: 0.10Epoch[30] Iteration[50/363] Loss: 0.15Epoch[30] Iteration[100/363] Loss: 0.07Epoch[30] Iteration[150/363] Loss: 0.15Epoch[30] Iteration[200/363] Loss: 0.20Epoch[30] Iteration[250/363] Loss: 0.06Epoch[30] Iteration[300/363] Loss: 0.13Epoch[30] Iteration[350/363] Loss: 0.06Epoch[31] Iteration[50/363] Loss: 0.13Epoch[31] Iteration[100/363] Loss: 0.06Epoch[31] Iteration[150/363] Loss: 0.11Epoch[31] Iteration[200/363] Loss: 0.17Epoch[31] Iteration[250/363] Loss: 0.18Epoch[31] Iteration[300/363] Loss: 0.18Epoch[31] Iteration[350/363] Loss: 0.05Epoch[32] Iteration[50/363] Loss: 0.12Epoch[32] Iteration[100/363] Loss: 0.03Epoch[32] Iteration[150/363] Loss: 0.10Epoch[32] Iteration[200/363] Loss: 0.14Epoch[32] Iteration[250/363] Loss: 0.02Epoch[32] Iteration[300/363] Loss: 0.20Epoch[32] Iteration[350/363] Loss: 0.08Epoch[33] Iteration[50/363] Loss: 0.12Epoch[33] Iteration[100/363] Loss: 0.01Epoch[33] Iteration[150/363] Loss: 0.08Epoch[33] Iteration[200/363] Loss: 0.05Epoch[33] Iteration[250/363] Loss: 0.03Epoch[33] Iteration[300/363] Loss: 0.16Epoch[33] Iteration[350/363] Loss: 0.18Epoch[34] Iteration[50/363] Loss: 0.15Epoch[34] Iteration[100/363] Loss: 0.01Epoch[34] Iteration[150/363] Loss: 0.08Epoch[34] Iteration[200/363] Loss: 0.15Epoch[34] Iteration[250/363] Loss: 0.02Epoch[34] Iteration[300/363] Loss: 0.17Epoch[34] Iteration[350/363] Loss: 0.09Epoch[35] Iteration[50/363] Loss: 0.08Epoch[35] Iteration[100/363] Loss: 0.03Epoch[35] Iteration[150/363] Loss: 0.13Epoch[35] Iteration[200/363] Loss: 0.11Epoch[35] Iteration[250/363] Loss: 0.10Epoch[35] Iteration[300/363] Loss: 0.16Epoch[35] Iteration[350/363] Loss: 0.06Epoch[36] Iteration[50/363] Loss: 0.10Epoch[36] Iteration[100/363] Loss: 0.01Epoch[36] Iteration[150/363] Loss: 0.12Epoch[36] Iteration[200/363] Loss: 0.10Epoch[36] Iteration[250/363] Loss: 0.03Epoch[36] Iteration[300/363] Loss: 0.08Epoch[36] Iteration[350/363] Loss: 0.05Epoch[37] Iteration[50/363] Loss: 0.10Epoch[37] Iteration[100/363] Loss: 0.01Epoch[37] Iteration[150/363] Loss: 0.05Epoch[37] Iteration[200/363] Loss: 0.08Epoch[37] Iteration[250/363] Loss: 0.04Epoch[37] Iteration[300/363] Loss: 0.19Epoch[37] Iteration[350/363] Loss: 0.02Epoch[38] Iteration[50/363] Loss: 0.11Epoch[38] Iteration[100/363] Loss: 0.02Epoch[38] Iteration[150/363] Loss: 0.09Epoch[38] Iteration[200/363] Loss: 0.08Epoch[38] Iteration[250/363] Loss: 0.05Epoch[38] Iteration[300/363] Loss: 0.06Epoch[38] Iteration[350/363] Loss: 0.02Epoch[39] Iteration[50/363] Loss: 0.09Epoch[39] Iteration[100/363] Loss: 0.00Epoch[39] Iteration[150/363] Loss: 0.07Epoch[39] Iteration[200/363] Loss: 0.07Epoch[39] Iteration[250/363] Loss: 0.08Epoch[39] Iteration[300/363] Loss: 0.07Epoch[39] Iteration[350/363] Loss: 0.01Epoch[40] Iteration[50/363] Loss: 0.10Epoch[40] Iteration[100/363] Loss: 0.04Epoch[40] Iteration[150/363] Loss: 0.08Epoch[40] Iteration[200/363] Loss: 0.06Epoch[40] Iteration[250/363] Loss: 0.05Epoch[40] Iteration[300/363] Loss: 0.05Epoch[40] Iteration[350/363] Loss: 0.02Epoch[41] Iteration[50/363] Loss: 0.10Epoch[41] Iteration[100/363] Loss: 0.00Epoch[41] Iteration[150/363] Loss: 0.03Epoch[41] Iteration[200/363] Loss: 0.06Epoch[41] Iteration[250/363] Loss: 0.30Epoch[41] Iteration[300/363] Loss: 0.06Epoch[41] Iteration[350/363] Loss: 0.02Epoch[42] Iteration[50/363] Loss: 0.11Epoch[42] Iteration[100/363] Loss: 0.01Epoch[42] Iteration[150/363] Loss: 0.09Epoch[42] Iteration[200/363] Loss: 0.04Epoch[42] Iteration[250/363] Loss: 0.02Epoch[42] Iteration[300/363] Loss: 0.06Epoch[42] Iteration[350/363] Loss: 0.02Epoch[43] Iteration[50/363] Loss: 0.09Epoch[43] Iteration[100/363] Loss: 0.09Epoch[43] Iteration[150/363] Loss: 0.02Epoch[43] Iteration[200/363] Loss: 0.10Epoch[43] Iteration[250/363] Loss: 0.13Epoch[43] Iteration[300/363] Loss: 0.05Epoch[43] Iteration[350/363] Loss: 0.01Epoch[44] Iteration[50/363] Loss: 0.08Epoch[44] Iteration[100/363] Loss: 0.00Epoch[44] Iteration[150/363] Loss: 0.06Epoch[44] Iteration[200/363] Loss: 0.03Epoch[44] Iteration[250/363] Loss: 0.02Epoch[44] Iteration[300/363] Loss: 0.04Epoch[44] Iteration[350/363] Loss: 0.01Epoch[45] Iteration[50/363] Loss: 0.09Epoch[45] Iteration[100/363] Loss: 0.00Epoch[45] Iteration[150/363] Loss: 0.07Epoch[45] Iteration[200/363] Loss: 0.05Epoch[45] Iteration[250/363] Loss: 0.03Epoch[45] Iteration[300/363] Loss: 0.03Epoch[45] Iteration[350/363] Loss: 0.02Epoch[46] Iteration[50/363] Loss: 0.10Epoch[46] Iteration[100/363] Loss: 0.00Epoch[46] Iteration[150/363] Loss: 0.06Epoch[46] Iteration[200/363] Loss: 0.05Epoch[46] Iteration[250/363] Loss: 0.03Epoch[46] Iteration[300/363] Loss: 0.03Epoch[46] Iteration[350/363] Loss: 0.02Epoch[47] Iteration[50/363] Loss: 0.07Epoch[47] Iteration[100/363] Loss: 0.00Epoch[47] Iteration[150/363] Loss: 0.04Epoch[47] Iteration[200/363] Loss: 0.06Epoch[47] Iteration[250/363] Loss: 0.03Epoch[47] Iteration[300/363] Loss: 0.07Epoch[47] Iteration[350/363] Loss: 0.04Epoch[48] Iteration[50/363] Loss: 0.07Epoch[48] Iteration[100/363] Loss: 0.00Epoch[48] Iteration[150/363] Loss: 0.13Epoch[48] Iteration[200/363] Loss: 0.11Epoch[48] Iteration[250/363] Loss: 0.05Epoch[48] Iteration[300/363] Loss: 0.15Epoch[48] Iteration[350/363] Loss: 0.02Epoch[49] Iteration[50/363] Loss: 0.09Epoch[49] Iteration[100/363] Loss: 0.00Epoch[49] Iteration[150/363] Loss: 0.01Epoch[49] Iteration[200/363] Loss: 0.03Epoch[49] Iteration[250/363] Loss: 0.03Epoch[49] Iteration[300/363] Loss: 0.06Epoch[49] Iteration[350/363] Loss: 0.05Epoch[50] Iteration[50/363] Loss: 0.11Epoch[50] Iteration[100/363] Loss: 0.00Epoch[50] Iteration[150/363] Loss: 0.03Epoch[50] Iteration[200/363] Loss: 0.08Epoch[50] Iteration[250/363] Loss: 0.05Epoch[50] Iteration[300/363] Loss: 0.03Epoch[50] Iteration[350/363] Loss: 0.03
======== densenet121 ========

spatial feature len: 4096, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.13Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.23Epoch[1] Iteration[250/363] Loss: 0.35Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.21Epoch[2] Iteration[100/363] Loss: 0.08Epoch[2] Iteration[150/363] Loss: 0.25Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.37Epoch[2] Iteration[350/363] Loss: 0.23Epoch[3] Iteration[50/363] Loss: 0.19Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.29Epoch[3] Iteration[300/363] Loss: 0.29Epoch[3] Iteration[350/363] Loss: 0.24Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.17Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.30Epoch[4] Iteration[350/363] Loss: 0.22Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.17Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.23Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.18Epoch[6] Iteration[250/363] Loss: 0.24Epoch[6] Iteration[300/363] Loss: 0.28Epoch[6] Iteration[350/363] Loss: 0.25Epoch[7] Iteration[50/363] Loss: 0.12Epoch[7] Iteration[100/363] Loss: 0.11Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.16Epoch[7] Iteration[250/363] Loss: 0.25Epoch[7] Iteration[300/363] Loss: 0.25Epoch[7] Iteration[350/363] Loss: 0.22Epoch[8] Iteration[50/363] Loss: 0.11Epoch[8] Iteration[100/363] Loss: 0.12Epoch[8] Iteration[150/363] Loss: 0.18Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.23Epoch[8] Iteration[300/363] Loss: 0.26Epoch[8] Iteration[350/363] Loss: 0.23Epoch[9] Iteration[50/363] Loss: 0.12Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.10Epoch[9] Iteration[200/363] Loss: 0.21Epoch[9] Iteration[250/363] Loss: 0.20Epoch[9] Iteration[300/363] Loss: 0.27Epoch[9] Iteration[350/363] Loss: 0.23Epoch[10] Iteration[50/363] Loss: 0.15Epoch[10] Iteration[100/363] Loss: 0.17Epoch[10] Iteration[150/363] Loss: 0.13Epoch[10] Iteration[200/363] Loss: 0.17Epoch[10] Iteration[250/363] Loss: 0.24Epoch[10] Iteration[300/363] Loss: 0.17Epoch[10] Iteration[350/363] Loss: 0.35Epoch[11] Iteration[50/363] Loss: 0.10Epoch[11] Iteration[100/363] Loss: 0.18Epoch[11] Iteration[150/363] Loss: 0.11Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.18Epoch[11] Iteration[300/363] Loss: 0.15Epoch[11] Iteration[350/363] Loss: 0.22Epoch[12] Iteration[50/363] Loss: 0.11Epoch[12] Iteration[100/363] Loss: 0.14Epoch[12] Iteration[150/363] Loss: 0.12Epoch[12] Iteration[200/363] Loss: 0.14Epoch[12] Iteration[250/363] Loss: 0.16Epoch[12] Iteration[300/363] Loss: 0.14Epoch[12] Iteration[350/363] Loss: 0.19Epoch[13] Iteration[50/363] Loss: 0.07Epoch[13] Iteration[100/363] Loss: 0.18Epoch[13] Iteration[150/363] Loss: 0.13Epoch[13] Iteration[200/363] Loss: 0.11Epoch[13] Iteration[250/363] Loss: 0.05Epoch[13] Iteration[300/363] Loss: 0.13Epoch[13] Iteration[350/363] Loss: 0.18Epoch[14] Iteration[50/363] Loss: 0.07Epoch[14] Iteration[100/363] Loss: 0.11Epoch[14] Iteration[150/363] Loss: 0.15Epoch[14] Iteration[200/363] Loss: 0.22Epoch[14] Iteration[250/363] Loss: 0.21Epoch[14] Iteration[300/363] Loss: 0.12Epoch[14] Iteration[350/363] Loss: 0.18Epoch[15] Iteration[50/363] Loss: 0.06Epoch[15] Iteration[100/363] Loss: 0.08Epoch[15] Iteration[150/363] Loss: 0.13Epoch[15] Iteration[200/363] Loss: 0.07Epoch[15] Iteration[250/363] Loss: 0.09Epoch[15] Iteration[300/363] Loss: 0.09Epoch[15] Iteration[350/363] Loss: 0.32Epoch[16] Iteration[50/363] Loss: 0.08No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.34Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.29Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.22Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.18Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.21Epoch[6] Iteration[350/363] Loss: 0.16
======== vgg11 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.40Epoch[1] Iteration[100/363] Loss: 0.07Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.29Epoch[1] Iteration[300/363] Loss: 0.31Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.21Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.22Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.32Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.23Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.20Epoch[5] Iteration[300/363] Loss: 0.34Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.23Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.36Epoch[6] Iteration[350/363] Loss: 0.16
======== vgg16 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.56Epoch[1] Iteration[100/363] Loss: 0.26Epoch[1] Iteration[150/363] Loss: 0.33Epoch[1] Iteration[200/363] Loss: 0.33Epoch[1] Iteration[250/363] Loss: 0.42Epoch[1] Iteration[300/363] Loss: 0.32Epoch[1] Iteration[350/363] Loss: 0.35Epoch[2] Iteration[50/363] Loss: 0.25Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.28Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.30Epoch[3] Iteration[100/363] Loss: 0.07Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.18Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.19Epoch[4] Iteration[100/363] Loss: 0.08Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.15Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.20Epoch[5] Iteration[50/363] Loss: 0.19Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.14Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.26Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.19Epoch[6] Iteration[100/363] Loss: 0.12Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.15Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.26Epoch[6] Iteration[350/363] Loss: 0.15
======== squeezenet1_1 ========

spatial feature len: 8192, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.68Epoch[1] Iteration[100/363] Loss: 0.66Epoch[1] Iteration[150/363] Loss: 0.66Epoch[1] Iteration[200/363] Loss: 0.64Epoch[1] Iteration[250/363] Loss: 0.64Epoch[1] Iteration[300/363] Loss: 0.56Epoch[1] Iteration[350/363] Loss: 0.52Epoch[2] Iteration[50/363] Loss: 0.42Epoch[2] Iteration[100/363] Loss: 0.30Epoch[2] Iteration[150/363] Loss: 0.47Epoch[2] Iteration[200/363] Loss: 0.46Epoch[2] Iteration[250/363] Loss: 0.44Epoch[2] Iteration[300/363] Loss: 0.35Epoch[2] Iteration[350/363] Loss: 0.31Epoch[3] Iteration[50/363] Loss: 0.40Epoch[3] Iteration[100/363] Loss: 0.23Epoch[3] Iteration[150/363] Loss: 0.45Epoch[3] Iteration[200/363] Loss: 0.45Epoch[3] Iteration[250/363] Loss: 0.42Epoch[3] Iteration[300/363] Loss: 0.33Epoch[3] Iteration[350/363] Loss: 0.30Epoch[4] Iteration[50/363] Loss: 0.40Epoch[4] Iteration[100/363] Loss: 0.22Epoch[4] Iteration[150/363] Loss: 0.44Epoch[4] Iteration[200/363] Loss: 0.44Epoch[4] Iteration[250/363] Loss: 0.40Epoch[4] Iteration[300/363] Loss: 0.32Epoch[4] Iteration[350/363] Loss: 0.29Epoch[5] Iteration[50/363] Loss: 0.41Epoch[5] Iteration[100/363] Loss: 0.20Epoch[5] Iteration[150/363] Loss: 0.44Epoch[5] Iteration[200/363] Loss: 0.43Epoch[5] Iteration[250/363] Loss: 0.39Epoch[5] Iteration[300/363] Loss: 0.31Epoch[5] Iteration[350/363] Loss: 0.29Epoch[6] Iteration[50/363] Loss: 0.41Epoch[6] Iteration[100/363] Loss: 0.19Epoch[6] Iteration[150/363] Loss: 0.44Epoch[6] Iteration[200/363] Loss: 0.42Epoch[6] Iteration[250/363] Loss: 0.38Epoch[6] Iteration[300/363] Loss: 0.29Epoch[6] Iteration[350/363] Loss: 0.29Epoch[7] Iteration[50/363] Loss: 0.40Epoch[7] Iteration[100/363] Loss: 0.18Epoch[7] Iteration[150/363] Loss: 0.44Epoch[7] Iteration[200/363] Loss: 0.40Epoch[7] Iteration[250/363] Loss: 0.37Epoch[7] Iteration[300/363] Loss: 0.27Epoch[7] Iteration[350/363] Loss: 0.27Epoch[8] Iteration[50/363] Loss: 0.39Epoch[8] Iteration[100/363] Loss: 0.17Epoch[8] Iteration[150/363] Loss: 0.44Epoch[8] Iteration[200/363] Loss: 0.40Epoch[8] Iteration[250/363] Loss: 0.36Epoch[8] Iteration[300/363] Loss: 0.26Epoch[8] Iteration[350/363] Loss: 0.26Epoch[9] Iteration[50/363] Loss: 0.38Epoch[9] Iteration[100/363] Loss: 0.15Epoch[9] Iteration[150/363] Loss: 0.44Epoch[9] Iteration[200/363] Loss: 0.39Epoch[9] Iteration[250/363] Loss: 0.34Epoch[9] Iteration[300/363] Loss: 0.25Epoch[9] Iteration[350/363] Loss: 0.25Epoch[10] Iteration[50/363] Loss: 0.38Epoch[10] Iteration[100/363] Loss: 0.14Epoch[10] Iteration[150/363] Loss: 0.43Epoch[10] Iteration[200/363] Loss: 0.38Epoch[10] Iteration[250/363] Loss: 0.31Epoch[10] Iteration[300/363] Loss: 0.24Epoch[10] Iteration[350/363] Loss: 0.24Epoch[11] Iteration[50/363] Loss: 0.38Epoch[11] Iteration[100/363] Loss: 0.13Epoch[11] Iteration[150/363] Loss: 0.42Epoch[11] Iteration[200/363] Loss: 0.38Epoch[11] Iteration[250/363] Loss: 0.29Epoch[11] Iteration[300/363] Loss: 0.23Epoch[11] Iteration[350/363] Loss: 0.24Epoch[12] Iteration[50/363] Loss: 0.37Epoch[12] Iteration[100/363] Loss: 0.12Epoch[12] Iteration[150/363] Loss: 0.40Epoch[12] Iteration[200/363] Loss: 0.38Epoch[12] Iteration[250/363] Loss: 0.28Epoch[12] Iteration[300/363] Loss: 0.23Epoch[12] Iteration[350/363] Loss: 0.24Epoch[13] Iteration[50/363] Loss: 0.35Epoch[13] Iteration[100/363] Loss: 0.12Epoch[13] Iteration[150/363] Loss: 0.39Epoch[13] Iteration[200/363] Loss: 0.38Epoch[13] Iteration[250/363] Loss: 0.27Epoch[13] Iteration[300/363] Loss: 0.22Epoch[13] Iteration[350/363] Loss: 0.25Epoch[14] Iteration[50/363] Loss: 0.35Epoch[14] Iteration[100/363] Loss: 0.11Epoch[14] Iteration[150/363] Loss: 0.37Epoch[14] Iteration[200/363] Loss: 0.38Epoch[14] Iteration[250/363] Loss: 0.26Epoch[14] Iteration[300/363] Loss: 0.22Epoch[14] Iteration[350/363] Loss: 0.25Epoch[15] Iteration[50/363] Loss: 0.33Epoch[15] Iteration[100/363] Loss: 0.11Epoch[15] Iteration[150/363] Loss: 0.36Epoch[15] Iteration[200/363] Loss: 0.39Epoch[15] Iteration[250/363] Loss: 0.25Epoch[15] Iteration[300/363] Loss: 0.21Epoch[15] Iteration[350/363] Loss: 0.25Epoch[16] Iteration[50/363] Loss: 0.31Epoch[16] Iteration[100/363] Loss: 0.10Epoch[16] Iteration[150/363] Loss: 0.34Epoch[16] Iteration[200/363] Loss: 0.39Epoch[16] Iteration[250/363] Loss: 0.24Epoch[16] Iteration[300/363] Loss: 0.21Epoch[16] Iteration[350/363] Loss: 0.26Epoch[17] Iteration[50/363] Loss: 0.31Epoch[17] Iteration[100/363] Loss: 0.10Epoch[17] Iteration[150/363] Loss: 0.32Epoch[17] Iteration[200/363] Loss: 0.37Epoch[17] Iteration[250/363] Loss: 0.23Epoch[17] Iteration[300/363] Loss: 0.21Epoch[17] Iteration[350/363] Loss: 0.26Epoch[18] Iteration[50/363] Loss: 0.29Epoch[18] Iteration[100/363] Loss: 0.10Epoch[18] Iteration[150/363] Loss: 0.30Epoch[18] Iteration[200/363] Loss: 0.37Epoch[18] Iteration[250/363] Loss: 0.23Epoch[18] Iteration[300/363] Loss: 0.20Epoch[18] Iteration[350/363] Loss: 0.25Epoch[19] Iteration[50/363] Loss: 0.24Epoch[19] Iteration[100/363] Loss: 0.10Epoch[19] Iteration[150/363] Loss: 0.29Epoch[19] Iteration[200/363] Loss: 0.34Epoch[19] Iteration[250/363] Loss: 0.22Epoch[19] Iteration[300/363] Loss: 0.21Epoch[19] Iteration[350/363] Loss: 0.25Epoch[20] Iteration[50/363] Loss: 0.23Epoch[20] Iteration[100/363] Loss: 0.10Epoch[20] Iteration[150/363] Loss: 0.26Epoch[20] Iteration[200/363] Loss: 0.32Epoch[20] Iteration[250/363] Loss: 0.19Epoch[20] Iteration[300/363] Loss: 0.20Epoch[20] Iteration[350/363] Loss: 0.20Epoch[21] Iteration[50/363] Loss: 0.21Epoch[21] Iteration[100/363] Loss: 0.09Epoch[21] Iteration[150/363] Loss: 0.26Epoch[21] Iteration[200/363] Loss: 0.35Epoch[21] Iteration[250/363] Loss: 0.18Epoch[21] Iteration[300/363] Loss: 0.20Epoch[21] Iteration[350/363] Loss: 0.20Epoch[22] Iteration[50/363] Loss: 0.22Epoch[22] Iteration[100/363] Loss: 0.09Epoch[22] Iteration[150/363] Loss: 0.21Epoch[22] Iteration[200/363] Loss: 0.30Epoch[22] Iteration[250/363] Loss: 0.15Epoch[22] Iteration[300/363] Loss: 0.20Epoch[22] Iteration[350/363] Loss: 0.18Epoch[23] Iteration[50/363] Loss: 0.23Epoch[23] Iteration[100/363] Loss: 0.09Epoch[23] Iteration[150/363] Loss: 0.24Epoch[23] Iteration[200/363] Loss: 0.32Epoch[23] Iteration[250/363] Loss: 0.12Epoch[23] Iteration[300/363] Loss: 0.19Epoch[23] Iteration[350/363] Loss: 0.21Epoch[24] Iteration[50/363] Loss: 0.18Epoch[24] Iteration[100/363] Loss: 0.08Epoch[24] Iteration[150/363] Loss: 0.21Epoch[24] Iteration[200/363] Loss: 0.27Epoch[24] Iteration[250/363] Loss: 0.13Epoch[24] Iteration[300/363] Loss: 0.20Epoch[24] Iteration[350/363] Loss: 0.15Epoch[25] Iteration[50/363] Loss: 0.21Epoch[25] Iteration[100/363] Loss: 0.07Epoch[25] Iteration[150/363] Loss: 0.23Epoch[25] Iteration[200/363] Loss: 0.30Epoch[25] Iteration[250/363] Loss: 0.09Epoch[25] Iteration[300/363] Loss: 0.15Epoch[25] Iteration[350/363] Loss: 0.16Epoch[26] Iteration[50/363] Loss: 0.15Epoch[26] Iteration[100/363] Loss: 0.07Epoch[26] Iteration[150/363] Loss: 0.22Epoch[26] Iteration[200/363] Loss: 0.40Epoch[26] Iteration[250/363] Loss: 0.07Epoch[26] Iteration[300/363] Loss: 0.15Epoch[26] Iteration[350/363] Loss: 0.12Epoch[27] Iteration[50/363] Loss: 0.17Epoch[27] Iteration[100/363] Loss: 0.07Epoch[27] Iteration[150/363] Loss: 0.12Epoch[27] Iteration[200/363] Loss: 0.28Epoch[27] Iteration[250/363] Loss: 0.15Epoch[27] Iteration[300/363] Loss: 0.15Epoch[27] Iteration[350/363] Loss: 0.08Epoch[28] Iteration[50/363] Loss: 0.12Epoch[28] Iteration[100/363] Loss: 0.15Epoch[28] Iteration[150/363] Loss: 0.18Epoch[28] Iteration[200/363] Loss: 0.24Epoch[28] Iteration[250/363] Loss: 0.09Epoch[28] Iteration[300/363] Loss: 0.15Epoch[28] Iteration[350/363] Loss: 0.10Epoch[29] Iteration[50/363] Loss: 0.13Epoch[29] Iteration[100/363] Loss: 0.08Epoch[29] Iteration[150/363] Loss: 0.16Epoch[29] Iteration[200/363] Loss: 0.43Epoch[29] Iteration[250/363] Loss: 0.11Epoch[29] Iteration[300/363] Loss: 0.15Epoch[29] Iteration[350/363] Loss: 0.10Epoch[30] Iteration[50/363] Loss: 0.15Epoch[30] Iteration[100/363] Loss: 0.07Epoch[30] Iteration[150/363] Loss: 0.15Epoch[30] Iteration[200/363] Loss: 0.20Epoch[30] Iteration[250/363] Loss: 0.06Epoch[30] Iteration[300/363] Loss: 0.13Epoch[30] Iteration[350/363] Loss: 0.06Epoch[31] Iteration[50/363] Loss: 0.13Epoch[31] Iteration[100/363] Loss: 0.06Epoch[31] Iteration[150/363] Loss: 0.11Epoch[31] Iteration[200/363] Loss: 0.17Epoch[31] Iteration[250/363] Loss: 0.18Epoch[31] Iteration[300/363] Loss: 0.18Epoch[31] Iteration[350/363] Loss: 0.05Epoch[32] Iteration[50/363] Loss: 0.12Epoch[32] Iteration[100/363] Loss: 0.03Epoch[32] Iteration[150/363] Loss: 0.10Epoch[32] Iteration[200/363] Loss: 0.14Epoch[32] Iteration[250/363] Loss: 0.02Epoch[32] Iteration[300/363] Loss: 0.20Epoch[32] Iteration[350/363] Loss: 0.08Epoch[33] Iteration[50/363] Loss: 0.12Epoch[33] Iteration[100/363] Loss: 0.01Epoch[33] Iteration[150/363] Loss: 0.08Epoch[33] Iteration[200/363] Loss: 0.05Epoch[33] Iteration[250/363] Loss: 0.03Epoch[33] Iteration[300/363] Loss: 0.16Epoch[33] Iteration[350/363] Loss: 0.18Epoch[34] Iteration[50/363] Loss: 0.15Epoch[34] Iteration[100/363] Loss: 0.01Epoch[34] Iteration[150/363] Loss: 0.08Epoch[34] Iteration[200/363] Loss: 0.15Epoch[34] Iteration[250/363] Loss: 0.02Epoch[34] Iteration[300/363] Loss: 0.17Epoch[34] Iteration[350/363] Loss: 0.09Epoch[35] Iteration[50/363] Loss: 0.08Epoch[35] Iteration[100/363] Loss: 0.03Epoch[35] Iteration[150/363] Loss: 0.13Epoch[35] Iteration[200/363] Loss: 0.11Epoch[35] Iteration[250/363] Loss: 0.10Epoch[35] Iteration[300/363] Loss: 0.16Epoch[35] Iteration[350/363] Loss: 0.06Epoch[36] Iteration[50/363] Loss: 0.10Epoch[36] Iteration[100/363] Loss: 0.01Epoch[36] Iteration[150/363] Loss: 0.12Epoch[36] Iteration[200/363] Loss: 0.10Epoch[36] Iteration[250/363] Loss: 0.03Epoch[36] Iteration[300/363] Loss: 0.08Epoch[36] Iteration[350/363] Loss: 0.05Epoch[37] Iteration[50/363] Loss: 0.10Epoch[37] Iteration[100/363] Loss: 0.01Epoch[37] Iteration[150/363] Loss: 0.05Epoch[37] Iteration[200/363] Loss: 0.08Epoch[37] Iteration[250/363] Loss: 0.04Epoch[37] Iteration[300/363] Loss: 0.19Epoch[37] Iteration[350/363] Loss: 0.02Epoch[38] Iteration[50/363] Loss: 0.11Epoch[38] Iteration[100/363] Loss: 0.02Epoch[38] Iteration[150/363] Loss: 0.09Epoch[38] Iteration[200/363] Loss: 0.08Epoch[38] Iteration[250/363] Loss: 0.05Epoch[38] Iteration[300/363] Loss: 0.06Epoch[38] Iteration[350/363] Loss: 0.02Epoch[39] Iteration[50/363] Loss: 0.09Epoch[39] Iteration[100/363] Loss: 0.00Epoch[39] Iteration[150/363] Loss: 0.07Epoch[39] Iteration[200/363] Loss: 0.07Epoch[39] Iteration[250/363] Loss: 0.08Epoch[39] Iteration[300/363] Loss: 0.07Epoch[39] Iteration[350/363] Loss: 0.01Epoch[40] Iteration[50/363] Loss: 0.10Epoch[40] Iteration[100/363] Loss: 0.04Epoch[40] Iteration[150/363] Loss: 0.08Epoch[40] Iteration[200/363] Loss: 0.06Epoch[40] Iteration[250/363] Loss: 0.05Epoch[40] Iteration[300/363] Loss: 0.05Epoch[40] Iteration[350/363] Loss: 0.02Epoch[41] Iteration[50/363] Loss: 0.10Epoch[41] Iteration[100/363] Loss: 0.00Epoch[41] Iteration[150/363] Loss: 0.03Epoch[41] Iteration[200/363] Loss: 0.06Epoch[41] Iteration[250/363] Loss: 0.30Epoch[41] Iteration[300/363] Loss: 0.06Epoch[41] Iteration[350/363] Loss: 0.02Epoch[42] Iteration[50/363] Loss: 0.11Epoch[42] Iteration[100/363] Loss: 0.01Epoch[42] Iteration[150/363] Loss: 0.09Epoch[42] Iteration[200/363] Loss: 0.04Epoch[42] Iteration[250/363] Loss: 0.02Epoch[42] Iteration[300/363] Loss: 0.06Epoch[42] Iteration[350/363] Loss: 0.02Epoch[43] Iteration[50/363] Loss: 0.09Epoch[43] Iteration[100/363] Loss: 0.09Epoch[43] Iteration[150/363] Loss: 0.02Epoch[43] Iteration[200/363] Loss: 0.10Epoch[43] Iteration[250/363] Loss: 0.13Epoch[43] Iteration[300/363] Loss: 0.05Epoch[43] Iteration[350/363] Loss: 0.01Epoch[44] Iteration[50/363] Loss: 0.08Epoch[44] Iteration[100/363] Loss: 0.00Epoch[44] Iteration[150/363] Loss: 0.06Epoch[44] Iteration[200/363] Loss: 0.03Epoch[44] Iteration[250/363] Loss: 0.02Epoch[44] Iteration[300/363] Loss: 0.04Epoch[44] Iteration[350/363] Loss: 0.01Epoch[45] Iteration[50/363] Loss: 0.09Epoch[45] Iteration[100/363] Loss: 0.00Epoch[45] Iteration[150/363] Loss: 0.07Epoch[45] Iteration[200/363] Loss: 0.05Epoch[45] Iteration[250/363] Loss: 0.03Epoch[45] Iteration[300/363] Loss: 0.03Epoch[45] Iteration[350/363] Loss: 0.02Epoch[46] Iteration[50/363] Loss: 0.10Epoch[46] Iteration[100/363] Loss: 0.00Epoch[46] Iteration[150/363] Loss: 0.06Epoch[46] Iteration[200/363] Loss: 0.05Epoch[46] Iteration[250/363] Loss: 0.03Epoch[46] Iteration[300/363] Loss: 0.03Epoch[46] Iteration[350/363] Loss: 0.02Epoch[47] Iteration[50/363] Loss: 0.07Epoch[47] Iteration[100/363] Loss: 0.00Epoch[47] Iteration[150/363] Loss: 0.04Epoch[47] Iteration[200/363] Loss: 0.06Epoch[47] Iteration[250/363] Loss: 0.03Epoch[47] Iteration[300/363] Loss: 0.07Epoch[47] Iteration[350/363] Loss: 0.04Epoch[48] Iteration[50/363] Loss: 0.07Epoch[48] Iteration[100/363] Loss: 0.00Epoch[48] Iteration[150/363] Loss: 0.13Epoch[48] Iteration[200/363] Loss: 0.11Epoch[48] Iteration[250/363] Loss: 0.05Epoch[48] Iteration[300/363] Loss: 0.15Epoch[48] Iteration[350/363] Loss: 0.02Epoch[49] Iteration[50/363] Loss: 0.09Epoch[49] Iteration[100/363] Loss: 0.00Epoch[49] Iteration[150/363] Loss: 0.01Epoch[49] Iteration[200/363] Loss: 0.03Epoch[49] Iteration[250/363] Loss: 0.03Epoch[49] Iteration[300/363] Loss: 0.06Epoch[49] Iteration[350/363] Loss: 0.05Epoch[50] Iteration[50/363] Loss: 0.11Epoch[50] Iteration[100/363] Loss: 0.00Epoch[50] Iteration[150/363] Loss: 0.03Epoch[50] Iteration[200/363] Loss: 0.08Epoch[50] Iteration[250/363] Loss: 0.05Epoch[50] Iteration[300/363] Loss: 0.03Epoch[50] Iteration[350/363] Loss: 0.03
======== densenet121 ========

spatial feature len: 4096, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.13Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.23Epoch[1] Iteration[250/363] Loss: 0.35Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.21Epoch[2] Iteration[100/363] Loss: 0.08Epoch[2] Iteration[150/363] Loss: 0.25Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.37Epoch[2] Iteration[350/363] Loss: 0.23Epoch[3] Iteration[50/363] Loss: 0.19Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.29Epoch[3] Iteration[300/363] Loss: 0.29Epoch[3] Iteration[350/363] Loss: 0.24Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.17Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.30Epoch[4] Iteration[350/363] Loss: 0.22Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.17Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.23Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.18Epoch[6] Iteration[250/363] Loss: 0.24Epoch[6] Iteration[300/363] Loss: 0.28Epoch[6] Iteration[350/363] Loss: 0.25Epoch[7] Iteration[50/363] Loss: 0.12Epoch[7] Iteration[100/363] Loss: 0.11Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.16Epoch[7] Iteration[250/363] Loss: 0.25Epoch[7] Iteration[300/363] Loss: 0.25Epoch[7] Iteration[350/363] Loss: 0.22Epoch[8] Iteration[50/363] Loss: 0.11Epoch[8] Iteration[100/363] Loss: 0.12Epoch[8] Iteration[150/363] Loss: 0.18Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.23Epoch[8] Iteration[300/363] Loss: 0.26Epoch[8] Iteration[350/363] Loss: 0.23Epoch[9] Iteration[50/363] Loss: 0.12Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.10Epoch[9] Iteration[200/363] Loss: 0.21Epoch[9] Iteration[250/363] Loss: 0.20Epoch[9] Iteration[300/363] Loss: 0.27Epoch[9] Iteration[350/363] Loss: 0.23Epoch[10] Iteration[50/363] Loss: 0.15Epoch[10] Iteration[100/363] Loss: 0.17Epoch[10] Iteration[150/363] Loss: 0.13Epoch[10] Iteration[200/363] Loss: 0.17Epoch[10] Iteration[250/363] Loss: 0.24Epoch[10] Iteration[300/363] Loss: 0.17Epoch[10] Iteration[350/363] Loss: 0.35Epoch[11] Iteration[50/363] Loss: 0.10Epoch[11] Iteration[100/363] Loss: 0.18Epoch[11] Iteration[150/363] Loss: 0.11Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.18Epoch[11] Iteration[300/363] Loss: 0.15Epoch[11] Iteration[350/363] Loss: 0.22Epoch[12] Iteration[50/363] Loss: 0.11Epoch[12] Iteration[100/363] Loss: 0.14Epoch[12] Iteration[150/363] Loss: 0.12Epoch[12] Iteration[200/363] Loss: 0.14Epoch[12] Iteration[250/363] Loss: 0.16Epoch[12] Iteration[300/363] Loss: 0.14Epoch[12] Iteration[350/363] Loss: 0.19Epoch[13] Iteration[50/363] Loss: 0.07Epoch[13] Iteration[100/363] Loss: 0.18Epoch[13] Iteration[150/363] Loss: 0.13Epoch[13] Iteration[200/363] Loss: 0.11Epoch[13] Iteration[250/363] Loss: 0.05Epoch[13] Iteration[300/363] Loss: 0.13Epoch[13] Iteration[350/363] Loss: 0.18Epoch[14] Iteration[50/363] Loss: 0.07Epoch[14] Iteration[100/363] Loss: 0.11Epoch[14] Iteration[150/363] Loss: 0.15Epoch[14] Iteration[200/363] Loss: 0.22Epoch[14] Iteration[250/363] Loss: 0.21Epoch[14] Iteration[300/363] Loss: 0.12Epoch[14] Iteration[350/363] Loss: 0.18Epoch[15] Iteration[50/363] Loss: 0.06Epoch[15] Iteration[100/363] Loss: 0.08Epoch[15] Iteration[150/363] Loss: 0.13Epoch[15] Iteration[200/363] Loss: 0.07Epoch[15] Iteration[250/363] Loss: 0.09Epoch[15] Iteration[300/363] Loss: 0.09Epoch[15] Iteration[350/363] Loss: 0.32Epoch[16] Iteration[50/363] Loss: 0.08Epoch[16] Iteration[100/363] Loss: 0.06Epoch[16] Iteration[150/363] Loss: 0.05Epoch[16] Iteration[200/363] Loss: 0.09Epoch[16] Iteration[250/363] Loss: 0.14Epoch[16] Iteration[300/363] Loss: 0.11Epoch[16] Iteration[350/363] Loss: 0.13Epoch[17] Iteration[50/363] Loss: 0.19Epoch[17] Iteration[100/363] Loss: 0.07Epoch[17] Iteration[150/363] Loss: 0.07Epoch[17] Iteration[200/363] Loss: 0.07Epoch[17] Iteration[250/363] Loss: 0.18Epoch[17] Iteration[300/363] Loss: 0.17Epoch[17] Iteration[350/363] Loss: 0.20Epoch[18] Iteration[50/363] Loss: 0.04Epoch[18] Iteration[100/363] Loss: 0.02Epoch[18] Iteration[150/363] Loss: 0.08Epoch[18] Iteration[200/363] Loss: 0.07Epoch[18] Iteration[250/363] Loss: 0.02Epoch[18] Iteration[300/363] Loss: 0.11Epoch[18] Iteration[350/363] Loss: 0.16Epoch[19] Iteration[50/363] Loss: 0.05Epoch[19] Iteration[100/363] Loss: 0.12Epoch[19] Iteration[150/363] Loss: 0.06Epoch[19] Iteration[200/363] Loss: 0.07Epoch[19] Iteration[250/363] Loss: 0.10Epoch[19] Iteration[300/363] Loss: 0.13Epoch[19] Iteration[350/363] Loss: 0.16Epoch[20] Iteration[50/363] Loss: 0.07Epoch[20] Iteration[100/363] Loss: 0.03Epoch[20] Iteration[150/363] Loss: 0.07Epoch[20] Iteration[200/363] Loss: 0.09Epoch[20] Iteration[250/363] Loss: 0.05Epoch[20] Iteration[300/363] Loss: 0.09Epoch[20] Iteration[350/363] Loss: 0.15Epoch[21] Iteration[50/363] Loss: 0.19Epoch[21] Iteration[100/363] Loss: 0.01Epoch[21] Iteration[150/363] Loss: 0.12Epoch[21] Iteration[200/363] Loss: 0.03Epoch[21] Iteration[250/363] Loss: 0.11Epoch[21] Iteration[300/363] Loss: 0.09Epoch[21] Iteration[350/363] Loss: 0.21Epoch[22] Iteration[50/363] Loss: 0.04Epoch[22] Iteration[100/363] Loss: 0.08Epoch[22] Iteration[150/363] Loss: 0.10Epoch[22] Iteration[200/363] Loss: 0.16Epoch[22] Iteration[250/363] Loss: 0.05Epoch[22] Iteration[300/363] Loss: 0.09Epoch[22] Iteration[350/363] Loss: 0.14Epoch[23] Iteration[50/363] Loss: 0.17Epoch[23] Iteration[100/363] Loss: 0.02Epoch[23] Iteration[150/363] Loss: 0.10Epoch[23] Iteration[200/363] Loss: 0.03Epoch[23] Iteration[250/363] Loss: 0.03Epoch[23] Iteration[300/363] Loss: 0.11Epoch[23] Iteration[350/363] Loss: 0.10No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.34Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.29Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.22Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.34Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.29Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.22Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.18Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.21Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.15Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.20Epoch[7] Iteration[200/363] Loss: 0.21Epoch[7] Iteration[250/363] Loss: 0.21Epoch[7] Iteration[300/363] Loss: 0.18Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.15Epoch[8] Iteration[100/363] Loss: 0.10Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.19Epoch[8] Iteration[300/363] Loss: 0.18Epoch[8] Iteration[350/363] Loss: 0.14Epoch[9] Iteration[50/363] Loss: 0.16Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.19Epoch[9] Iteration[200/363] Loss: 0.20Epoch[9] Iteration[250/363] Loss: 0.19Epoch[9] Iteration[300/363] Loss: 0.16Epoch[9] Iteration[350/363] Loss: 0.13Epoch[10] Iteration[50/363] Loss: 0.17Epoch[10] Iteration[100/363] Loss: 0.09Epoch[10] Iteration[150/363] Loss: 0.18Epoch[10] Iteration[200/363] Loss: 0.19Epoch[10] Iteration[250/363] Loss: 0.18Epoch[10] Iteration[300/363] Loss: 0.17Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.17Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.18Epoch[11] Iteration[200/363] Loss: 0.18Epoch[11] Iteration[250/363] Loss: 0.17Epoch[11] Iteration[300/363] Loss: 0.17Epoch[11] Iteration[350/363] Loss: 0.13No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== vgg11 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.30Epoch[1] Iteration[100/363] Loss: 0.12Epoch[1] Iteration[150/363] Loss: 0.36Epoch[1] Iteration[200/363] Loss: 0.24Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.32Epoch[1] Iteration[350/363] Loss: 0.24Epoch[2] Iteration[50/363] Loss: 0.24Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.29Epoch[2] Iteration[350/363] Loss: 0.20Epoch[3] Iteration[50/363] Loss: 0.19Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.22Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.17Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.18Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.19Epoch[6] Iteration[200/363] Loss: 0.20Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.27Epoch[6] Iteration[350/363] Loss: 0.18Epoch[7] Iteration[50/363] Loss: 0.17Epoch[7] Iteration[100/363] Loss: 0.07Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.18Epoch[7] Iteration[250/363] Loss: 0.16Epoch[7] Iteration[300/363] Loss: 0.24Epoch[7] Iteration[350/363] Loss: 0.19Epoch[8] Iteration[50/363] Loss: 0.16Epoch[8] Iteration[100/363] Loss: 0.12Epoch[8] Iteration[150/363] Loss: 0.18Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.15Epoch[8] Iteration[300/363] Loss: 0.20Epoch[8] Iteration[350/363] Loss: 0.15Epoch[9] Iteration[50/363] Loss: 0.18Epoch[9] Iteration[100/363] Loss: 0.11Epoch[9] Iteration[150/363] Loss: 0.18Epoch[9] Iteration[200/363] Loss: 0.20Epoch[9] Iteration[250/363] Loss: 0.18Epoch[9] Iteration[300/363] Loss: 0.21Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.18Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.20Epoch[10] Iteration[200/363] Loss: 0.15Epoch[10] Iteration[250/363] Loss: 0.16Epoch[10] Iteration[300/363] Loss: 0.19Epoch[10] Iteration[350/363] Loss: 0.11Epoch[11] Iteration[50/363] Loss: 0.16Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.18Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.14Epoch[11] Iteration[300/363] Loss: 0.21Epoch[11] Iteration[350/363] Loss: 0.10
======== vgg16 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.34Epoch[1] Iteration[100/363] Loss: 0.19Epoch[1] Iteration[150/363] Loss: 0.36Epoch[1] Iteration[200/363] Loss: 0.22Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.33Epoch[1] Iteration[350/363] Loss: 0.26Epoch[2] Iteration[50/363] Loss: 0.23Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.28Epoch[2] Iteration[200/363] Loss: 0.26Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.30Epoch[2] Iteration[350/363] Loss: 0.19Epoch[3] Iteration[50/363] Loss: 0.21Epoch[3] Iteration[100/363] Loss: 0.08Epoch[3] Iteration[150/363] Loss: 0.21Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.17Epoch[4] Iteration[50/363] Loss: 0.20Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.22Epoch[4] Iteration[300/363] Loss: 0.33Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.21Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.17Epoch[5] Iteration[250/363] Loss: 0.25Epoch[5] Iteration[300/363] Loss: 0.38Epoch[5] Iteration[350/363] Loss: 0.16Epoch[6] Iteration[50/363] Loss: 0.20Epoch[6] Iteration[100/363] Loss: 0.12Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.34Epoch[6] Iteration[350/363] Loss: 0.19Epoch[7] Iteration[50/363] Loss: 0.19Epoch[7] Iteration[100/363] Loss: 0.07Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.14Epoch[7] Iteration[250/363] Loss: 0.21Epoch[7] Iteration[300/363] Loss: 0.26Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.17Epoch[8] Iteration[100/363] Loss: 0.04Epoch[8] Iteration[150/363] Loss: 0.17Epoch[8] Iteration[200/363] Loss: 0.15Epoch[8] Iteration[250/363] Loss: 0.21Epoch[8] Iteration[300/363] Loss: 0.23Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.17Epoch[9] Iteration[100/363] Loss: 0.06Epoch[9] Iteration[150/363] Loss: 0.15Epoch[9] Iteration[200/363] Loss: 0.10Epoch[9] Iteration[250/363] Loss: 0.17Epoch[9] Iteration[300/363] Loss: 0.22Epoch[9] Iteration[350/363] Loss: 0.16Epoch[10] Iteration[50/363] Loss: 0.17Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.11Epoch[10] Iteration[250/363] Loss: 0.16Epoch[10] Iteration[300/363] Loss: 0.19Epoch[10] Iteration[350/363] Loss: 0.14Epoch[11] Iteration[50/363] Loss: 0.14Epoch[11] Iteration[100/363] Loss: 0.22Epoch[11] Iteration[150/363] Loss: 0.18Epoch[11] Iteration[200/363] Loss: 0.12Epoch[11] Iteration[250/363] Loss: 0.11Epoch[11] Iteration[300/363] Loss: 0.13Epoch[11] Iteration[350/363] Loss: 0.20
======== squeezenet1_1 ========

spatial feature len: 8192, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.66Epoch[1] Iteration[100/363] Loss: 0.63Epoch[1] Iteration[150/363] Loss: 0.57Epoch[1] Iteration[200/363] Loss: 0.49Epoch[1] Iteration[250/363] Loss: 0.43Epoch[1] Iteration[300/363] Loss: 0.36Epoch[1] Iteration[350/363] Loss: 0.32Epoch[2] Iteration[50/363] Loss: 0.41Epoch[2] Iteration[100/363] Loss: 0.24Epoch[2] Iteration[150/363] Loss: 0.45Epoch[2] Iteration[200/363] Loss: 0.46Epoch[2] Iteration[250/363] Loss: 0.40Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.30Epoch[3] Iteration[50/363] Loss: 0.41Epoch[3] Iteration[100/363] Loss: 0.22Epoch[3] Iteration[150/363] Loss: 0.44Epoch[3] Iteration[200/363] Loss: 0.45Epoch[3] Iteration[250/363] Loss: 0.40Epoch[3] Iteration[300/363] Loss: 0.34Epoch[3] Iteration[350/363] Loss: 0.30Epoch[4] Iteration[50/363] Loss: 0.42Epoch[4] Iteration[100/363] Loss: 0.21Epoch[4] Iteration[150/363] Loss: 0.44Epoch[4] Iteration[200/363] Loss: 0.44Epoch[4] Iteration[250/363] Loss: 0.39Epoch[4] Iteration[300/363] Loss: 0.33Epoch[4] Iteration[350/363] Loss: 0.29Epoch[5] Iteration[50/363] Loss: 0.42Epoch[5] Iteration[100/363] Loss: 0.20Epoch[5] Iteration[150/363] Loss: 0.45Epoch[5] Iteration[200/363] Loss: 0.43Epoch[5] Iteration[250/363] Loss: 0.39Epoch[5] Iteration[300/363] Loss: 0.32Epoch[5] Iteration[350/363] Loss: 0.29Epoch[6] Iteration[50/363] Loss: 0.42Epoch[6] Iteration[100/363] Loss: 0.19Epoch[6] Iteration[150/363] Loss: 0.46Epoch[6] Iteration[200/363] Loss: 0.42Epoch[6] Iteration[250/363] Loss: 0.38Epoch[6] Iteration[300/363] Loss: 0.32Epoch[6] Iteration[350/363] Loss: 0.29Epoch[7] Iteration[50/363] Loss: 0.41Epoch[7] Iteration[100/363] Loss: 0.18Epoch[7] Iteration[150/363] Loss: 0.45Epoch[7] Iteration[200/363] Loss: 0.42Epoch[7] Iteration[250/363] Loss: 0.36Epoch[7] Iteration[300/363] Loss: 0.31Epoch[7] Iteration[350/363] Loss: 0.28Epoch[8] Iteration[50/363] Loss: 0.40Epoch[8] Iteration[100/363] Loss: 0.17Epoch[8] Iteration[150/363] Loss: 0.44Epoch[8] Iteration[200/363] Loss: 0.42Epoch[8] Iteration[250/363] Loss: 0.34Epoch[8] Iteration[300/363] Loss: 0.31Epoch[8] Iteration[350/363] Loss: 0.26Epoch[9] Iteration[50/363] Loss: 0.39Epoch[9] Iteration[100/363] Loss: 0.16Epoch[9] Iteration[150/363] Loss: 0.42Epoch[9] Iteration[200/363] Loss: 0.42Epoch[9] Iteration[250/363] Loss: 0.31Epoch[9] Iteration[300/363] Loss: 0.30Epoch[9] Iteration[350/363] Loss: 0.24Epoch[10] Iteration[50/363] Loss: 0.38Epoch[10] Iteration[100/363] Loss: 0.14Epoch[10] Iteration[150/363] Loss: 0.38Epoch[10] Iteration[200/363] Loss: 0.39Epoch[10] Iteration[250/363] Loss: 0.27Epoch[10] Iteration[300/363] Loss: 0.26Epoch[10] Iteration[350/363] Loss: 0.24Epoch[11] Iteration[50/363] Loss: 0.39Epoch[11] Iteration[100/363] Loss: 0.12Epoch[11] Iteration[150/363] Loss: 0.36Epoch[11] Iteration[200/363] Loss: 0.39Epoch[11] Iteration[250/363] Loss: 0.26Epoch[11] Iteration[300/363] Loss: 0.24Epoch[11] Iteration[350/363] Loss: 0.23Epoch[12] Iteration[50/363] Loss: 0.41Epoch[12] Iteration[100/363] Loss: 0.11Epoch[12] Iteration[150/363] Loss: 0.34Epoch[12] Iteration[200/363] Loss: 0.43Epoch[12] Iteration[250/363] Loss: 0.26Epoch[12] Iteration[300/363] Loss: 0.23Epoch[12] Iteration[350/363] Loss: 0.22Epoch[13] Iteration[50/363] Loss: 0.41Epoch[13] Iteration[100/363] Loss: 0.10Epoch[13] Iteration[150/363] Loss: 0.33Epoch[13] Iteration[200/363] Loss: 0.46Epoch[13] Iteration[250/363] Loss: 0.24Epoch[13] Iteration[300/363] Loss: 0.23Epoch[13] Iteration[350/363] Loss: 0.23Epoch[14] Iteration[50/363] Loss: 0.40Epoch[14] Iteration[100/363] Loss: 0.10Epoch[14] Iteration[150/363] Loss: 0.31Epoch[14] Iteration[200/363] Loss: 0.47Epoch[14] Iteration[250/363] Loss: 0.24Epoch[14] Iteration[300/363] Loss: 0.22Epoch[14] Iteration[350/363] Loss: 0.24Epoch[15] Iteration[50/363] Loss: 0.38Epoch[15] Iteration[100/363] Loss: 0.09Epoch[15] Iteration[150/363] Loss: 0.31Epoch[15] Iteration[200/363] Loss: 0.46Epoch[15] Iteration[250/363] Loss: 0.23Epoch[15] Iteration[300/363] Loss: 0.21Epoch[15] Iteration[350/363] Loss: 0.24Epoch[16] Iteration[50/363] Loss: 0.34Epoch[16] Iteration[100/363] Loss: 0.08Epoch[16] Iteration[150/363] Loss: 0.32Epoch[16] Iteration[200/363] Loss: 0.40Epoch[16] Iteration[250/363] Loss: 0.22Epoch[16] Iteration[300/363] Loss: 0.21Epoch[16] Iteration[350/363] Loss: 0.22Epoch[17] Iteration[50/363] Loss: 0.28Epoch[17] Iteration[100/363] Loss: 0.07Epoch[17] Iteration[150/363] Loss: 0.30Epoch[17] Iteration[200/363] Loss: 0.39Epoch[17] Iteration[250/363] Loss: 0.20Epoch[17] Iteration[300/363] Loss: 0.19Epoch[17] Iteration[350/363] Loss: 0.20Epoch[18] Iteration[50/363] Loss: 0.22Epoch[18] Iteration[100/363] Loss: 0.06Epoch[18] Iteration[150/363] Loss: 0.30Epoch[18] Iteration[200/363] Loss: 0.35Epoch[18] Iteration[250/363] Loss: 0.18Epoch[18] Iteration[300/363] Loss: 0.17Epoch[18] Iteration[350/363] Loss: 0.19Epoch[19] Iteration[50/363] Loss: 0.19Epoch[19] Iteration[100/363] Loss: 0.06Epoch[19] Iteration[150/363] Loss: 0.27Epoch[19] Iteration[200/363] Loss: 0.32Epoch[19] Iteration[250/363] Loss: 0.17Epoch[19] Iteration[300/363] Loss: 0.16Epoch[19] Iteration[350/363] Loss: 0.15Epoch[20] Iteration[50/363] Loss: 0.18Epoch[20] Iteration[100/363] Loss: 0.07Epoch[20] Iteration[150/363] Loss: 0.18Epoch[20] Iteration[200/363] Loss: 0.36Epoch[20] Iteration[250/363] Loss: 0.10Epoch[20] Iteration[300/363] Loss: 0.17Epoch[20] Iteration[350/363] Loss: 0.13Epoch[21] Iteration[50/363] Loss: 0.15Epoch[21] Iteration[100/363] Loss: 0.08Epoch[21] Iteration[150/363] Loss: 0.23Epoch[21] Iteration[200/363] Loss: 0.36Epoch[21] Iteration[250/363] Loss: 0.10Epoch[21] Iteration[300/363] Loss: 0.15Epoch[21] Iteration[350/363] Loss: 0.14Epoch[22] Iteration[50/363] Loss: 0.16Epoch[22] Iteration[100/363] Loss: 0.10Epoch[22] Iteration[150/363] Loss: 0.22Epoch[22] Iteration[200/363] Loss: 0.22Epoch[22] Iteration[250/363] Loss: 0.09Epoch[22] Iteration[300/363] Loss: 0.13Epoch[22] Iteration[350/363] Loss: 0.07
======== densenet121 ========

spatial feature len: 4096, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.21Epoch[1] Iteration[100/363] Loss: 0.13Epoch[1] Iteration[150/363] Loss: 0.31Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.38Epoch[1] Iteration[350/363] Loss: 0.29Epoch[2] Iteration[50/363] Loss: 0.15Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.21Epoch[2] Iteration[300/363] Loss: 0.40Epoch[2] Iteration[350/363] Loss: 0.25Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.24Epoch[3] Iteration[250/363] Loss: 0.20Epoch[3] Iteration[300/363] Loss: 0.34Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.07Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.24Epoch[4] Iteration[250/363] Loss: 0.20Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.18Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.05Epoch[5] Iteration[150/363] Loss: 0.25Epoch[5] Iteration[200/363] Loss: 0.22Epoch[5] Iteration[250/363] Loss: 0.16Epoch[5] Iteration[300/363] Loss: 0.31Epoch[5] Iteration[350/363] Loss: 0.34Epoch[6] Iteration[50/363] Loss: 0.12Epoch[6] Iteration[100/363] Loss: 0.07Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.17Epoch[6] Iteration[300/363] Loss: 0.32Epoch[6] Iteration[350/363] Loss: 0.13Epoch[7] Iteration[50/363] Loss: 0.14Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.23Epoch[7] Iteration[200/363] Loss: 0.22Epoch[7] Iteration[250/363] Loss: 0.22Epoch[7] Iteration[300/363] Loss: 0.31Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.12Epoch[8] Iteration[100/363] Loss: 0.08Epoch[8] Iteration[150/363] Loss: 0.25Epoch[8] Iteration[200/363] Loss: 0.16Epoch[8] Iteration[250/363] Loss: 0.22Epoch[8] Iteration[300/363] Loss: 0.22Epoch[8] Iteration[350/363] Loss: 0.16Epoch[9] Iteration[50/363] Loss: 0.09Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.19Epoch[9] Iteration[200/363] Loss: 0.17Epoch[9] Iteration[250/363] Loss: 0.20Epoch[9] Iteration[300/363] Loss: 0.28Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.10Epoch[10] Iteration[100/363] Loss: 0.19Epoch[10] Iteration[150/363] Loss: 0.24Epoch[10] Iteration[200/363] Loss: 0.17Epoch[10] Iteration[250/363] Loss: 0.14Epoch[10] Iteration[300/363] Loss: 0.20Epoch[10] Iteration[350/363] Loss: 0.13Epoch[11] Iteration[50/363] Loss: 0.06Epoch[11] Iteration[100/363] Loss: 0.04Epoch[11] Iteration[150/363] Loss: 0.23Epoch[11] Iteration[200/363] Loss: 0.18Epoch[11] Iteration[250/363] Loss: 0.13Epoch[11] Iteration[300/363] Loss: 0.26Epoch[11] Iteration[350/363] Loss: 0.17Epoch[12] Iteration[50/363] Loss: 0.07Epoch[12] Iteration[100/363] Loss: 0.05Epoch[12] Iteration[150/363] Loss: 0.16Epoch[12] Iteration[200/363] Loss: 0.15Epoch[12] Iteration[250/363] Loss: 0.10Epoch[12] Iteration[300/363] Loss: 0.13Epoch[12] Iteration[350/363] Loss: 0.13
======== densenet201mobilenet_v2 ========

Traceback (most recent call last):
  File "conpare_deep_models.py", line 87, in <module>
    main()
  File "conpare_deep_models.py", line 80, in main
    t_output_dim=500
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/model.py", line 38, in __init__
    self.spatial_stage = Extractor(s_stage, pretrained=True).cuda()
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/extractor.py", line 38, in __init__
    raise ValueError(f'{self.model_name} is unsupported extractor')
ValueError: densenet201mobilenet_v2 is unsupported extractor
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== densenet201 ========

spatial feature len: 7680, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.23Epoch[1] Iteration[100/363] Loss: 0.15Epoch[1] Iteration[150/363] Loss: 0.26Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.32Epoch[1] Iteration[300/363] Loss: 0.45Epoch[1] Iteration[350/363] Loss: 0.36Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.26Epoch[2] Iteration[200/363] Loss: 0.25Epoch[2] Iteration[250/363] Loss: 0.20Epoch[2] Iteration[300/363] Loss: 0.49Epoch[2] Iteration[350/363] Loss: 0.33Epoch[3] Iteration[50/363] Loss: 0.18Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.22Epoch[3] Iteration[250/363] Loss: 0.22Epoch[3] Iteration[300/363] Loss: 0.42Epoch[3] Iteration[350/363] Loss: 0.26Epoch[4] Iteration[50/363] Loss: 0.20Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.20Epoch[4] Iteration[250/363] Loss: 0.19Epoch[4] Iteration[300/363] Loss: 0.38Epoch[4] Iteration[350/363] Loss: 0.25Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.07Epoch[5] Iteration[150/363] Loss: 0.19Epoch[5] Iteration[200/363] Loss: 0.24Epoch[5] Iteration[250/363] Loss: 0.12Epoch[5] Iteration[300/363] Loss: 0.35Epoch[5] Iteration[350/363] Loss: 0.20Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.04Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.15Epoch[6] Iteration[300/363] Loss: 0.23Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.04Epoch[7] Iteration[150/363] Loss: 0.24Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.07Epoch[7] Iteration[300/363] Loss: 0.19Epoch[7] Iteration[350/363] Loss: 0.18Epoch[8] Iteration[50/363] Loss: 0.11Epoch[8] Iteration[100/363] Loss: 0.05Epoch[8] Iteration[150/363] Loss: 0.16Epoch[8] Iteration[200/363] Loss: 0.18Epoch[8] Iteration[250/363] Loss: 0.09Epoch[8] Iteration[300/363] Loss: 0.13Epoch[8] Iteration[350/363] Loss: 0.15Epoch[9] Iteration[50/363] Loss: 0.13Epoch[9] Iteration[100/363] Loss: 0.04Epoch[9] Iteration[150/363] Loss: 0.16Epoch[9] Iteration[200/363] Loss: 0.18Epoch[9] Iteration[250/363] Loss: 0.12Epoch[9] Iteration[300/363] Loss: 0.26Epoch[9] Iteration[350/363] Loss: 0.19Epoch[10] Iteration[50/363] Loss: 0.10Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.13Epoch[10] Iteration[250/363] Loss: 0.07Epoch[10] Iteration[300/363] Loss: 0.10Epoch[10] Iteration[350/363] Loss: 0.14Epoch[11] Iteration[50/363] Loss: 0.17Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.19Epoch[11] Iteration[200/363] Loss: 0.20Epoch[11] Iteration[250/363] Loss: 0.09Epoch[11] Iteration[300/363] Loss: 0.19Epoch[11] Iteration[350/363] Loss: 0.14Epoch[12] Iteration[50/363] Loss: 0.09Epoch[12] Iteration[100/363] Loss: 0.07Epoch[12] Iteration[150/363] Loss: 0.20Epoch[12] Iteration[200/363] Loss: 0.12Epoch[12] Iteration[250/363] Loss: 0.16Epoch[12] Iteration[300/363] Loss: 0.20Epoch[12] Iteration[350/363] Loss: 0.17
======== mobilenet_v2 ========

spatial feature len: 11520, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.16Epoch[1] Iteration[100/363] Loss: 0.12Epoch[1] Iteration[150/363] Loss: 0.26Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.32Epoch[1] Iteration[300/363] Loss: 0.49Epoch[1] Iteration[350/363] Loss: 0.23Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.26Epoch[2] Iteration[200/363] Loss: 0.25Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.45Epoch[2] Iteration[350/363] Loss: 0.21Epoch[3] Iteration[50/363] Loss: 0.18Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.26Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.39Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.18Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.24Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.28Epoch[4] Iteration[300/363] Loss: 0.36Epoch[4] Iteration[350/363] Loss: 0.18Epoch[5] Iteration[50/363] Loss: 0.18Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.24Epoch[5] Iteration[200/363] Loss: 0.21Epoch[5] Iteration[250/363] Loss: 0.18Epoch[5] Iteration[300/363] Loss: 0.33Epoch[5] Iteration[350/363] Loss: 0.19Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.25Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.27Epoch[6] Iteration[350/363] Loss: 0.19Epoch[7] Iteration[50/363] Loss: 0.15Epoch[7] Iteration[100/363] Loss: 0.09Epoch[7] Iteration[150/363] Loss: 0.26Epoch[7] Iteration[200/363] Loss: 0.24Epoch[7] Iteration[250/363] Loss: 0.18Epoch[7] Iteration[300/363] Loss: 0.21Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.18Epoch[8] Iteration[100/363] Loss: 0.16Epoch[8] Iteration[150/363] Loss: 0.23Epoch[8] Iteration[200/363] Loss: 0.21Epoch[8] Iteration[250/363] Loss: 0.15Epoch[8] Iteration[300/363] Loss: 0.22Epoch[8] Iteration[350/363] Loss: 0.15Epoch[9] Iteration[50/363] Loss: 0.16Epoch[9] Iteration[100/363] Loss: 0.17Epoch[9] Iteration[150/363] Loss: 0.25Epoch[9] Iteration[200/363] Loss: 0.29Epoch[9] Iteration[250/363] Loss: 0.18Epoch[9] Iteration[300/363] Loss: 0.20Epoch[9] Iteration[350/363] Loss: 0.13Epoch[10] Iteration[50/363] Loss: 0.12Epoch[10] Iteration[100/363] Loss: 0.06Epoch[10] Iteration[150/363] Loss: 0.24Epoch[10] Iteration[200/363] Loss: 0.17Epoch[10] Iteration[250/363] Loss: 0.15Epoch[10] Iteration[300/363] Loss: 0.19Epoch[10] Iteration[350/363] Loss: 0.14Epoch[11] Iteration[50/363] Loss: 0.13Epoch[11] Iteration[100/363] Loss: 0.09Epoch[11] Iteration[150/363] Loss: 0.22Epoch[11] Iteration[200/363] Loss: 0.20Epoch[11] Iteration[250/363] Loss: 0.12Epoch[11] Iteration[300/363] Loss: 0.21Epoch[11] Iteration[350/363] Loss: 0.16Epoch[12] Iteration[50/363] Loss: 0.12Epoch[12] Iteration[100/363] Loss: 0.10Epoch[12] Iteration[150/363] Loss: 0.22Epoch[12] Iteration[200/363] Loss: 0.18Epoch[12] Iteration[250/363] Loss: 0.09Epoch[12] Iteration[300/363] Loss: 0.15Epoch[12] Iteration[350/363] Loss: 0.17Epoch[13] Iteration[50/363] Loss: 0.11Epoch[13] Iteration[100/363] Loss: 0.13Epoch[13] Iteration[150/363] Loss: 0.19Epoch[13] Iteration[200/363] Loss: 0.12Epoch[13] Iteration[250/363] Loss: 0.12Epoch[13] Iteration[300/363] Loss: 0.06Epoch[13] Iteration[350/363] Loss: 0.18
======== resnet18 ========

spatial feature len: 4608, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.19Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.41Epoch[1] Iteration[200/363] Loss: 0.25Epoch[1] Iteration[250/363] Loss: 0.36Epoch[1] Iteration[300/363] Loss: 0.50Epoch[1] Iteration[350/363] Loss: 0.32Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.30Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.32Epoch[2] Iteration[300/363] Loss: 0.39Epoch[2] Iteration[350/363] Loss: 0.30Epoch[3] Iteration[50/363] Loss: 0.16Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.27Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.22Epoch[3] Iteration[300/363] Loss: 0.41Epoch[3] Iteration[350/363] Loss: 0.27Epoch[4] Iteration[50/363] Loss: 0.15Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.24Epoch[4] Iteration[300/363] Loss: 0.34Epoch[4] Iteration[350/363] Loss: 0.28Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.19Epoch[5] Iteration[200/363] Loss: 0.24Epoch[5] Iteration[250/363] Loss: 0.16Epoch[5] Iteration[300/363] Loss: 0.27Epoch[5] Iteration[350/363] Loss: 0.26Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.12Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.24Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.47Epoch[6] Iteration[350/363] Loss: 0.26Epoch[7] Iteration[50/363] Loss: 0.19Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.16Epoch[7] Iteration[300/363] Loss: 0.31Epoch[7] Iteration[350/363] Loss: 0.25Epoch[8] Iteration[50/363] Loss: 0.12Epoch[8] Iteration[100/363] Loss: 0.12Epoch[8] Iteration[150/363] Loss: 0.18Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.11Epoch[8] Iteration[300/363] Loss: 0.14Epoch[8] Iteration[350/363] Loss: 0.09Epoch[9] Iteration[50/363] Loss: 0.12Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.18Epoch[9] Iteration[200/363] Loss: 0.14Epoch[9] Iteration[250/363] Loss: 0.39Epoch[9] Iteration[300/363] Loss: 0.20Epoch[9] Iteration[350/363] Loss: 0.17Epoch[10] Iteration[50/363] Loss: 0.09Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.09Epoch[10] Iteration[200/363] Loss: 0.15Epoch[10] Iteration[250/363] Loss: 0.14Epoch[10] Iteration[300/363] Loss: 0.28Epoch[10] Iteration[350/363] Loss: 0.23Epoch[11] Iteration[50/363] Loss: 0.13Epoch[11] Iteration[100/363] Loss: 0.14Epoch[11] Iteration[150/363] Loss: 0.10Epoch[11] Iteration[200/363] Loss: 0.12Epoch[11] Iteration[250/363] Loss: 0.06Epoch[11] Iteration[300/363] Loss: 0.18Epoch[11] Iteration[350/363] Loss: 0.09Epoch[12] Iteration[50/363] Loss: 0.09Epoch[12] Iteration[100/363] Loss: 0.07Epoch[12] Iteration[150/363] Loss: 0.07Epoch[12] Iteration[200/363] Loss: 0.08Epoch[12] Iteration[250/363] Loss: 0.24Epoch[12] Iteration[300/363] Loss: 0.16Epoch[12] Iteration[350/363] Loss: 0.16Epoch[13] Iteration[50/363] Loss: 0.14Epoch[13] Iteration[100/363] Loss: 0.09Epoch[13] Iteration[150/363] Loss: 0.06Epoch[13] Iteration[200/363] Loss: 0.05Epoch[13] Iteration[250/363] Loss: 0.06Epoch[13] Iteration[300/363] Loss: 0.16Epoch[13] Iteration[350/363] Loss: 0.10
======== resnet50 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.17Epoch[1] Iteration[100/363] Loss: 0.17Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.25Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.49Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.15Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.20Epoch[2] Iteration[250/363] Loss: 0.25Epoch[2] Iteration[300/363] Loss: 0.30Epoch[2] Iteration[350/363] Loss: 0.29Epoch[3] Iteration[50/363] Loss: 0.13Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.22Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.18Epoch[3] Iteration[300/363] Loss: 0.28Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.10Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.17Epoch[4] Iteration[250/363] Loss: 0.26Epoch[4] Iteration[300/363] Loss: 0.26Epoch[4] Iteration[350/363] Loss: 0.20Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.18Epoch[5] Iteration[200/363] Loss: 0.15Epoch[5] Iteration[250/363] Loss: 0.15Epoch[5] Iteration[300/363] Loss: 0.31Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.13Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.11Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.13Epoch[6] Iteration[350/363] Loss: 0.17Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.18Epoch[7] Iteration[200/363] Loss: 0.12Epoch[7] Iteration[250/363] Loss: 0.32Epoch[7] Iteration[300/363] Loss: 0.26Epoch[7] Iteration[350/363] Loss: 0.17Epoch[8] Iteration[50/363] Loss: 0.07Epoch[8] Iteration[100/363] Loss: 0.19Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.16Epoch[8] Iteration[250/363] Loss: 0.16Epoch[8] Iteration[300/363] Loss: 0.23Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.05Epoch[9] Iteration[100/363] Loss: 0.11Epoch[9] Iteration[150/363] Loss: 0.17Epoch[9] Iteration[200/363] Loss: 0.10Epoch[9] Iteration[250/363] Loss: 0.17Epoch[9] Iteration[300/363] Loss: 0.08Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.14Epoch[10] Iteration[100/363] Loss: 0.11Epoch[10] Iteration[150/363] Loss: 0.16Epoch[10] Iteration[200/363] Loss: 0.06Epoch[10] Iteration[250/363] Loss: 0.12Epoch[10] Iteration[300/363] Loss: 0.23Epoch[10] Iteration[350/363] Loss: 0.16Epoch[11] Iteration[50/363] Loss: 0.20Epoch[11] Iteration[100/363] Loss: 0.09Epoch[11] Iteration[150/363] Loss: 0.16Epoch[11] Iteration[200/363] Loss: 0.07Epoch[11] Iteration[250/363] Loss: 0.17Epoch[11] Iteration[300/363] Loss: 0.15Epoch[11] Iteration[350/363] Loss: 0.20Epoch[12] Iteration[50/363] Loss: 0.06Epoch[12] Iteration[100/363] Loss: 0.08Epoch[12] Iteration[150/363] Loss: 0.12Epoch[12] Iteration[200/363] Loss: 0.04Epoch[12] Iteration[250/363] Loss: 0.08Epoch[12] Iteration[300/363] Loss: 0.12Epoch[12] Iteration[350/363] Loss: 0.20
======== resnet152 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.19Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.32Epoch[1] Iteration[200/363] Loss: 0.30Epoch[1] Iteration[250/363] Loss: 0.27Epoch[1] Iteration[300/363] Loss: 0.56Epoch[1] Iteration[350/363] Loss: 0.26Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.15Epoch[2] Iteration[150/363] Loss: 0.31Epoch[2] Iteration[200/363] Loss: 0.21Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.44Epoch[2] Iteration[350/363] Loss: 0.19Epoch[3] Iteration[50/363] Loss: 0.12Epoch[3] Iteration[100/363] Loss: 0.15Epoch[3] Iteration[150/363] Loss: 0.25Epoch[3] Iteration[200/363] Loss: 0.16Epoch[3] Iteration[250/363] Loss: 0.18Epoch[3] Iteration[300/363] Loss: 0.38Epoch[3] Iteration[350/363] Loss: 0.16Epoch[4] Iteration[50/363] Loss: 0.11Epoch[4] Iteration[100/363] Loss: 0.17Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.14Epoch[4] Iteration[250/363] Loss: 0.27Epoch[4] Iteration[300/363] Loss: 0.35Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.14Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.15Epoch[5] Iteration[200/363] Loss: 0.16Epoch[5] Iteration[250/363] Loss: 0.15Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.14Epoch[6] Iteration[50/363] Loss: 0.09Epoch[6] Iteration[100/363] Loss: 0.09Epoch[6] Iteration[150/363] Loss: 0.24Epoch[6] Iteration[200/363] Loss: 0.15Epoch[6] Iteration[250/363] Loss: 0.09Epoch[6] Iteration[300/363] Loss: 0.38Epoch[6] Iteration[350/363] Loss: 0.14Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.15Epoch[7] Iteration[200/363] Loss: 0.12Epoch[7] Iteration[250/363] Loss: 0.15Epoch[7] Iteration[300/363] Loss: 0.28Epoch[7] Iteration[350/363] Loss: 0.08Epoch[8] Iteration[50/363] Loss: 0.08Epoch[8] Iteration[100/363] Loss: 0.13Epoch[8] Iteration[150/363] Loss: 0.21Epoch[8] Iteration[200/363] Loss: 0.11Epoch[8] Iteration[250/363] Loss: 0.05Epoch[8] Iteration[300/363] Loss: 0.08Epoch[8] Iteration[350/363] Loss: 0.11Epoch[9] Iteration[50/363] Loss: 0.11Epoch[9] Iteration[100/363] Loss: 0.14Epoch[9] Iteration[150/363] Loss: 0.12Epoch[9] Iteration[200/363] Loss: 0.08Epoch[9] Iteration[250/363] Loss: 0.22Epoch[9] Iteration[300/363] Loss: 0.19Epoch[9] Iteration[350/363] Loss: 0.13Epoch[10] Iteration[50/363] Loss: 0.10Epoch[10] Iteration[100/363] Loss: 0.09Epoch[10] Iteration[150/363] Loss: 0.12Epoch[10] Iteration[200/363] Loss: 0.07Epoch[10] Iteration[250/363] Loss: 0.09Epoch[10] Iteration[300/363] Loss: 0.06Epoch[10] Iteration[350/363] Loss: 0.13Epoch[11] Iteration[50/363] Loss: 0.07Epoch[11] Iteration[100/363] Loss: 0.02Epoch[11] Iteration[150/363] Loss: 0.17Epoch[11] Iteration[200/363] Loss: 0.21Epoch[11] Iteration[250/363] Loss: 0.19Epoch[11] Iteration[300/363] Loss: 0.19Epoch[11] Iteration[350/363] Loss: 0.28Epoch[12] Iteration[50/363] Loss: 0.09Epoch[12] Iteration[100/363] Loss: 0.01Epoch[12] Iteration[150/363] Loss: 0.22Epoch[12] Iteration[200/363] Loss: 0.04Epoch[12] Iteration[250/363] Loss: 0.06Epoch[12] Iteration[300/363] Loss: 0.11Epoch[12] Iteration[350/363] Loss: 0.04Epoch[13] Iteration[50/363] Loss: 0.04Epoch[13] Iteration[100/363] Loss: 0.01Epoch[13] Iteration[150/363] Loss: 0.12Epoch[13] Iteration[200/363] Loss: 0.11Epoch[13] Iteration[250/363] Loss: 0.13Epoch[13] Iteration[300/363] Loss: 0.07Epoch[13] Iteration[350/363] Loss: 0.02Epoch[14] Iteration[50/363] Loss: 0.03Epoch[14] Iteration[100/363] Loss: 0.01Epoch[14] Iteration[150/363] Loss: 0.08Epoch[14] Iteration[200/363] Loss: 0.09Epoch[14] Iteration[250/363] Loss: 0.07Epoch[14] Iteration[300/363] Loss: 0.16Epoch[14] Iteration[350/363] Loss: 0.22Epoch[15] Iteration[50/363] Loss: 0.02Epoch[15] Iteration[100/363] Loss: 0.03Epoch[15] Iteration[150/363] Loss: 0.12Epoch[15] Iteration[200/363] Loss: 0.03Epoch[15] Iteration[250/363] Loss: 0.11Epoch[15] Iteration[300/363] Loss: 0.12Epoch[15] Iteration[350/363] Loss: 0.02Epoch[16] Iteration[50/363] Loss: 0.01Epoch[16] Iteration[100/363] Loss: 0.01Epoch[16] Iteration[150/363] Loss: 0.05Epoch[16] Iteration[200/363] Loss: 0.07Epoch[16] Iteration[250/363] Loss: 0.03Epoch[16] Iteration[300/363] Loss: 0.07Epoch[16] Iteration[350/363] Loss: 0.07
======== resnext50_32x4d ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.20Epoch[1] Iteration[100/363] Loss: 0.16Epoch[1] Iteration[150/363] Loss: 0.26Epoch[1] Iteration[200/363] Loss: 0.33Epoch[1] Iteration[250/363] Loss: 0.33Epoch[1] Iteration[300/363] Loss: 0.39Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.14Epoch[2] Iteration[150/363] Loss: 0.26Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.23Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.27Epoch[3] Iteration[50/363] Loss: 0.16Epoch[3] Iteration[100/363] Loss: 0.11Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.29Epoch[3] Iteration[350/363] Loss: 0.24Epoch[4] Iteration[50/363] Loss: 0.12Epoch[4] Iteration[100/363] Loss: 0.11Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.18Epoch[4] Iteration[300/363] Loss: 0.26Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.20Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.28Epoch[5] Iteration[250/363] Loss: 0.15Epoch[5] Iteration[300/363] Loss: 0.19Epoch[5] Iteration[350/363] Loss: 0.21Epoch[6] Iteration[50/363] Loss: 0.13Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.20Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.23Epoch[6] Iteration[300/363] Loss: 0.25Epoch[6] Iteration[350/363] Loss: 0.14Epoch[7] Iteration[50/363] Loss: 0.16Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.30Epoch[7] Iteration[200/363] Loss: 0.21Epoch[7] Iteration[250/363] Loss: 0.11Epoch[7] Iteration[300/363] Loss: 0.18Epoch[7] Iteration[350/363] Loss: 0.13Epoch[8] Iteration[50/363] Loss: 0.15Epoch[8] Iteration[100/363] Loss: 0.06Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.13Epoch[8] Iteration[250/363] Loss: 0.24Epoch[8] Iteration[300/363] Loss: 0.19Epoch[8] Iteration[350/363] Loss: 0.20Epoch[9] Iteration[50/363] Loss: 0.16Epoch[9] Iteration[100/363] Loss: 0.04Epoch[9] Iteration[150/363] Loss: 0.20Epoch[9] Iteration[200/363] Loss: 0.14Epoch[9] Iteration[250/363] Loss: 0.07Epoch[9] Iteration[300/363] Loss: 0.38Epoch[9] Iteration[350/363] Loss: 0.16Epoch[10] Iteration[50/363] Loss: 0.08Epoch[10] Iteration[100/363] Loss: 0.02Epoch[10] Iteration[150/363] Loss: 0.21Epoch[10] Iteration[200/363] Loss: 0.23Epoch[10] Iteration[250/363] Loss: 0.13Epoch[10] Iteration[300/363] Loss: 0.21Epoch[10] Iteration[350/363] Loss: 0.18Epoch[11] Iteration[50/363] Loss: 0.09Epoch[11] Iteration[100/363] Loss: 0.06Epoch[11] Iteration[150/363] Loss: 0.18Epoch[11] Iteration[200/363] Loss: 0.14Epoch[11] Iteration[250/363] Loss: 0.14Epoch[11] Iteration[300/363] Loss: 0.22Epoch[11] Iteration[350/363] Loss: 0.13Epoch[12] Iteration[50/363] Loss: 0.09Epoch[12] Iteration[100/363] Loss: 0.02Epoch[12] Iteration[150/363] Loss: 0.32Epoch[12] Iteration[200/363] Loss: 0.08Epoch[12] Iteration[250/363] Loss: 0.05Epoch[12] Iteration[300/363] Loss: 0.10Epoch[12] Iteration[350/363] Loss: 0.13Epoch[13] Iteration[50/363] Loss: 0.12Epoch[13] Iteration[100/363] Loss: 0.02Epoch[13] Iteration[150/363] Loss: 0.26Epoch[13] Iteration[200/363] Loss: 0.08Epoch[13] Iteration[250/363] Loss: 0.02Epoch[13] Iteration[300/363] Loss: 0.17Epoch[13] Iteration[350/363] Loss: 0.20
======== wide_resnet50_2 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.35Epoch[1] Iteration[100/363] Loss: 0.12Epoch[1] Iteration[150/363] Loss: 0.38Epoch[1] Iteration[200/363] Loss: 0.33Epoch[1] Iteration[250/363] Loss: 0.34Epoch[1] Iteration[300/363] Loss: 0.44Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.29Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.42Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.13Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.19Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.33Epoch[3] Iteration[350/363] Loss: 0.25Epoch[4] Iteration[50/363] Loss: 0.12Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.25Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.22Epoch[4] Iteration[300/363] Loss: 0.36Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.19Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.14Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.29Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.14Epoch[6] Iteration[100/363] Loss: 0.05Epoch[6] Iteration[150/363] Loss: 0.17Epoch[6] Iteration[200/363] Loss: 0.16Epoch[6] Iteration[250/363] Loss: 0.20Epoch[6] Iteration[300/363] Loss: 0.24Epoch[6] Iteration[350/363] Loss: 0.14Epoch[7] Iteration[50/363] Loss: 0.14Epoch[7] Iteration[100/363] Loss: 0.07Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.14Epoch[7] Iteration[300/363] Loss: 0.32Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.12Epoch[8] Iteration[100/363] Loss: 0.13Epoch[8] Iteration[150/363] Loss: 0.18Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.13Epoch[8] Iteration[300/363] Loss: 0.19Epoch[8] Iteration[350/363] Loss: 0.27Epoch[9] Iteration[50/363] Loss: 0.09Epoch[9] Iteration[100/363] Loss: 0.06Epoch[9] Iteration[150/363] Loss: 0.11Epoch[9] Iteration[200/363] Loss: 0.12Epoch[9] Iteration[250/363] Loss: 0.10Epoch[9] Iteration[300/363] Loss: 0.18Epoch[9] Iteration[350/363] Loss: 0.14Epoch[10] Iteration[50/363] Loss: 0.09Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.09Epoch[10] Iteration[200/363] Loss: 0.15Epoch[10] Iteration[250/363] Loss: 0.11Epoch[10] Iteration[300/363] Loss: 0.21Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.07Epoch[11] Iteration[100/363] Loss: 0.11Epoch[11] Iteration[150/363] Loss: 0.11Epoch[11] Iteration[200/363] Loss: 0.07Epoch[11] Iteration[250/363] Loss: 0.13Epoch[11] Iteration[300/363] Loss: 0.27Epoch[11] Iteration[350/363] Loss: 0.22No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== alexnet ========

spatial feature len: 256, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.37Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.34Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.29Epoch[2] Iteration[100/363] Loss: 0.09Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.22Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.18Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.24Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.21Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.15Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.20Epoch[7] Iteration[200/363] Loss: 0.21Epoch[7] Iteration[250/363] Loss: 0.21Epoch[7] Iteration[300/363] Loss: 0.18Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.15Epoch[8] Iteration[100/363] Loss: 0.10Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.19Epoch[8] Iteration[300/363] Loss: 0.18Epoch[8] Iteration[350/363] Loss: 0.14Epoch[9] Iteration[50/363] Loss: 0.16Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.19Epoch[9] Iteration[200/363] Loss: 0.20Epoch[9] Iteration[250/363] Loss: 0.19Epoch[9] Iteration[300/363] Loss: 0.16Epoch[9] Iteration[350/363] Loss: 0.13Epoch[10] Iteration[50/363] Loss: 0.17Epoch[10] Iteration[100/363] Loss: 0.09Epoch[10] Iteration[150/363] Loss: 0.18Epoch[10] Iteration[200/363] Loss: 0.19Epoch[10] Iteration[250/363] Loss: 0.18Epoch[10] Iteration[300/363] Loss: 0.17Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.17Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.18Epoch[11] Iteration[200/363] Loss: 0.18Epoch[11] Iteration[250/363] Loss: 0.17Epoch[11] Iteration[300/363] Loss: 0.17Epoch[11] Iteration[350/363] Loss: 0.13
======== vgg11 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.52Epoch[1] Iteration[100/363] Loss: 0.10Epoch[1] Iteration[150/363] Loss: 0.33Epoch[1] Iteration[200/363] Loss: 0.29Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.31Epoch[1] Iteration[350/363] Loss: 0.24Epoch[2] Iteration[50/363] Loss: 0.21Epoch[2] Iteration[100/363] Loss: 0.07Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.27Epoch[2] Iteration[250/363] Loss: 0.25Epoch[2] Iteration[300/363] Loss: 0.30Epoch[2] Iteration[350/363] Loss: 0.21Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.22Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.16Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.30Epoch[4] Iteration[350/363] Loss: 0.16Epoch[5] Iteration[50/363] Loss: 0.17Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.22Epoch[5] Iteration[200/363] Loss: 0.19Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.29Epoch[5] Iteration[350/363] Loss: 0.14Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.22Epoch[6] Iteration[200/363] Loss: 0.18Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.26Epoch[6] Iteration[350/363] Loss: 0.13Epoch[7] Iteration[50/363] Loss: 0.15Epoch[7] Iteration[100/363] Loss: 0.11Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.17Epoch[7] Iteration[250/363] Loss: 0.20Epoch[7] Iteration[300/363] Loss: 0.26Epoch[7] Iteration[350/363] Loss: 0.13Epoch[8] Iteration[50/363] Loss: 0.14Epoch[8] Iteration[100/363] Loss: 0.11Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.15Epoch[8] Iteration[250/363] Loss: 0.18Epoch[8] Iteration[300/363] Loss: 0.24Epoch[8] Iteration[350/363] Loss: 0.15Epoch[9] Iteration[50/363] Loss: 0.17Epoch[9] Iteration[100/363] Loss: 0.12Epoch[9] Iteration[150/363] Loss: 0.22Epoch[9] Iteration[200/363] Loss: 0.14Epoch[9] Iteration[250/363] Loss: 0.18Epoch[9] Iteration[300/363] Loss: 0.21Epoch[9] Iteration[350/363] Loss: 0.17Epoch[10] Iteration[50/363] Loss: 0.18Epoch[10] Iteration[100/363] Loss: 0.08Epoch[10] Iteration[150/363] Loss: 0.20Epoch[10] Iteration[200/363] Loss: 0.18Epoch[10] Iteration[250/363] Loss: 0.19Epoch[10] Iteration[300/363] Loss: 0.15Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.14Epoch[11] Iteration[100/363] Loss: 0.12Epoch[11] Iteration[150/363] Loss: 0.20Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.14Epoch[11] Iteration[300/363] Loss: 0.20Epoch[11] Iteration[350/363] Loss: 0.10
======== vgg16 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.35Epoch[1] Iteration[100/363] Loss: 0.27Epoch[1] Iteration[150/363] Loss: 0.52Epoch[1] Iteration[200/363] Loss: 0.22Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.32Epoch[1] Iteration[350/363] Loss: 0.24Epoch[2] Iteration[50/363] Loss: 0.21Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.25Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.28Epoch[2] Iteration[350/363] Loss: 0.21Epoch[3] Iteration[50/363] Loss: 0.21Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.22Epoch[3] Iteration[200/363] Loss: 0.19Epoch[3] Iteration[250/363] Loss: 0.26Epoch[3] Iteration[300/363] Loss: 0.39Epoch[3] Iteration[350/363] Loss: 0.18Epoch[4] Iteration[50/363] Loss: 0.20Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.24Epoch[4] Iteration[200/363] Loss: 0.18Epoch[4] Iteration[250/363] Loss: 0.25Epoch[4] Iteration[300/363] Loss: 0.27Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.19Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.24Epoch[5] Iteration[200/363] Loss: 0.18Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.39Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.17Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.20Epoch[6] Iteration[200/363] Loss: 0.24Epoch[6] Iteration[250/363] Loss: 0.25Epoch[6] Iteration[300/363] Loss: 0.32Epoch[6] Iteration[350/363] Loss: 0.17Epoch[7] Iteration[50/363] Loss: 0.17Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.24Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.23Epoch[7] Iteration[300/363] Loss: 0.24Epoch[7] Iteration[350/363] Loss: 0.15Epoch[8] Iteration[50/363] Loss: 0.15Epoch[8] Iteration[100/363] Loss: 0.04Epoch[8] Iteration[150/363] Loss: 0.15Epoch[8] Iteration[200/363] Loss: 0.13Epoch[8] Iteration[250/363] Loss: 0.23Epoch[8] Iteration[300/363] Loss: 0.32Epoch[8] Iteration[350/363] Loss: 0.16Epoch[9] Iteration[50/363] Loss: 0.19Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.17Epoch[9] Iteration[200/363] Loss: 0.16Epoch[9] Iteration[250/363] Loss: 0.23Epoch[9] Iteration[300/363] Loss: 0.25Epoch[9] Iteration[350/363] Loss: 0.11Epoch[10] Iteration[50/363] Loss: 0.17Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.17Epoch[10] Iteration[200/363] Loss: 0.34Epoch[10] Iteration[250/363] Loss: 0.21Epoch[10] Iteration[300/363] Loss: 0.23Epoch[10] Iteration[350/363] Loss: 0.10Epoch[11] Iteration[50/363] Loss: 0.14Epoch[11] Iteration[100/363] Loss: 0.17Epoch[11] Iteration[150/363] Loss: 0.17Epoch[11] Iteration[200/363] Loss: 0.20Epoch[11] Iteration[250/363] Loss: 0.27Epoch[11] Iteration[300/363] Loss: 0.20Epoch[11] Iteration[350/363] Loss: 0.10Epoch[12] Iteration[50/363] Loss: 0.22Epoch[12] Iteration[100/363] Loss: 0.05Epoch[12] Iteration[150/363] Loss: 0.22Epoch[12] Iteration[200/363] Loss: 0.15Epoch[12] Iteration[250/363] Loss: 0.22Epoch[12] Iteration[300/363] Loss: 0.17Epoch[12] Iteration[350/363] Loss: 0.06Epoch[13] Iteration[50/363] Loss: 0.14Epoch[13] Iteration[100/363] Loss: 0.14Epoch[13] Iteration[150/363] Loss: 0.19Epoch[13] Iteration[200/363] Loss: 0.11Epoch[13] Iteration[250/363] Loss: 0.18Epoch[13] Iteration[300/363] Loss: 0.19Epoch[13] Iteration[350/363] Loss: 0.10Epoch[14] Iteration[50/363] Loss: 0.19Epoch[14] Iteration[100/363] Loss: 0.05Epoch[14] Iteration[150/363] Loss: 0.15Epoch[14] Iteration[200/363] Loss: 0.14Epoch[14] Iteration[250/363] Loss: 0.20Epoch[14] Iteration[300/363] Loss: 0.28Epoch[14] Iteration[350/363] Loss: 0.07Epoch[15] Iteration[50/363] Loss: 0.13Epoch[15] Iteration[100/363] Loss: 0.03Epoch[15] Iteration[150/363] Loss: 0.15Epoch[15] Iteration[200/363] Loss: 0.09Epoch[15] Iteration[250/363] Loss: 0.31Epoch[15] Iteration[300/363] Loss: 0.16Epoch[15] Iteration[350/363] Loss: 0.09Epoch[16] Iteration[50/363] Loss: 0.05Epoch[16] Iteration[100/363] Loss: 0.03Epoch[16] Iteration[150/363] Loss: 0.17Epoch[16] Iteration[200/363] Loss: 0.13Epoch[16] Iteration[250/363] Loss: 0.22Epoch[16] Iteration[300/363] Loss: 0.13Epoch[16] Iteration[350/363] Loss: 0.08
======== squeezenet1_1 ========

spatial feature len: 8192, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.67Epoch[1] Iteration[100/363] Loss: 0.66Epoch[1] Iteration[150/363] Loss: 0.66Epoch[1] Iteration[200/363] Loss: 0.64Epoch[1] Iteration[250/363] Loss: 0.54Epoch[1] Iteration[300/363] Loss: 0.54Epoch[1] Iteration[350/363] Loss: 0.44Epoch[2] Iteration[50/363] Loss: 0.42Epoch[2] Iteration[100/363] Loss: 0.17Epoch[2] Iteration[150/363] Loss: 0.21Epoch[2] Iteration[200/363] Loss: 0.30Epoch[2] Iteration[250/363] Loss: 0.37Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.39Epoch[3] Iteration[50/363] Loss: 0.31Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.18Epoch[3] Iteration[200/363] Loss: 0.30Epoch[3] Iteration[250/363] Loss: 0.37Epoch[3] Iteration[300/363] Loss: 0.41Epoch[3] Iteration[350/363] Loss: 0.35Epoch[4] Iteration[50/363] Loss: 0.25Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.19Epoch[4] Iteration[200/363] Loss: 0.27Epoch[4] Iteration[250/363] Loss: 0.31Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.31Epoch[5] Iteration[50/363] Loss: 0.24Epoch[5] Iteration[100/363] Loss: 0.11Epoch[5] Iteration[150/363] Loss: 0.23Epoch[5] Iteration[200/363] Loss: 0.25Epoch[5] Iteration[250/363] Loss: 0.29Epoch[5] Iteration[300/363] Loss: 0.27Epoch[5] Iteration[350/363] Loss: 0.29Epoch[6] Iteration[50/363] Loss: 0.20Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.22Epoch[6] Iteration[200/363] Loss: 0.26Epoch[6] Iteration[250/363] Loss: 0.29Epoch[6] Iteration[300/363] Loss: 0.25Epoch[6] Iteration[350/363] Loss: 0.22Epoch[7] Iteration[50/363] Loss: 0.19Epoch[7] Iteration[100/363] Loss: 0.11Epoch[7] Iteration[150/363] Loss: 0.21Epoch[7] Iteration[200/363] Loss: 0.31Epoch[7] Iteration[250/363] Loss: 0.26Epoch[7] Iteration[300/363] Loss: 0.23Epoch[7] Iteration[350/363] Loss: 0.25Epoch[8] Iteration[50/363] Loss: 0.18Epoch[8] Iteration[100/363] Loss: 0.10Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.28Epoch[8] Iteration[250/363] Loss: 0.25Epoch[8] Iteration[300/363] Loss: 0.21Epoch[8] Iteration[350/363] Loss: 0.23Epoch[9] Iteration[50/363] Loss: 0.20Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.21Epoch[9] Iteration[200/363] Loss: 0.29Epoch[9] Iteration[250/363] Loss: 0.27Epoch[9] Iteration[300/363] Loss: 0.22Epoch[9] Iteration[350/363] Loss: 0.24Epoch[10] Iteration[50/363] Loss: 0.21Epoch[10] Iteration[100/363] Loss: 0.09Epoch[10] Iteration[150/363] Loss: 0.20Epoch[10] Iteration[200/363] Loss: 0.25Epoch[10] Iteration[250/363] Loss: 0.28Epoch[10] Iteration[300/363] Loss: 0.21Epoch[10] Iteration[350/363] Loss: 0.20Epoch[11] Iteration[50/363] Loss: 0.19Epoch[11] Iteration[100/363] Loss: 0.10Epoch[11] Iteration[150/363] Loss: 0.21Epoch[11] Iteration[200/363] Loss: 0.23Epoch[11] Iteration[250/363] Loss: 0.22Epoch[11] Iteration[300/363] Loss: 0.18Epoch[11] Iteration[350/363] Loss: 0.19Epoch[12] Iteration[50/363] Loss: 0.17Epoch[12] Iteration[100/363] Loss: 0.08Epoch[12] Iteration[150/363] Loss: 0.20Epoch[12] Iteration[200/363] Loss: 0.22Epoch[12] Iteration[250/363] Loss: 0.20Epoch[12] Iteration[300/363] Loss: 0.20Epoch[12] Iteration[350/363] Loss: 0.17Epoch[13] Iteration[50/363] Loss: 0.21Epoch[13] Iteration[100/363] Loss: 0.09Epoch[13] Iteration[150/363] Loss: 0.22Epoch[13] Iteration[200/363] Loss: 0.22Epoch[13] Iteration[250/363] Loss: 0.21Epoch[13] Iteration[300/363] Loss: 0.18Epoch[13] Iteration[350/363] Loss: 0.18Epoch[14] Iteration[50/363] Loss: 0.22Epoch[14] Iteration[100/363] Loss: 0.09Epoch[14] Iteration[150/363] Loss: 0.19Epoch[14] Iteration[200/363] Loss: 0.23Epoch[14] Iteration[250/363] Loss: 0.20Epoch[14] Iteration[300/363] Loss: 0.21Epoch[14] Iteration[350/363] Loss: 0.16Epoch[15] Iteration[50/363] Loss: 0.19Epoch[15] Iteration[100/363] Loss: 0.11Epoch[15] Iteration[150/363] Loss: 0.19Epoch[15] Iteration[200/363] Loss: 0.20Epoch[15] Iteration[250/363] Loss: 0.20Epoch[15] Iteration[300/363] Loss: 0.20Epoch[15] Iteration[350/363] Loss: 0.16Epoch[16] Iteration[50/363] Loss: 0.21Epoch[16] Iteration[100/363] Loss: 0.09Epoch[16] Iteration[150/363] Loss: 0.18Epoch[16] Iteration[200/363] Loss: 0.20Epoch[16] Iteration[250/363] Loss: 0.18Epoch[16] Iteration[300/363] Loss: 0.22Epoch[16] Iteration[350/363] Loss: 0.15Epoch[17] Iteration[50/363] Loss: 0.19Epoch[17] Iteration[100/363] Loss: 0.10Epoch[17] Iteration[150/363] Loss: 0.19Epoch[17] Iteration[200/363] Loss: 0.19Epoch[17] Iteration[250/363] Loss: 0.18Epoch[17] Iteration[300/363] Loss: 0.24Epoch[17] Iteration[350/363] Loss: 0.17Epoch[18] Iteration[50/363] Loss: 0.21Epoch[18] Iteration[100/363] Loss: 0.10Epoch[18] Iteration[150/363] Loss: 0.16Epoch[18] Iteration[200/363] Loss: 0.21Epoch[18] Iteration[250/363] Loss: 0.18Epoch[18] Iteration[300/363] Loss: 0.20Epoch[18] Iteration[350/363] Loss: 0.16Epoch[19] Iteration[50/363] Loss: 0.19Epoch[19] Iteration[100/363] Loss: 0.09Epoch[19] Iteration[150/363] Loss: 0.14Epoch[19] Iteration[200/363] Loss: 0.19Epoch[19] Iteration[250/363] Loss: 0.17Epoch[19] Iteration[300/363] Loss: 0.17Epoch[19] Iteration[350/363] Loss: 0.20Epoch[20] Iteration[50/363] Loss: 0.19Epoch[20] Iteration[100/363] Loss: 0.10Epoch[20] Iteration[150/363] Loss: 0.13Epoch[20] Iteration[200/363] Loss: 0.19Epoch[20] Iteration[250/363] Loss: 0.16Epoch[20] Iteration[300/363] Loss: 0.18Epoch[20] Iteration[350/363] Loss: 0.15
======== densenet121 ========

spatial feature len: 4096, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.22Epoch[1] Iteration[100/363] Loss: 0.15Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.25Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.44Epoch[1] Iteration[350/363] Loss: 0.30Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.23Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.20Epoch[2] Iteration[300/363] Loss: 0.42Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.13Epoch[3] Iteration[100/363] Loss: 0.09Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.22Epoch[3] Iteration[300/363] Loss: 0.31Epoch[3] Iteration[350/363] Loss: 0.24Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.25Epoch[4] Iteration[250/363] Loss: 0.18Epoch[4] Iteration[300/363] Loss: 0.30Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.25Epoch[5] Iteration[200/363] Loss: 0.26Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.34Epoch[5] Iteration[350/363] Loss: 0.20Epoch[6] Iteration[50/363] Loss: 0.14Epoch[6] Iteration[100/363] Loss: 0.05Epoch[6] Iteration[150/363] Loss: 0.24Epoch[6] Iteration[200/363] Loss: 0.24Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.25Epoch[6] Iteration[350/363] Loss: 0.17Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.08Epoch[7] Iteration[150/363] Loss: 0.21Epoch[7] Iteration[200/363] Loss: 0.24Epoch[7] Iteration[250/363] Loss: 0.18Epoch[7] Iteration[300/363] Loss: 0.27Epoch[7] Iteration[350/363] Loss: 0.20Epoch[8] Iteration[50/363] Loss: 0.12Epoch[8] Iteration[100/363] Loss: 0.04Epoch[8] Iteration[150/363] Loss: 0.17Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.19Epoch[8] Iteration[300/363] Loss: 0.34Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.12Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.17Epoch[9] Iteration[200/363] Loss: 0.17Epoch[9] Iteration[250/363] Loss: 0.16Epoch[9] Iteration[300/363] Loss: 0.36Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.26Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.15Epoch[10] Iteration[200/363] Loss: 0.19Epoch[10] Iteration[250/363] Loss: 0.14Epoch[10] Iteration[300/363] Loss: 0.21Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.12Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.15Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.12Epoch[11] Iteration[300/363] Loss: 0.28Epoch[11] Iteration[350/363] Loss: 0.13Epoch[12] Iteration[50/363] Loss: 0.09Epoch[12] Iteration[100/363] Loss: 0.15Epoch[12] Iteration[150/363] Loss: 0.13Epoch[12] Iteration[200/363] Loss: 0.20Epoch[12] Iteration[250/363] Loss: 0.11Epoch[12] Iteration[300/363] Loss: 0.24Epoch[12] Iteration[350/363] Loss: 0.15
======== densenet201 ========

spatial feature len: 7680, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.23Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.29Epoch[1] Iteration[200/363] Loss: 0.23Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.49Epoch[1] Iteration[350/363] Loss: 0.30Epoch[2] Iteration[50/363] Loss: 0.20Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.25Epoch[2] Iteration[300/363] Loss: 0.38Epoch[2] Iteration[350/363] Loss: 0.25Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.19Epoch[3] Iteration[300/363] Loss: 0.33Epoch[3] Iteration[350/363] Loss: 0.23Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.11Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.19Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.36Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.14Epoch[5] Iteration[100/363] Loss: 0.07Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.19Epoch[5] Iteration[250/363] Loss: 0.16Epoch[5] Iteration[300/363] Loss: 0.27Epoch[5] Iteration[350/363] Loss: 0.28Epoch[6] Iteration[50/363] Loss: 0.13Epoch[6] Iteration[100/363] Loss: 0.06Epoch[6] Iteration[150/363] Loss: 0.25Epoch[6] Iteration[200/363] Loss: 0.19Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.22Epoch[6] Iteration[350/363] Loss: 0.14Epoch[7] Iteration[50/363] Loss: 0.13Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.20Epoch[7] Iteration[250/363] Loss: 0.11Epoch[7] Iteration[300/363] Loss: 0.24Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.10Epoch[8] Iteration[100/363] Loss: 0.07Epoch[8] Iteration[150/363] Loss: 0.22Epoch[8] Iteration[200/363] Loss: 0.20Epoch[8] Iteration[250/363] Loss: 0.17Epoch[8] Iteration[300/363] Loss: 0.23Epoch[8] Iteration[350/363] Loss: 0.21Epoch[9] Iteration[50/363] Loss: 0.20Epoch[9] Iteration[100/363] Loss: 0.15Epoch[9] Iteration[150/363] Loss: 0.20Epoch[9] Iteration[200/363] Loss: 0.21Epoch[9] Iteration[250/363] Loss: 0.14Epoch[9] Iteration[300/363] Loss: 0.23Epoch[9] Iteration[350/363] Loss: 0.16Epoch[10] Iteration[50/363] Loss: 0.17Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.15Epoch[10] Iteration[250/363] Loss: 0.11Epoch[10] Iteration[300/363] Loss: 0.31Epoch[10] Iteration[350/363] Loss: 0.17Epoch[11] Iteration[50/363] Loss: 0.10Epoch[11] Iteration[100/363] Loss: 0.09Epoch[11] Iteration[150/363] Loss: 0.16Epoch[11] Iteration[200/363] Loss: 0.15Epoch[11] Iteration[250/363] Loss: 0.05Epoch[11] Iteration[300/363] Loss: 0.15Epoch[11] Iteration[350/363] Loss: 0.14Epoch[12] Iteration[50/363] Loss: 0.17Epoch[12] Iteration[100/363] Loss: 0.04Epoch[12] Iteration[150/363] Loss: 0.18Epoch[12] Iteration[200/363] Loss: 0.14Epoch[12] Iteration[250/363] Loss: 0.10Epoch[12] Iteration[300/363] Loss: 0.15Epoch[12] Iteration[350/363] Loss: 0.15
======== mobilenet_v2 ========

spatial feature len: 11520, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.18Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.20Epoch[1] Iteration[200/363] Loss: 0.31Epoch[1] Iteration[250/363] Loss: 0.35Epoch[1] Iteration[300/363] Loss: 0.46Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.18Epoch[2] Iteration[100/363] Loss: 0.12Epoch[2] Iteration[150/363] Loss: 0.25Epoch[2] Iteration[200/363] Loss: 0.28Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.47Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.14Epoch[3] Iteration[100/363] Loss: 0.15Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.27Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.22Epoch[4] Iteration[200/363] Loss: 0.24Epoch[4] Iteration[250/363] Loss: 0.24Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.23Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.11Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.22Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.12Epoch[6] Iteration[100/363] Loss: 0.18Epoch[6] Iteration[150/363] Loss: 0.19Epoch[6] Iteration[200/363] Loss: 0.21Epoch[6] Iteration[250/363] Loss: 0.21Epoch[6] Iteration[300/363] Loss: 0.20Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.12Epoch[7] Iteration[100/363] Loss: 0.13Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.19Epoch[7] Iteration[250/363] Loss: 0.20Epoch[7] Iteration[300/363] Loss: 0.16Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.08Epoch[8] Iteration[100/363] Loss: 0.13Epoch[8] Iteration[150/363] Loss: 0.19Epoch[8] Iteration[200/363] Loss: 0.24Epoch[8] Iteration[250/363] Loss: 0.27Epoch[8] Iteration[300/363] Loss: 0.26Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.06Epoch[9] Iteration[100/363] Loss: 0.11Epoch[9] Iteration[150/363] Loss: 0.18Epoch[9] Iteration[200/363] Loss: 0.20Epoch[9] Iteration[250/363] Loss: 0.20Epoch[9] Iteration[300/363] Loss: 0.19Epoch[9] Iteration[350/363] Loss: 0.17Epoch[10] Iteration[50/363] Loss: 0.05Epoch[10] Iteration[100/363] Loss: 0.21Epoch[10] Iteration[150/363] Loss: 0.23Epoch[10] Iteration[200/363] Loss: 0.21Epoch[10] Iteration[250/363] Loss: 0.20Epoch[10] Iteration[300/363] Loss: 0.29Epoch[10] Iteration[350/363] Loss: 0.16Epoch[11] Iteration[50/363] Loss: 0.06Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.15Epoch[11] Iteration[200/363] Loss: 0.20Epoch[11] Iteration[250/363] Loss: 0.21Epoch[11] Iteration[300/363] Loss: 0.12Epoch[11] Iteration[350/363] Loss: 0.13Epoch[12] Iteration[50/363] Loss: 0.08Epoch[12] Iteration[100/363] Loss: 0.04Epoch[12] Iteration[150/363] Loss: 0.17Epoch[12] Iteration[200/363] Loss: 0.18Epoch[12] Iteration[250/363] Loss: 0.19Epoch[12] Iteration[300/363] Loss: 0.11Epoch[12] Iteration[350/363] Loss: 0.13
======== resnet18 ========

spatial feature len: 4608, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.36Epoch[1] Iteration[100/363] Loss: 0.11Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.31Epoch[1] Iteration[250/363] Loss: 0.26Epoch[1] Iteration[300/363] Loss: 0.47Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.22Epoch[2] Iteration[300/363] Loss: 0.41Epoch[2] Iteration[350/363] Loss: 0.26Epoch[3] Iteration[50/363] Loss: 0.14Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.24Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.26Epoch[3] Iteration[300/363] Loss: 0.31Epoch[3] Iteration[350/363] Loss: 0.23Epoch[4] Iteration[50/363] Loss: 0.16Epoch[4] Iteration[100/363] Loss: 0.05Epoch[4] Iteration[150/363] Loss: 0.26Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.15Epoch[4] Iteration[300/363] Loss: 0.33Epoch[4] Iteration[350/363] Loss: 0.16Epoch[5] Iteration[50/363] Loss: 0.21Epoch[5] Iteration[100/363] Loss: 0.09Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.14Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.27Epoch[5] Iteration[350/363] Loss: 0.18Epoch[6] Iteration[50/363] Loss: 0.13Epoch[6] Iteration[100/363] Loss: 0.07Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.31Epoch[6] Iteration[350/363] Loss: 0.18Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.15Epoch[7] Iteration[150/363] Loss: 0.22Epoch[7] Iteration[200/363] Loss: 0.21Epoch[7] Iteration[250/363] Loss: 0.35Epoch[7] Iteration[300/363] Loss: 0.24Epoch[7] Iteration[350/363] Loss: 0.28Epoch[8] Iteration[50/363] Loss: 0.06Epoch[8] Iteration[100/363] Loss: 0.08Epoch[8] Iteration[150/363] Loss: 0.14Epoch[8] Iteration[200/363] Loss: 0.14Epoch[8] Iteration[250/363] Loss: 0.11Epoch[8] Iteration[300/363] Loss: 0.20Epoch[8] Iteration[350/363] Loss: 0.22Epoch[9] Iteration[50/363] Loss: 0.09Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.17Epoch[9] Iteration[200/363] Loss: 0.14Epoch[9] Iteration[250/363] Loss: 0.15Epoch[9] Iteration[300/363] Loss: 0.27Epoch[9] Iteration[350/363] Loss: 0.18Epoch[10] Iteration[50/363] Loss: 0.05Epoch[10] Iteration[100/363] Loss: 0.11Epoch[10] Iteration[150/363] Loss: 0.17Epoch[10] Iteration[200/363] Loss: 0.14Epoch[10] Iteration[250/363] Loss: 0.11Epoch[10] Iteration[300/363] Loss: 0.18Epoch[10] Iteration[350/363] Loss: 0.16Epoch[11] Iteration[50/363] Loss: 0.05Epoch[11] Iteration[100/363] Loss: 0.06Epoch[11] Iteration[150/363] Loss: 0.13Epoch[11] Iteration[200/363] Loss: 0.12Epoch[11] Iteration[250/363] Loss: 0.11Epoch[11] Iteration[300/363] Loss: 0.18Epoch[11] Iteration[350/363] Loss: 0.10
======== resnet50 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.21Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.25Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.27Epoch[1] Iteration[300/363] Loss: 0.55Epoch[1] Iteration[350/363] Loss: 0.38Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.28Epoch[2] Iteration[200/363] Loss: 0.19Epoch[2] Iteration[250/363] Loss: 0.30Epoch[2] Iteration[300/363] Loss: 0.43Epoch[2] Iteration[350/363] Loss: 0.23Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.14Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.41Epoch[3] Iteration[350/363] Loss: 0.19Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.16Epoch[4] Iteration[250/363] Loss: 0.19Epoch[4] Iteration[300/363] Loss: 0.34Epoch[4] Iteration[350/363] Loss: 0.16Epoch[5] Iteration[50/363] Loss: 0.18Epoch[5] Iteration[100/363] Loss: 0.11Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.19Epoch[5] Iteration[250/363] Loss: 0.24Epoch[5] Iteration[300/363] Loss: 0.31Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.16Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.15Epoch[6] Iteration[300/363] Loss: 0.17Epoch[6] Iteration[350/363] Loss: 0.22Epoch[7] Iteration[50/363] Loss: 0.09Epoch[7] Iteration[100/363] Loss: 0.13Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.17Epoch[7] Iteration[250/363] Loss: 0.17Epoch[7] Iteration[300/363] Loss: 0.24Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.09Epoch[8] Iteration[100/363] Loss: 0.13Epoch[8] Iteration[150/363] Loss: 0.20Epoch[8] Iteration[200/363] Loss: 0.10Epoch[8] Iteration[250/363] Loss: 0.17Epoch[8] Iteration[300/363] Loss: 0.11Epoch[8] Iteration[350/363] Loss: 0.10Epoch[9] Iteration[50/363] Loss: 0.06Epoch[9] Iteration[100/363] Loss: 0.09Epoch[9] Iteration[150/363] Loss: 0.13Epoch[9] Iteration[200/363] Loss: 0.12Epoch[9] Iteration[250/363] Loss: 0.13Epoch[9] Iteration[300/363] Loss: 0.15Epoch[9] Iteration[350/363] Loss: 0.07Epoch[10] Iteration[50/363] Loss: 0.12Epoch[10] Iteration[100/363] Loss: 0.06Epoch[10] Iteration[150/363] Loss: 0.10Epoch[10] Iteration[200/363] Loss: 0.08Epoch[10] Iteration[250/363] Loss: 0.07Epoch[10] Iteration[300/363] Loss: 0.13Epoch[10] Iteration[350/363] Loss: 0.10Epoch[11] Iteration[50/363] Loss: 0.03Epoch[11] Iteration[100/363] Loss: 0.02Epoch[11] Iteration[150/363] Loss: 0.16Epoch[11] Iteration[200/363] Loss: 0.07Epoch[11] Iteration[250/363] Loss: 0.18Epoch[11] Iteration[300/363] Loss: 0.09Epoch[11] Iteration[350/363] Loss: 0.09Epoch[12] Iteration[50/363] Loss: 0.05Epoch[12] Iteration[100/363] Loss: 0.05Epoch[12] Iteration[150/363] Loss: 0.14Epoch[12] Iteration[200/363] Loss: 0.08Epoch[12] Iteration[250/363] Loss: 0.10Epoch[12] Iteration[300/363] Loss: 0.21Epoch[12] Iteration[350/363] Loss: 0.19Epoch[13] Iteration[50/363] Loss: 0.05Epoch[13] Iteration[100/363] Loss: 0.02Epoch[13] Iteration[150/363] Loss: 0.18Epoch[13] Iteration[200/363] Loss: 0.06Epoch[13] Iteration[250/363] Loss: 0.04Epoch[13] Iteration[300/363] Loss: 0.10Epoch[13] Iteration[350/363] Loss: 0.08
======== resnet152 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.21Epoch[1] Iteration[100/363] Loss: 0.15Epoch[1] Iteration[150/363] Loss: 0.41Epoch[1] Iteration[200/363] Loss: 0.33Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.50Epoch[1] Iteration[350/363] Loss: 0.32Epoch[2] Iteration[50/363] Loss: 0.13Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.29Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.19Epoch[2] Iteration[300/363] Loss: 0.33Epoch[2] Iteration[350/363] Loss: 0.25Epoch[3] Iteration[50/363] Loss: 0.11Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.27Epoch[3] Iteration[200/363] Loss: 0.24Epoch[3] Iteration[250/363] Loss: 0.19Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.20Epoch[4] Iteration[50/363] Loss: 0.12Epoch[4] Iteration[100/363] Loss: 0.09Epoch[4] Iteration[150/363] Loss: 0.27Epoch[4] Iteration[200/363] Loss: 0.16Epoch[4] Iteration[250/363] Loss: 0.22Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.18Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.19Epoch[5] Iteration[200/363] Loss: 0.16Epoch[5] Iteration[250/363] Loss: 0.14Epoch[5] Iteration[300/363] Loss: 0.21Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.09Epoch[6] Iteration[100/363] Loss: 0.07Epoch[6] Iteration[150/363] Loss: 0.20Epoch[6] Iteration[200/363] Loss: 0.17Epoch[6] Iteration[250/363] Loss: 0.19Epoch[6] Iteration[300/363] Loss: 0.19Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.09Epoch[7] Iteration[100/363] Loss: 0.05Epoch[7] Iteration[150/363] Loss: 0.15Epoch[7] Iteration[200/363] Loss: 0.12Epoch[7] Iteration[250/363] Loss: 0.16Epoch[7] Iteration[300/363] Loss: 0.12Epoch[7] Iteration[350/363] Loss: 0.17Epoch[8] Iteration[50/363] Loss: 0.09Epoch[8] Iteration[100/363] Loss: 0.05Epoch[8] Iteration[150/363] Loss: 0.13Epoch[8] Iteration[200/363] Loss: 0.10Epoch[8] Iteration[250/363] Loss: 0.13Epoch[8] Iteration[300/363] Loss: 0.08Epoch[8] Iteration[350/363] Loss: 0.15Epoch[9] Iteration[50/363] Loss: 0.10Epoch[9] Iteration[100/363] Loss: 0.08Epoch[9] Iteration[150/363] Loss: 0.07Epoch[9] Iteration[200/363] Loss: 0.06Epoch[9] Iteration[250/363] Loss: 0.15Epoch[9] Iteration[300/363] Loss: 0.16Epoch[9] Iteration[350/363] Loss: 0.08Epoch[10] Iteration[50/363] Loss: 0.03Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.09Epoch[10] Iteration[200/363] Loss: 0.11Epoch[10] Iteration[250/363] Loss: 0.06Epoch[10] Iteration[300/363] Loss: 0.09Epoch[10] Iteration[350/363] Loss: 0.08Epoch[11] Iteration[50/363] Loss: 0.02Epoch[11] Iteration[100/363] Loss: 0.07Epoch[11] Iteration[150/363] Loss: 0.08Epoch[11] Iteration[200/363] Loss: 0.10Epoch[11] Iteration[250/363] Loss: 0.16Epoch[11] Iteration[300/363] Loss: 0.12Epoch[11] Iteration[350/363] Loss: 0.07Epoch[12] Iteration[50/363] Loss: 0.12Epoch[12] Iteration[100/363] Loss: 0.17Epoch[12] Iteration[150/363] Loss: 0.03Epoch[12] Iteration[200/363] Loss: 0.11Epoch[12] Iteration[250/363] Loss: 0.06Epoch[12] Iteration[300/363] Loss: 0.05Epoch[12] Iteration[350/363] Loss: 0.20
======== resnext50_32x4d ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.24Epoch[1] Iteration[100/363] Loss: 0.16Epoch[1] Iteration[150/363] Loss: 0.30Epoch[1] Iteration[200/363] Loss: 0.22Epoch[1] Iteration[250/363] Loss: 0.27Epoch[1] Iteration[300/363] Loss: 0.44Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.10Epoch[2] Iteration[150/363] Loss: 0.25Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.21Epoch[2] Iteration[300/363] Loss: 0.36Epoch[2] Iteration[350/363] Loss: 0.31Epoch[3] Iteration[50/363] Loss: 0.16Epoch[3] Iteration[100/363] Loss: 0.15Epoch[3] Iteration[150/363] Loss: 0.27Epoch[3] Iteration[200/363] Loss: 0.30Epoch[3] Iteration[250/363] Loss: 0.18Epoch[3] Iteration[300/363] Loss: 0.30Epoch[3] Iteration[350/363] Loss: 0.25Epoch[4] Iteration[50/363] Loss: 0.16Epoch[4] Iteration[100/363] Loss: 0.17Epoch[4] Iteration[150/363] Loss: 0.27Epoch[4] Iteration[200/363] Loss: 0.24Epoch[4] Iteration[250/363] Loss: 0.18Epoch[4] Iteration[300/363] Loss: 0.14Epoch[4] Iteration[350/363] Loss: 0.24Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.25Epoch[5] Iteration[200/363] Loss: 0.27Epoch[5] Iteration[250/363] Loss: 0.12Epoch[5] Iteration[300/363] Loss: 0.22Epoch[5] Iteration[350/363] Loss: 0.15Epoch[6] Iteration[50/363] Loss: 0.14Epoch[6] Iteration[100/363] Loss: 0.19Epoch[6] Iteration[150/363] Loss: 0.29Epoch[6] Iteration[200/363] Loss: 0.26Epoch[6] Iteration[250/363] Loss: 0.16Epoch[6] Iteration[300/363] Loss: 0.14Epoch[6] Iteration[350/363] Loss: 0.27Epoch[7] Iteration[50/363] Loss: 0.14Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.25Epoch[7] Iteration[200/363] Loss: 0.20Epoch[7] Iteration[250/363] Loss: 0.10Epoch[7] Iteration[300/363] Loss: 0.22Epoch[7] Iteration[350/363] Loss: 0.18Epoch[8] Iteration[50/363] Loss: 0.13Epoch[8] Iteration[100/363] Loss: 0.13Epoch[8] Iteration[150/363] Loss: 0.19Epoch[8] Iteration[200/363] Loss: 0.16Epoch[8] Iteration[250/363] Loss: 0.08Epoch[8] Iteration[300/363] Loss: 0.18Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.12Epoch[9] Iteration[100/363] Loss: 0.07Epoch[9] Iteration[150/363] Loss: 0.22Epoch[9] Iteration[200/363] Loss: 0.18Epoch[9] Iteration[250/363] Loss: 0.12Epoch[9] Iteration[300/363] Loss: 0.17Epoch[9] Iteration[350/363] Loss: 0.19Epoch[10] Iteration[50/363] Loss: 0.16Epoch[10] Iteration[100/363] Loss: 0.11Epoch[10] Iteration[150/363] Loss: 0.14Epoch[10] Iteration[200/363] Loss: 0.19Epoch[10] Iteration[250/363] Loss: 0.03Epoch[10] Iteration[300/363] Loss: 0.14Epoch[10] Iteration[350/363] Loss: 0.14Epoch[11] Iteration[50/363] Loss: 0.08Epoch[11] Iteration[100/363] Loss: 0.03Epoch[11] Iteration[150/363] Loss: 0.24Epoch[11] Iteration[200/363] Loss: 0.16Epoch[11] Iteration[250/363] Loss: 0.09Epoch[11] Iteration[300/363] Loss: 0.18Epoch[11] Iteration[350/363] Loss: 0.19Epoch[12] Iteration[50/363] Loss: 0.22Epoch[12] Iteration[100/363] Loss: 0.04Epoch[12] Iteration[150/363] Loss: 0.25Epoch[12] Iteration[200/363] Loss: 0.15Epoch[12] Iteration[250/363] Loss: 0.07Epoch[12] Iteration[300/363] Loss: 0.18Epoch[12] Iteration[350/363] Loss: 0.11Epoch[13] Iteration[50/363] Loss: 0.04Epoch[13] Iteration[100/363] Loss: 0.01Epoch[13] Iteration[150/363] Loss: 0.09Epoch[13] Iteration[200/363] Loss: 0.14Epoch[13] Iteration[250/363] Loss: 0.05Epoch[13] Iteration[300/363] Loss: 0.18Epoch[13] Iteration[350/363] Loss: 0.15
======== wide_resnet50_2 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.16Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.35Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.40Epoch[1] Iteration[300/363] Loss: 0.50Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.12Epoch[2] Iteration[150/363] Loss: 0.29Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.23Epoch[2] Iteration[300/363] Loss: 0.32Epoch[2] Iteration[350/363] Loss: 0.31Epoch[3] Iteration[50/363] Loss: 0.16Epoch[3] Iteration[100/363] Loss: 0.14Epoch[3] Iteration[150/363] Loss: 0.33Epoch[3] Iteration[200/363] Loss: 0.17Epoch[3] Iteration[250/363] Loss: 0.20Epoch[3] Iteration[300/363] Loss: 0.32Epoch[3] Iteration[350/363] Loss: 0.25Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.17Epoch[4] Iteration[150/363] Loss: 0.31Epoch[4] Iteration[200/363] Loss: 0.22Epoch[4] Iteration[250/363] Loss: 0.20Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.16Epoch[5] Iteration[150/363] Loss: 0.20Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.25Epoch[5] Iteration[350/363] Loss: 0.24Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.09Epoch[6] Iteration[150/363] Loss: 0.24Epoch[6] Iteration[200/363] Loss: 0.27Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.23Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.10Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.17Epoch[7] Iteration[200/363] Loss: 0.18Epoch[7] Iteration[250/363] Loss: 0.19Epoch[7] Iteration[300/363] Loss: 0.14Epoch[7] Iteration[350/363] Loss: 0.10Epoch[8] Iteration[50/363] Loss: 0.16Epoch[8] Iteration[100/363] Loss: 0.06Epoch[8] Iteration[150/363] Loss: 0.15Epoch[8] Iteration[200/363] Loss: 0.17Epoch[8] Iteration[250/363] Loss: 0.23Epoch[8] Iteration[300/363] Loss: 0.24Epoch[8] Iteration[350/363] Loss: 0.14Epoch[9] Iteration[50/363] Loss: 0.09Epoch[9] Iteration[100/363] Loss: 0.09Epoch[9] Iteration[150/363] Loss: 0.14Epoch[9] Iteration[200/363] Loss: 0.13Epoch[9] Iteration[250/363] Loss: 0.19Epoch[9] Iteration[300/363] Loss: 0.18Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.06Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.11Epoch[10] Iteration[250/363] Loss: 0.11Epoch[10] Iteration[300/363] Loss: 0.29Epoch[10] Iteration[350/363] Loss: 0.11Epoch[11] Iteration[50/363] Loss: 0.07Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.16Epoch[11] Iteration[200/363] Loss: 0.15Epoch[11] Iteration[250/363] Loss: 0.17Epoch[11] Iteration[300/363] Loss: 0.11Epoch[11] Iteration[350/363] Loss: 0.14Epoch[12] Iteration[50/363] Loss: 0.07Epoch[12] Iteration[100/363] Loss: 0.04Epoch[12] Iteration[150/363] Loss: 0.13Epoch[12] Iteration[200/363] Loss: 0.14Epoch[12] Iteration[250/363] Loss: 0.17Epoch[12] Iteration[300/363] Loss: 0.07Epoch[12] Iteration[350/363] Loss: 0.17Epoch[13] Iteration[50/363] Loss: 0.08Epoch[13] Iteration[100/363] Loss: 0.08Epoch[13] Iteration[150/363] Loss: 0.25Epoch[13] Iteration[200/363] Loss: 0.09Epoch[13] Iteration[250/363] Loss: 0.14Epoch[13] Iteration[300/363] Loss: 0.13Epoch[13] Iteration[350/363] Loss: 0.09Epoch[14] Iteration[50/363] Loss: 0.07Epoch[14] Iteration[100/363] Loss: 0.05Epoch[14] Iteration[150/363] Loss: 0.12Epoch[14] Iteration[200/363] Loss: 0.07Epoch[14] Iteration[250/363] Loss: 0.18Epoch[14] Iteration[300/363] Loss: 0.08Epoch[14] Iteration[350/363] Loss: 0.07
======== shufflenet_v2_x1_0 ========

spatial feature len: 9216, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.49Epoch[1] Iteration[100/363] Loss: 0.25Epoch[1] Iteration[150/363] Loss: 0.27Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.38Epoch[1] Iteration[300/363] Loss: 0.33Epoch[1] Iteration[350/363] Loss: 0.27Epoch[2] Iteration[50/363] Loss: 0.18Epoch[2] Iteration[100/363] Loss: 0.13Epoch[2] Iteration[150/363] Loss: 0.22Epoch[2] Iteration[200/363] Loss: 0.20Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.28Epoch[2] Iteration[350/363] Loss: 0.19Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.19Epoch[3] Iteration[200/363] Loss: 0.16Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.25Epoch[3] Iteration[350/363] Loss: 0.16Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.08Epoch[4] Iteration[150/363] Loss: 0.25Epoch[4] Iteration[200/363] Loss: 0.16Epoch[4] Iteration[250/363] Loss: 0.17Epoch[4] Iteration[300/363] Loss: 0.21Epoch[4] Iteration[350/363] Loss: 0.17Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.07Epoch[5] Iteration[150/363] Loss: 0.19Epoch[5] Iteration[200/363] Loss: 0.16Epoch[5] Iteration[250/363] Loss: 0.13Epoch[5] Iteration[300/363] Loss: 0.19Epoch[5] Iteration[350/363] Loss: 0.12Epoch[6] Iteration[50/363] Loss: 0.13Epoch[6] Iteration[100/363] Loss: 0.04Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.15Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.17Epoch[6] Iteration[350/363] Loss: 0.13Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.08Epoch[7] Iteration[150/363] Loss: 0.18Epoch[7] Iteration[200/363] Loss: 0.10Epoch[7] Iteration[250/363] Loss: 0.23Epoch[7] Iteration[300/363] Loss: 0.17Epoch[7] Iteration[350/363] Loss: 0.10Epoch[8] Iteration[50/363] Loss: 0.14Epoch[8] Iteration[100/363] Loss: 0.05Epoch[8] Iteration[150/363] Loss: 0.12Epoch[8] Iteration[200/363] Loss: 0.14Epoch[8] Iteration[250/363] Loss: 0.12Epoch[8] Iteration[300/363] Loss: 0.22Epoch[8] Iteration[350/363] Loss: 0.08Epoch[9] Iteration[50/363] Loss: 0.09Epoch[9] Iteration[100/363] Loss: 0.02Epoch[9] Iteration[150/363] Loss: 0.23Epoch[9] Iteration[200/363] Loss: 0.09Epoch[9] Iteration[250/363] Loss: 0.11Epoch[9] Iteration[300/363] Loss: 0.06Epoch[9] Iteration[350/363] Loss: 0.12Epoch[10] Iteration[50/363] Loss: 0.07Epoch[10] Iteration[100/363] Loss: 0.06Epoch[10] Iteration[150/363] Loss: 0.26Epoch[10] Iteration[200/363] Loss: 0.08Epoch[10] Iteration[250/363] Loss: 0.09Epoch[10] Iteration[300/363] Loss: 0.18Epoch[10] Iteration[350/363] Loss: 0.11Epoch[11] Iteration[50/363] Loss: 0.06Epoch[11] Iteration[100/363] Loss: 0.01Epoch[11] Iteration[150/363] Loss: 0.19Epoch[11] Iteration[200/363] Loss: 0.12Epoch[11] Iteration[250/363] Loss: 0.09Epoch[11] Iteration[300/363] Loss: 0.04Epoch[11] Iteration[350/363] Loss: 0.10Epoch[12] Iteration[50/363] Loss: 0.05Epoch[12] Iteration[100/363] Loss: 0.09Epoch[12] Iteration[150/363] Loss: 0.20Epoch[12] Iteration[200/363] Loss: 0.08Epoch[12] Iteration[250/363] Loss: 0.09Epoch[12] Iteration[300/363] Loss: 0.05Epoch[12] Iteration[350/363] Loss: 0.02
======== inception_v3 ========

Traceback (most recent call last):
  File "conpare_deep_models.py", line 87, in <module>
    main()
  File "conpare_deep_models.py", line 80, in main
    t_output_dim=500
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/model.py", line 47, in __init__
    self.temporal_stage = CNN_LSTM(
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/extractor.py", line 122, in forward
    return self.__inception_forward(x)
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/extractor.py", line 84, in __inception_forward
    x = self.model.Mixed_7a(x)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torchvision/models/inception.py", line 349, in forward
    outputs = self._forward(x)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torchvision/models/inception.py", line 337, in _forward
    branch3x3 = self.branch3x3_2(branch3x3)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torchvision/models/inception.py", line 440, in forward
    x = self.bn(x)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 136, in forward
    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/functional.py", line 2054, in batch_norm
    _verify_batch_size(input.size())
  File "/home/hassaku/research/cnmfe-reviewer/venv/lib/python3.7/site-packages/torch/nn/functional.py", line 2037, in _verify_batch_size
    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 320, 1, 1])
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== CNN ========

Traceback (most recent call last):
  File "conpare_deep_models.py", line 88, in <module>
    main()
  File "conpare_deep_models.py", line 81, in main
    t_output_dim=500
TypeError: __init__() got an unexpected keyword argument 'res_block_num'
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== CNN ========

Traceback (most recent call last):
  File "conpare_deep_models.py", line 88, in <module>
    main()
  File "conpare_deep_models.py", line 81, in main
    t_output_dim=500
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/model.py", line 37, in __init__
    self.spatial_stage = CNN(block_num=block_num).cuda()
  File "/home/hassaku/research/cnmfe-reviewer/notebooks/nn/res_block.py", line 96, in __init__
    net.append(maxpool)
NameError: name 'net' is not defined
No preprocessing on spatial data
File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.
No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.
Successfully loaded data.
Training and test data loaded

======== vgg13 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.25Epoch[1] Iteration[100/363] Loss: 0.16Epoch[1] Iteration[150/363] Loss: 0.31Epoch[1] Iteration[200/363] Loss: 0.20Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.30Epoch[1] Iteration[350/363] Loss: 0.26Epoch[2] Iteration[50/363] Loss: 0.22Epoch[2] Iteration[100/363] Loss: 0.13Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.27Epoch[2] Iteration[300/363] Loss: 0.31Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.21Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.22Epoch[3] Iteration[200/363] Loss: 0.18Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.26Epoch[3] Iteration[350/363] Loss: 0.21Epoch[4] Iteration[50/363] Loss: 0.20Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.23Epoch[4] Iteration[200/363] Loss: 0.17Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.20Epoch[5] Iteration[50/363] Loss: 0.19Epoch[5] Iteration[100/363] Loss: 0.11Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.19Epoch[5] Iteration[250/363] Loss: 0.20Epoch[5] Iteration[300/363] Loss: 0.28Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.22Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.32Epoch[6] Iteration[350/363] Loss: 0.18Epoch[7] Iteration[50/363] Loss: 0.16Epoch[7] Iteration[100/363] Loss: 0.09Epoch[7] Iteration[150/363] Loss: 0.20Epoch[7] Iteration[200/363] Loss: 0.16Epoch[7] Iteration[250/363] Loss: 0.16Epoch[7] Iteration[300/363] Loss: 0.26Epoch[7] Iteration[350/363] Loss: 0.15Epoch[8] Iteration[50/363] Loss: 0.13Epoch[8] Iteration[100/363] Loss: 0.06Epoch[8] Iteration[150/363] Loss: 0.17Epoch[8] Iteration[200/363] Loss: 0.15Epoch[8] Iteration[250/363] Loss: 0.14Epoch[8] Iteration[300/363] Loss: 0.24Epoch[8] Iteration[350/363] Loss: 0.12Epoch[9] Iteration[50/363] Loss: 0.10Epoch[9] Iteration[100/363] Loss: 0.06Epoch[9] Iteration[150/363] Loss: 0.19Epoch[9] Iteration[200/363] Loss: 0.15Epoch[9] Iteration[250/363] Loss: 0.14Epoch[9] Iteration[300/363] Loss: 0.27Epoch[9] Iteration[350/363] Loss: 0.11Epoch[10] Iteration[50/363] Loss: 0.13Epoch[10] Iteration[100/363] Loss: 0.07Epoch[10] Iteration[150/363] Loss: 0.21Epoch[10] Iteration[200/363] Loss: 0.16Epoch[10] Iteration[250/363] Loss: 0.10Epoch[10] Iteration[300/363] Loss: 0.19Epoch[10] Iteration[350/363] Loss: 0.12Epoch[11] Iteration[50/363] Loss: 0.16Epoch[11] Iteration[100/363] Loss: 0.04Epoch[11] Iteration[150/363] Loss: 0.21Epoch[11] Iteration[200/363] Loss: 0.12Epoch[11] Iteration[250/363] Loss: 0.07Epoch[11] Iteration[300/363] Loss: 0.21Epoch[11] Iteration[350/363] Loss: 0.20Epoch[12] Iteration[50/363] Loss: 0.15Epoch[12] Iteration[100/363] Loss: 0.06Epoch[12] Iteration[150/363] Loss: 0.19Epoch[12] Iteration[200/363] Loss: 0.16Epoch[12] Iteration[250/363] Loss: 0.07Epoch[12] Iteration[300/363] Loss: 0.20Epoch[12] Iteration[350/363] Loss: 0.11Epoch[13] Iteration[50/363] Loss: 0.11Epoch[13] Iteration[100/363] Loss: 0.02Epoch[13] Iteration[150/363] Loss: 0.26Epoch[13] Iteration[200/363] Loss: 0.23Epoch[13] Iteration[250/363] Loss: 0.07Epoch[13] Iteration[300/363] Loss: 0.08Epoch[13] Iteration[350/363] Loss: 0.06Epoch[14] Iteration[50/363] Loss: 0.11Epoch[14] Iteration[100/363] Loss: 0.06Epoch[14] Iteration[150/363] Loss: 0.19Epoch[14] Iteration[200/363] Loss: 0.14Epoch[14] Iteration[250/363] Loss: 0.11Epoch[14] Iteration[300/363] Loss: 0.11Epoch[14] Iteration[350/363] Loss: 0.05Epoch[15] Iteration[50/363] Loss: 0.19Epoch[15] Iteration[100/363] Loss: 0.05Epoch[15] Iteration[150/363] Loss: 0.17Epoch[15] Iteration[200/363] Loss: 0.14Epoch[15] Iteration[250/363] Loss: 0.08Epoch[15] Iteration[300/363] Loss: 0.12Epoch[15] Iteration[350/363] Loss: 0.06Epoch[16] Iteration[50/363] Loss: 0.19Epoch[16] Iteration[100/363] Loss: 0.03Epoch[16] Iteration[150/363] Loss: 0.20Epoch[16] Iteration[200/363] Loss: 0.13Epoch[16] Iteration[250/363] Loss: 0.08Epoch[16] Iteration[300/363] Loss: 0.05Epoch[16] Iteration[350/363] Loss: 0.09Epoch[17] Iteration[50/363] Loss: 0.08Epoch[17] Iteration[100/363] Loss: 0.05Epoch[17] Iteration[150/363] Loss: 0.21Epoch[17] Iteration[200/363] Loss: 0.13Epoch[17] Iteration[250/363] Loss: 0.11Epoch[17] Iteration[300/363] Loss: 0.17Epoch[17] Iteration[350/363] Loss: 0.02Epoch[18] Iteration[50/363] Loss: 0.27Epoch[18] Iteration[100/363] Loss: 0.05Epoch[18] Iteration[150/363] Loss: 0.17Epoch[18] Iteration[200/363] Loss: 0.10Epoch[18] Iteration[250/363] Loss: 0.13Epoch[18] Iteration[300/363] Loss: 0.08Epoch[18] Iteration[350/363] Loss: 0.09
======== vgg19 ========

spatial feature len: 2048, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.37Epoch[1] Iteration[100/363] Loss: 0.27Epoch[1] Iteration[150/363] Loss: 0.35Epoch[1] Iteration[200/363] Loss: 0.36Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.28Epoch[1] Iteration[350/363] Loss: 0.26Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.08Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.28Epoch[2] Iteration[250/363] Loss: 0.28Epoch[2] Iteration[300/363] Loss: 0.27Epoch[2] Iteration[350/363] Loss: 0.24Epoch[3] Iteration[50/363] Loss: 0.18Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.27Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.28Epoch[3] Iteration[300/363] Loss: 0.24Epoch[3] Iteration[350/363] Loss: 0.25Epoch[4] Iteration[50/363] Loss: 0.24Epoch[4] Iteration[100/363] Loss: 0.10Epoch[4] Iteration[150/363] Loss: 0.25Epoch[4] Iteration[200/363] Loss: 0.21Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.26Epoch[4] Iteration[350/363] Loss: 0.22Epoch[5] Iteration[50/363] Loss: 0.21Epoch[5] Iteration[100/363] Loss: 0.10Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.18Epoch[5] Iteration[250/363] Loss: 0.25Epoch[5] Iteration[300/363] Loss: 0.24Epoch[5] Iteration[350/363] Loss: 0.20Epoch[6] Iteration[50/363] Loss: 0.20Epoch[6] Iteration[100/363] Loss: 0.11Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.20Epoch[6] Iteration[250/363] Loss: 0.24Epoch[6] Iteration[300/363] Loss: 0.27Epoch[6] Iteration[350/363] Loss: 0.18Epoch[7] Iteration[50/363] Loss: 0.18Epoch[7] Iteration[100/363] Loss: 0.10Epoch[7] Iteration[150/363] Loss: 0.19Epoch[7] Iteration[200/363] Loss: 0.23Epoch[7] Iteration[250/363] Loss: 0.20Epoch[7] Iteration[300/363] Loss: 0.26Epoch[7] Iteration[350/363] Loss: 0.21Epoch[8] Iteration[50/363] Loss: 0.17Epoch[8] Iteration[100/363] Loss: 0.11Epoch[8] Iteration[150/363] Loss: 0.21Epoch[8] Iteration[200/363] Loss: 0.26Epoch[8] Iteration[250/363] Loss: 0.15Epoch[8] Iteration[300/363] Loss: 0.20Epoch[8] Iteration[350/363] Loss: 0.20Epoch[9] Iteration[50/363] Loss: 0.21Epoch[9] Iteration[100/363] Loss: 0.09Epoch[9] Iteration[150/363] Loss: 0.24Epoch[9] Iteration[200/363] Loss: 0.22Epoch[9] Iteration[250/363] Loss: 0.15Epoch[9] Iteration[300/363] Loss: 0.17Epoch[9] Iteration[350/363] Loss: 0.19Epoch[10] Iteration[50/363] Loss: 0.19Epoch[10] Iteration[100/363] Loss: 0.10Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.23Epoch[10] Iteration[250/363] Loss: 0.15Epoch[10] Iteration[300/363] Loss: 0.11Epoch[10] Iteration[350/363] Loss: 0.13Epoch[11] Iteration[50/363] Loss: 0.20Epoch[11] Iteration[100/363] Loss: 0.08Epoch[11] Iteration[150/363] Loss: 0.19Epoch[11] Iteration[200/363] Loss: 0.17Epoch[11] Iteration[250/363] Loss: 0.19Epoch[11] Iteration[300/363] Loss: 0.13Epoch[11] Iteration[350/363] Loss: 0.13Epoch[12] Iteration[50/363] Loss: 0.16Epoch[12] Iteration[100/363] Loss: 0.10Epoch[12] Iteration[150/363] Loss: 0.25Epoch[12] Iteration[200/363] Loss: 0.22Epoch[12] Iteration[250/363] Loss: 0.13Epoch[12] Iteration[300/363] Loss: 0.16Epoch[12] Iteration[350/363] Loss: 0.13Epoch[13] Iteration[50/363] Loss: 0.23Epoch[13] Iteration[100/363] Loss: 0.09Epoch[13] Iteration[150/363] Loss: 0.24Epoch[13] Iteration[200/363] Loss: 0.12Epoch[13] Iteration[250/363] Loss: 0.17Epoch[13] Iteration[300/363] Loss: 0.07Epoch[13] Iteration[350/363] Loss: 0.19Epoch[14] Iteration[50/363] Loss: 0.18Epoch[14] Iteration[100/363] Loss: 0.08Epoch[14] Iteration[150/363] Loss: 0.17Epoch[14] Iteration[200/363] Loss: 0.16Epoch[14] Iteration[250/363] Loss: 0.18Epoch[14] Iteration[300/363] Loss: 0.14Epoch[14] Iteration[350/363] Loss: 0.22Epoch[15] Iteration[50/363] Loss: 0.14Epoch[15] Iteration[100/363] Loss: 0.06Epoch[15] Iteration[150/363] Loss: 0.23Epoch[15] Iteration[200/363] Loss: 0.20Epoch[15] Iteration[250/363] Loss: 0.16Epoch[15] Iteration[300/363] Loss: 0.07Epoch[15] Iteration[350/363] Loss: 0.11Epoch[16] Iteration[50/363] Loss: 0.13Epoch[16] Iteration[100/363] Loss: 0.09Epoch[16] Iteration[150/363] Loss: 0.19Epoch[16] Iteration[200/363] Loss: 0.15Epoch[16] Iteration[250/363] Loss: 0.14Epoch[16] Iteration[300/363] Loss: 0.04Epoch[16] Iteration[350/363] Loss: 0.06Epoch[17] Iteration[50/363] Loss: 0.22Epoch[17] Iteration[100/363] Loss: 0.11Epoch[17] Iteration[150/363] Loss: 0.17Epoch[17] Iteration[200/363] Loss: 0.15Epoch[17] Iteration[250/363] Loss: 0.26Epoch[17] Iteration[300/363] Loss: 0.06Epoch[17] Iteration[350/363] Loss: 0.14Epoch[18] Iteration[50/363] Loss: 0.14Epoch[18] Iteration[100/363] Loss: 0.06Epoch[18] Iteration[150/363] Loss: 0.23Epoch[18] Iteration[200/363] Loss: 0.16Epoch[18] Iteration[250/363] Loss: 0.09Epoch[18] Iteration[300/363] Loss: 0.03Epoch[18] Iteration[350/363] Loss: 0.15
======== densenet161 ========

spatial feature len: 8832, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.19Epoch[1] Iteration[100/363] Loss: 0.11Epoch[1] Iteration[150/363] Loss: 0.29Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.37Epoch[1] Iteration[300/363] Loss: 0.45Epoch[1] Iteration[350/363] Loss: 0.24Epoch[2] Iteration[50/363] Loss: 0.19Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.24Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.29Epoch[2] Iteration[300/363] Loss: 0.51Epoch[2] Iteration[350/363] Loss: 0.23Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.13Epoch[3] Iteration[150/363] Loss: 0.23Epoch[3] Iteration[200/363] Loss: 0.20Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.44Epoch[3] Iteration[350/363] Loss: 0.21Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.13Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.24Epoch[4] Iteration[250/363] Loss: 0.21Epoch[4] Iteration[300/363] Loss: 0.39Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.11Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.21Epoch[5] Iteration[200/363] Loss: 0.20Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.35Epoch[5] Iteration[350/363] Loss: 0.17Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.06Epoch[6] Iteration[150/363] Loss: 0.17Epoch[6] Iteration[200/363] Loss: 0.18Epoch[6] Iteration[250/363] Loss: 0.22Epoch[6] Iteration[300/363] Loss: 0.26Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.06Epoch[7] Iteration[100/363] Loss: 0.03Epoch[7] Iteration[150/363] Loss: 0.18Epoch[7] Iteration[200/363] Loss: 0.25Epoch[7] Iteration[250/363] Loss: 0.20Epoch[7] Iteration[300/363] Loss: 0.35Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.08Epoch[8] Iteration[100/363] Loss: 0.04Epoch[8] Iteration[150/363] Loss: 0.13Epoch[8] Iteration[200/363] Loss: 0.21Epoch[8] Iteration[250/363] Loss: 0.26Epoch[8] Iteration[300/363] Loss: 0.31Epoch[8] Iteration[350/363] Loss: 0.16Epoch[9] Iteration[50/363] Loss: 0.06Epoch[9] Iteration[100/363] Loss: 0.11Epoch[9] Iteration[150/363] Loss: 0.12Epoch[9] Iteration[200/363] Loss: 0.22Epoch[9] Iteration[250/363] Loss: 0.22Epoch[9] Iteration[300/363] Loss: 0.33Epoch[9] Iteration[350/363] Loss: 0.15Epoch[10] Iteration[50/363] Loss: 0.08Epoch[10] Iteration[100/363] Loss: 0.04Epoch[10] Iteration[150/363] Loss: 0.08Epoch[10] Iteration[200/363] Loss: 0.20Epoch[10] Iteration[250/363] Loss: 0.15Epoch[10] Iteration[300/363] Loss: 0.22Epoch[10] Iteration[350/363] Loss: 0.14Epoch[11] Iteration[50/363] Loss: 0.05Epoch[11] Iteration[100/363] Loss: 0.15Epoch[11] Iteration[150/363] Loss: 0.15Epoch[11] Iteration[200/363] Loss: 0.14Epoch[11] Iteration[250/363] Loss: 0.10Epoch[11] Iteration[300/363] Loss: 0.19Epoch[11] Iteration[350/363] Loss: 0.12Epoch[12] Iteration[50/363] Loss: 0.05Epoch[12] Iteration[100/363] Loss: 0.02Epoch[12] Iteration[150/363] Loss: 0.16Epoch[12] Iteration[200/363] Loss: 0.15Epoch[12] Iteration[250/363] Loss: 0.10Epoch[12] Iteration[300/363] Loss: 0.13Epoch[12] Iteration[350/363] Loss: 0.13
======== densenet169 ========

spatial feature len: 6656, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.22Epoch[1] Iteration[100/363] Loss: 0.12Epoch[1] Iteration[150/363] Loss: 0.26Epoch[1] Iteration[200/363] Loss: 0.27Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.55Epoch[1] Iteration[350/363] Loss: 0.31Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.21Epoch[2] Iteration[200/363] Loss: 0.23Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.36Epoch[2] Iteration[350/363] Loss: 0.27Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.14Epoch[3] Iteration[150/363] Loss: 0.20Epoch[3] Iteration[200/363] Loss: 0.21Epoch[3] Iteration[250/363] Loss: 0.22Epoch[3] Iteration[300/363] Loss: 0.37Epoch[3] Iteration[350/363] Loss: 0.24Epoch[4] Iteration[50/363] Loss: 0.13Epoch[4] Iteration[100/363] Loss: 0.11Epoch[4] Iteration[150/363] Loss: 0.17Epoch[4] Iteration[200/363] Loss: 0.24Epoch[4] Iteration[250/363] Loss: 0.19Epoch[4] Iteration[300/363] Loss: 0.35Epoch[4] Iteration[350/363] Loss: 0.19Epoch[5] Iteration[50/363] Loss: 0.12Epoch[5] Iteration[100/363] Loss: 0.12Epoch[5] Iteration[150/363] Loss: 0.17Epoch[5] Iteration[200/363] Loss: 0.21Epoch[5] Iteration[250/363] Loss: 0.21Epoch[5] Iteration[300/363] Loss: 0.32Epoch[5] Iteration[350/363] Loss: 0.23Epoch[6] Iteration[50/363] Loss: 0.08Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.12Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.13Epoch[6] Iteration[300/363] Loss: 0.49Epoch[6] Iteration[350/363] Loss: 0.15Epoch[7] Iteration[50/363] Loss: 0.07Epoch[7] Iteration[100/363] Loss: 0.05Epoch[7] Iteration[150/363] Loss: 0.16Epoch[7] Iteration[200/363] Loss: 0.15Epoch[7] Iteration[250/363] Loss: 0.12Epoch[7] Iteration[300/363] Loss: 0.34Epoch[7] Iteration[350/363] Loss: 0.26Epoch[8] Iteration[50/363] Loss: 0.08Epoch[8] Iteration[100/363] Loss: 0.11Epoch[8] Iteration[150/363] Loss: 0.15Epoch[8] Iteration[200/363] Loss: 0.13Epoch[8] Iteration[250/363] Loss: 0.12Epoch[8] Iteration[300/363] Loss: 0.28Epoch[8] Iteration[350/363] Loss: 0.07Epoch[9] Iteration[50/363] Loss: 0.07Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.16Epoch[9] Iteration[200/363] Loss: 0.17Epoch[9] Iteration[250/363] Loss: 0.18Epoch[9] Iteration[300/363] Loss: 0.27Epoch[9] Iteration[350/363] Loss: 0.10Epoch[10] Iteration[50/363] Loss: 0.08Epoch[10] Iteration[100/363] Loss: 0.08Epoch[10] Iteration[150/363] Loss: 0.16Epoch[10] Iteration[200/363] Loss: 0.16Epoch[10] Iteration[250/363] Loss: 0.19Epoch[10] Iteration[300/363] Loss: 0.18Epoch[10] Iteration[350/363] Loss: 0.11Epoch[11] Iteration[50/363] Loss: 0.06Epoch[11] Iteration[100/363] Loss: 0.02Epoch[11] Iteration[150/363] Loss: 0.16Epoch[11] Iteration[200/363] Loss: 0.14Epoch[11] Iteration[250/363] Loss: 0.16Epoch[11] Iteration[300/363] Loss: 0.19Epoch[11] Iteration[350/363] Loss: 0.10Epoch[12] Iteration[50/363] Loss: 0.15Epoch[12] Iteration[100/363] Loss: 0.03Epoch[12] Iteration[150/363] Loss: 0.14Epoch[12] Iteration[200/363] Loss: 0.21Epoch[12] Iteration[250/363] Loss: 0.08Epoch[12] Iteration[300/363] Loss: 0.31Epoch[12] Iteration[350/363] Loss: 0.13
======== resnet34 ========

spatial feature len: 4608, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.22Epoch[1] Iteration[100/363] Loss: 0.22Epoch[1] Iteration[150/363] Loss: 0.27Epoch[1] Iteration[200/363] Loss: 0.26Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.45Epoch[1] Iteration[350/363] Loss: 0.34Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.13Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.34Epoch[2] Iteration[350/363] Loss: 0.29Epoch[3] Iteration[50/363] Loss: 0.13Epoch[3] Iteration[100/363] Loss: 0.15Epoch[3] Iteration[150/363] Loss: 0.26Epoch[3] Iteration[200/363] Loss: 0.19Epoch[3] Iteration[250/363] Loss: 0.25Epoch[3] Iteration[300/363] Loss: 0.35Epoch[3] Iteration[350/363] Loss: 0.22Epoch[4] Iteration[50/363] Loss: 0.15Epoch[4] Iteration[100/363] Loss: 0.14Epoch[4] Iteration[150/363] Loss: 0.21Epoch[4] Iteration[200/363] Loss: 0.22Epoch[4] Iteration[250/363] Loss: 0.28Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.16Epoch[5] Iteration[100/363] Loss: 0.15Epoch[5] Iteration[150/363] Loss: 0.17Epoch[5] Iteration[200/363] Loss: 0.24Epoch[5] Iteration[250/363] Loss: 0.23Epoch[5] Iteration[300/363] Loss: 0.24Epoch[5] Iteration[350/363] Loss: 0.25Epoch[6] Iteration[50/363] Loss: 0.15Epoch[6] Iteration[100/363] Loss: 0.10Epoch[6] Iteration[150/363] Loss: 0.19Epoch[6] Iteration[200/363] Loss: 0.22Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.20Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.11Epoch[7] Iteration[100/363] Loss: 0.17Epoch[7] Iteration[150/363] Loss: 0.15Epoch[7] Iteration[200/363] Loss: 0.12Epoch[7] Iteration[250/363] Loss: 0.16Epoch[7] Iteration[300/363] Loss: 0.34Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.11Epoch[8] Iteration[100/363] Loss: 0.09Epoch[8] Iteration[150/363] Loss: 0.15Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.16Epoch[8] Iteration[300/363] Loss: 0.18Epoch[8] Iteration[350/363] Loss: 0.19Epoch[9] Iteration[50/363] Loss: 0.11Epoch[9] Iteration[100/363] Loss: 0.10Epoch[9] Iteration[150/363] Loss: 0.15Epoch[9] Iteration[200/363] Loss: 0.14Epoch[9] Iteration[250/363] Loss: 0.19Epoch[9] Iteration[300/363] Loss: 0.16Epoch[9] Iteration[350/363] Loss: 0.13Epoch[10] Iteration[50/363] Loss: 0.07Epoch[10] Iteration[100/363] Loss: 0.06Epoch[10] Iteration[150/363] Loss: 0.15Epoch[10] Iteration[200/363] Loss: 0.13Epoch[10] Iteration[250/363] Loss: 0.25Epoch[10] Iteration[300/363] Loss: 0.12Epoch[10] Iteration[350/363] Loss: 0.26Epoch[11] Iteration[50/363] Loss: 0.10Epoch[11] Iteration[100/363] Loss: 0.12Epoch[11] Iteration[150/363] Loss: 0.14Epoch[11] Iteration[200/363] Loss: 0.07Epoch[11] Iteration[250/363] Loss: 0.05Epoch[11] Iteration[300/363] Loss: 0.10Epoch[11] Iteration[350/363] Loss: 0.11Epoch[12] Iteration[50/363] Loss: 0.06Epoch[12] Iteration[100/363] Loss: 0.10Epoch[12] Iteration[150/363] Loss: 0.09Epoch[12] Iteration[200/363] Loss: 0.07Epoch[12] Iteration[250/363] Loss: 0.19Epoch[12] Iteration[300/363] Loss: 0.14Epoch[12] Iteration[350/363] Loss: 0.16
======== resnet101 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.16Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.28Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.28Epoch[1] Iteration[300/363] Loss: 0.45Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.16Epoch[2] Iteration[100/363] Loss: 0.13Epoch[2] Iteration[150/363] Loss: 0.27Epoch[2] Iteration[200/363] Loss: 0.22Epoch[2] Iteration[250/363] Loss: 0.30Epoch[2] Iteration[300/363] Loss: 0.38Epoch[2] Iteration[350/363] Loss: 0.27Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.14Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.19Epoch[3] Iteration[250/363] Loss: 0.23Epoch[3] Iteration[300/363] Loss: 0.37Epoch[3] Iteration[350/363] Loss: 0.25Epoch[4] Iteration[50/363] Loss: 0.14Epoch[4] Iteration[100/363] Loss: 0.16Epoch[4] Iteration[150/363] Loss: 0.24Epoch[4] Iteration[200/363] Loss: 0.19Epoch[4] Iteration[250/363] Loss: 0.15Epoch[4] Iteration[300/363] Loss: 0.31Epoch[4] Iteration[350/363] Loss: 0.21Epoch[5] Iteration[50/363] Loss: 0.13Epoch[5] Iteration[100/363] Loss: 0.16Epoch[5] Iteration[150/363] Loss: 0.17Epoch[5] Iteration[200/363] Loss: 0.24Epoch[5] Iteration[250/363] Loss: 0.11Epoch[5] Iteration[300/363] Loss: 0.32Epoch[5] Iteration[350/363] Loss: 0.19Epoch[6] Iteration[50/363] Loss: 0.08Epoch[6] Iteration[100/363] Loss: 0.08Epoch[6] Iteration[150/363] Loss: 0.18Epoch[6] Iteration[200/363] Loss: 0.15Epoch[6] Iteration[250/363] Loss: 0.14Epoch[6] Iteration[300/363] Loss: 0.21Epoch[6] Iteration[350/363] Loss: 0.15Epoch[7] Iteration[50/363] Loss: 0.13Epoch[7] Iteration[100/363] Loss: 0.06Epoch[7] Iteration[150/363] Loss: 0.15Epoch[7] Iteration[200/363] Loss: 0.14Epoch[7] Iteration[250/363] Loss: 0.20Epoch[7] Iteration[300/363] Loss: 0.19Epoch[7] Iteration[350/363] Loss: 0.16Epoch[8] Iteration[50/363] Loss: 0.16Epoch[8] Iteration[100/363] Loss: 0.06Epoch[8] Iteration[150/363] Loss: 0.17Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.22Epoch[8] Iteration[300/363] Loss: 0.18Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.13Epoch[9] Iteration[100/363] Loss: 0.05Epoch[9] Iteration[150/363] Loss: 0.16Epoch[9] Iteration[200/363] Loss: 0.09Epoch[9] Iteration[250/363] Loss: 0.08Epoch[9] Iteration[300/363] Loss: 0.17Epoch[9] Iteration[350/363] Loss: 0.09Epoch[10] Iteration[50/363] Loss: 0.05Epoch[10] Iteration[100/363] Loss: 0.03Epoch[10] Iteration[150/363] Loss: 0.12Epoch[10] Iteration[200/363] Loss: 0.09Epoch[10] Iteration[250/363] Loss: 0.09Epoch[10] Iteration[300/363] Loss: 0.15Epoch[10] Iteration[350/363] Loss: 0.15Epoch[11] Iteration[50/363] Loss: 0.09Epoch[11] Iteration[100/363] Loss: 0.06Epoch[11] Iteration[150/363] Loss: 0.10Epoch[11] Iteration[200/363] Loss: 0.09Epoch[11] Iteration[250/363] Loss: 0.05Epoch[11] Iteration[300/363] Loss: 0.15Epoch[11] Iteration[350/363] Loss: 0.13
======== resnext101_32x8d ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.22Epoch[1] Iteration[100/363] Loss: 0.18Epoch[1] Iteration[150/363] Loss: 0.30Epoch[1] Iteration[200/363] Loss: 0.28Epoch[1] Iteration[250/363] Loss: 0.31Epoch[1] Iteration[300/363] Loss: 0.73Epoch[1] Iteration[350/363] Loss: 0.33Epoch[2] Iteration[50/363] Loss: 0.20Epoch[2] Iteration[100/363] Loss: 0.11Epoch[2] Iteration[150/363] Loss: 0.29Epoch[2] Iteration[200/363] Loss: 0.24Epoch[2] Iteration[250/363] Loss: 0.24Epoch[2] Iteration[300/363] Loss: 0.45Epoch[2] Iteration[350/363] Loss: 0.27Epoch[3] Iteration[50/363] Loss: 0.15Epoch[3] Iteration[100/363] Loss: 0.12Epoch[3] Iteration[150/363] Loss: 0.25Epoch[3] Iteration[200/363] Loss: 0.23Epoch[3] Iteration[250/363] Loss: 0.24Epoch[3] Iteration[300/363] Loss: 0.35Epoch[3] Iteration[350/363] Loss: 0.27Epoch[4] Iteration[50/363] Loss: 0.11Epoch[4] Iteration[100/363] Loss: 0.12Epoch[4] Iteration[150/363] Loss: 0.20Epoch[4] Iteration[200/363] Loss: 0.26Epoch[4] Iteration[250/363] Loss: 0.23Epoch[4] Iteration[300/363] Loss: 0.28Epoch[4] Iteration[350/363] Loss: 0.18Epoch[5] Iteration[50/363] Loss: 0.10Epoch[5] Iteration[100/363] Loss: 0.07Epoch[5] Iteration[150/363] Loss: 0.23Epoch[5] Iteration[200/363] Loss: 0.19Epoch[5] Iteration[250/363] Loss: 0.18Epoch[5] Iteration[300/363] Loss: 0.23Epoch[5] Iteration[350/363] Loss: 0.16Epoch[6] Iteration[50/363] Loss: 0.11Epoch[6] Iteration[100/363] Loss: 0.12Epoch[6] Iteration[150/363] Loss: 0.21Epoch[6] Iteration[200/363] Loss: 0.19Epoch[6] Iteration[250/363] Loss: 0.18Epoch[6] Iteration[300/363] Loss: 0.10Epoch[6] Iteration[350/363] Loss: 0.16Epoch[7] Iteration[50/363] Loss: 0.13Epoch[7] Iteration[100/363] Loss: 0.12Epoch[7] Iteration[150/363] Loss: 0.22Epoch[7] Iteration[200/363] Loss: 0.15Epoch[7] Iteration[250/363] Loss: 0.15Epoch[7] Iteration[300/363] Loss: 0.16Epoch[7] Iteration[350/363] Loss: 0.14Epoch[8] Iteration[50/363] Loss: 0.04Epoch[8] Iteration[100/363] Loss: 0.07Epoch[8] Iteration[150/363] Loss: 0.17Epoch[8] Iteration[200/363] Loss: 0.09Epoch[8] Iteration[250/363] Loss: 0.18Epoch[8] Iteration[300/363] Loss: 0.50Epoch[8] Iteration[350/363] Loss: 0.17Epoch[9] Iteration[50/363] Loss: 0.03Epoch[9] Iteration[100/363] Loss: 0.12Epoch[9] Iteration[150/363] Loss: 0.17Epoch[9] Iteration[200/363] Loss: 0.15Epoch[9] Iteration[250/363] Loss: 0.15Epoch[9] Iteration[300/363] Loss: 0.12Epoch[9] Iteration[350/363] Loss: 0.23Epoch[10] Iteration[50/363] Loss: 0.13Epoch[10] Iteration[100/363] Loss: 0.03Epoch[10] Iteration[150/363] Loss: 0.17Epoch[10] Iteration[200/363] Loss: 0.20Epoch[10] Iteration[250/363] Loss: 0.18Epoch[10] Iteration[300/363] Loss: 0.13Epoch[10] Iteration[350/363] Loss: 0.11Epoch[11] Iteration[50/363] Loss: 0.10Epoch[11] Iteration[100/363] Loss: 0.07Epoch[11] Iteration[150/363] Loss: 0.14Epoch[11] Iteration[200/363] Loss: 0.05Epoch[11] Iteration[250/363] Loss: 0.17Epoch[11] Iteration[300/363] Loss: 0.09Epoch[11] Iteration[350/363] Loss: 0.12Epoch[12] Iteration[50/363] Loss: 0.01Epoch[12] Iteration[100/363] Loss: 0.16Epoch[12] Iteration[150/363] Loss: 0.16Epoch[12] Iteration[200/363] Loss: 0.08Epoch[12] Iteration[250/363] Loss: 0.15Epoch[12] Iteration[300/363] Loss: 0.14Epoch[12] Iteration[350/363] Loss: 0.10
======== wide_resnet101_2 ========

spatial feature len: 18432, temporal feature len: 500
Epoch[1] Iteration[50/363] Loss: 0.23Epoch[1] Iteration[100/363] Loss: 0.14Epoch[1] Iteration[150/363] Loss: 0.39Epoch[1] Iteration[200/363] Loss: 0.30Epoch[1] Iteration[250/363] Loss: 0.30Epoch[1] Iteration[300/363] Loss: 0.55Epoch[1] Iteration[350/363] Loss: 0.34Epoch[2] Iteration[50/363] Loss: 0.17Epoch[2] Iteration[100/363] Loss: 0.13Epoch[2] Iteration[150/363] Loss: 0.32Epoch[2] Iteration[200/363] Loss: 0.26Epoch[2] Iteration[250/363] Loss: 0.26Epoch[2] Iteration[300/363] Loss: 0.42Epoch[2] Iteration[350/363] Loss: 0.31Epoch[3] Iteration[50/363] Loss: 0.17Epoch[3] Iteration[100/363] Loss: 0.10Epoch[3] Iteration[150/363] Loss: 0.28Epoch[3] Iteration[200/363] Loss: 0.22Epoch[3] Iteration[250/363] Loss: 0.21Epoch[3] Iteration[300/363] Loss: 0.29Epoch[3] Iteration[350/363] Loss: 0.30Epoch[4] Iteration[50/363] Loss: 0.17Epoch[4] Iteration[100/363] Loss: 0.15Epoch[4] Iteration[150/363] Loss: 0.26Epoch[4] Iteration[200/363] Loss: 0.27Epoch[4] Iteration[250/363] Loss: 0.29Epoch[4] Iteration[300/363] Loss: 0.32Epoch[4] Iteration[350/363] Loss: 0.26Epoch[5] Iteration[50/363] Loss: 0.15Epoch[5] Iteration[100/363] Loss: 0.18Epoch[5] Iteration[150/363] Loss: 0.26Epoch[5] Iteration[200/363] Loss: 0.26Epoch[5] Iteration[250/363] Loss: 0.31Epoch[5] Iteration[300/363] Loss: 0.29Epoch[5] Iteration[350/363] Loss: 0.25Epoch[6] Iteration[50/363] Loss: 0.16Epoch[6] Iteration[100/363] Loss: 0.21Epoch[6] Iteration[150/363] Loss: 0.29Epoch[6] Iteration[200/363] Loss: 0.30Epoch[6] Iteration[250/363] Loss: 0.23Epoch[6] Iteration[300/363] Loss: 0.20Epoch[6] Iteration[350/363] Loss: 0.17Epoch[7] Iteration[50/363] Loss: 0.10Epoch[7] Iteration[100/363] Loss: 0.13Epoch[7] Iteration[150/363] Loss: 0.21Epoch[7] Iteration[200/363] Loss: 0.24Epoch[7] Iteration[250/363] Loss: 0.15Epoch[7] Iteration[300/363] Loss: 0.20Epoch[7] Iteration[350/363] Loss: 0.18Epoch[8] Iteration[50/363] Loss: 0.11Epoch[8] Iteration[100/363] Loss: 0.08Epoch[8] Iteration[150/363] Loss: 0.21Epoch[8] Iteration[200/363] Loss: 0.19Epoch[8] Iteration[250/363] Loss: 0.13Epoch[8] Iteration[300/363] Loss: 0.13Epoch[8] Iteration[350/363] Loss: 0.13Epoch[9] Iteration[50/363] Loss: 0.08Epoch[9] Iteration[100/363] Loss: 0.14Epoch[9] Iteration[150/363] Loss: 0.14Epoch[9] Iteration[200/363] Loss: 0.16Epoch[9] Iteration[250/363] Loss: 0.14Epoch[9] Iteration[300/363] Loss: 0.22Epoch[9] Iteration[350/363] Loss: 0.14Epoch[10] Iteration[50/363] Loss: 0.07Epoch[10] Iteration[100/363] Loss: 0.05Epoch[10] Iteration[150/363] Loss: 0.19Epoch[10] Iteration[200/363] Loss: 0.22Epoch[10] Iteration[250/363] Loss: 0.12Epoch[10] Iteration[300/363] Loss: 0.07Epoch[10] Iteration[350/363] Loss: 0.24Epoch[11] Iteration[50/363] Loss: 0.06Epoch[11] Iteration[100/363] Loss: 0.03Epoch[11] Iteration[150/363] Loss: 0.15Epoch[11] Iteration[200/363] Loss: 0.13Epoch[11] Iteration[250/363] Loss: 0.13