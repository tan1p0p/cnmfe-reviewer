{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No preprocessing on spatial data\n",
      "File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.\n",
      "No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.\n",
      "Successfully loaded data.\n",
      "Training and test data loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11603, 6900)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cnmfereview as cr\n",
    "import config as cfg\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "MODELDIR = Path('../best_models')\n",
    "\n",
    "data = cr.Dataset(\n",
    "    data_paths=cfg.data_paths,\n",
    "    exp_id=cfg.exp_id,\n",
    "    img_shape=cfg.img_shape,\n",
    "    img_crop_size=cfg.img_crop_size,\n",
    "    max_trace=cfg.max_trace_len,\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = data.split_training_test_data(\n",
    "    test_split=.20,\n",
    "    seed=10\n",
    ")\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "**NOTE: Remove the next cell when training your own models.** This step uses fewer ROIs (only ~3000 instead of 11 000) in the tutorial dataset to speed up computation in the tutorial. Do not do this when you are training your own data. You want to use as many data samples as possible to get the best results in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 11603\n",
      "Number of samples in test set: 2901\n"
     ]
    }
   ],
   "source": [
    "# remove or comment out this cell when using on your own data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.75)\n",
    "\n",
    "print(f\"Number of samples in training set: {x_train.shape[0]}\") \n",
    "print(f\"Number of samples in test set: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the saved models on your data\n",
    "### Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cupy' has no attribute 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-13d5f4928fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNNDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/nn/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msan_block\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_block\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/nn/san_block.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubtraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubtraction2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maggregation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msubtraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msubtraction2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/modules/aggregation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpad_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maggregation_zeropad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maggregation_refpad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msubtraction_zeropad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msubtraction_refpad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msubtraction2_zeropad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/functions/aggregation_zeropad.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/cnmfe-reviewer/notebooks/lib/sa/functions/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_each_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cupy' has no attribute 'util'"
     ]
    }
   ],
   "source": [
    "import ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import optuna\n",
    "\n",
    "from nn.model import Model\n",
    "from nn.train import train, NNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.spatial.shape, data.trace.shape, data.targets.shape\n",
    "x_train, x_test, y_train, y_test = data.split_training_test_data(\n",
    "    test_split=.20, seed=10, for_deep=True)\n",
    "\n",
    "device = 'cuda:0'\n",
    "trainsets = NNDataset(x_train, y_train, device)\n",
    "testsets = NNDataset(x_test, y_test, device)\n",
    "train_loader = torch.utils.data.DataLoader(trainsets, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(testsets, batch_size=32)\n",
    "model = Model(\n",
    "    s_stage='resnet18',\n",
    "    res_block_num=5,\n",
    "    t_hidden_dim=500,\n",
    "    t_output_dim=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, model = train(model, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), '../best_models/deep_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 is best\n",
    "scores = []\n",
    "for i in range(1, 6):\n",
    "    model = Model(\n",
    "        s_stage='ResNet',\n",
    "        res_block_num=i,\n",
    "    )\n",
    "    scores.append()\n",
    "for i in range(5):\n",
    "    print(i+1, scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimaze_san(trial):\n",
    "    block_num = trial.suggest_int('block_num', 1, 5)\n",
    "    layer_size_hop = trial.suggest_int('layer_size_hop', 2, 5)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 7, 2)\n",
    "\n",
    "    layers = [3]\n",
    "    kernels = [3]\n",
    "    for i in range(1, block_num):\n",
    "        layers.append(2 + i*layer_size_hop)\n",
    "        kernels.append(kernel_size)\n",
    "    \n",
    "    model = Model(\n",
    "        s_stage='SAN',\n",
    "        san_layers=layers,\n",
    "        san_kernels=kernels,\n",
    "    )\n",
    "    score = train(model.to(device))\n",
    "    return -score\n",
    "study = optuna.create_study()\n",
    "study.optimize(optimaze_san, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimaze_lstm(trial):\n",
    "    model = Model(\n",
    "        s_stage='ResNet',\n",
    "        res_block_num=4,\n",
    "        t_hidden_dim=trial.suggest_int('t_hidden_dim', 50, 500, 50),\n",
    "        t_output_dim=trial.suggest_int('t_output_dim', 50, 500, 50),\n",
    "    )\n",
    "    score = train(model.to(device))\n",
    "    return -score\n",
    "study = optuna.create_study()\n",
    "study.optimize(optimaze_lstm, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def print_score(results):\n",
    "    print('Acc, F1, P, R: ', end='')\n",
    "    print(f'{accuracy_score(y_test, results):.3f} & ', end='')\n",
    "    print(f'{f1_score(y_test, results):.3f} & ', end='')\n",
    "    print(f'{precision_score(y_test, results):.3f} & ', end='')\n",
    "    print(f'{recall_score(y_test, results):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831 & 0.866 & 0.871 & 0.861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(x_train, y_train)\n",
    "results_tree = tree_model.predict(x_test)\n",
    "print_score(recall_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844 & 0.882 & 0.843 & 0.926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "K_model = KNeighborsClassifier()\n",
    "K_model.fit(x_train, y_train)\n",
    "results_K = K_model.predict(x_test)\n",
    "print_score(results_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# this was the final TPOT exported pipeline that acheived the highest F1 score\n",
    "# tpot_model = LinearSVC(C=0.1, dual=False, loss=\"squared_hinge\", penalty=\"l1\", tol=0.1)\n",
    "# tpot_model.fit(x_train, y_train)\n",
    "# dump(tpot_model, MODELDIR / f'{cfg.exp_id}_tpot.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8783178214408824\n",
      "f1: 0.9102009666751462\n",
      "P, R: 0.853530534351145 0.9749318801089918\n"
     ]
    }
   ],
   "source": [
    "tpot_model = load(MODELDIR / f'{cfg.exp_id}_tpot.joblib')\n",
    "results_tpot = tpot_model.predict(x_test)\n",
    "print_score(results_tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the model finetuned on your data to use again in the future to predict without having to retrain.\n",
    "### AutoSklearn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn\n",
    "\n",
    "# load the AutoSklearn ensemble object\n",
    "# askl.refit(x_train, y_train)\n",
    "# dump(askl, MODELDIR / f'{cfg.exp_id}_askl.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator VarianceThreshold from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator ExtraTreeClassifier from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator ExtraTreesClassifier from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SelectFromModel from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RobustScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator Normalizer from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SelectPercentile from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hassaku/.pyenv/versions/miniconda3-latest/envs/cnmfe_reviewer/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator QuantileTransformer from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8772836952774905\n",
      "f1: 0.9074844074844074\n",
      "P, R: 0.8673621460506706 0.9514986376021798\n"
     ]
    }
   ],
   "source": [
    "askl = load(MODELDIR / f'{cfg.exp_id}_askl.joblib')\n",
    "results_automl = askl.predict(x_test)\n",
    "print_score(results_automl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply classifiers to unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "askl = load(MODELDIR / f'{cfg.exp_id}_askl.joblib');\n",
    "tpot_model = load(MODELDIR / f'{cfg.exp_id}_tpot.joblib')\n",
    "cfg.img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = cr.UnlabeledDataset(\n",
    "    mat_file='../data/unlabeled_rois_DM298.mat',\n",
    "    img_shape={'x': 284, 'y': 231},\n",
    "    img_crop_size=cfg.img_crop_size,\n",
    "    max_trace=cfg.max_trace_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.img_shape, cfg.img_crop_size, cfg.max_trace_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_askl = askl.predict(unseen_data.combined)\n",
    "pred_tpot = tpot_model.predict(unseen_data.combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by askl as \"positives\"\n",
    "positive_askl = np.where(pred_askl==1)[0]\n",
    "# limit to only show 10 at once, you can play around with this of course\n",
    "cr.plot_rois(unseen_data, positive_askl[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by askl as \"negatives\"\n",
    "negative_askl = np.where(pred_askl==0)[0]\n",
    "# limit to only show 10 at once, you can play around with this of course\n",
    "cr.plot_rois(unseen_data, negative_askl[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label = [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "accuracy_score(gt_label, pred_askl), f1_score(gt_label, pred_askl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by TPOT as \"negatives\"\n",
    "cr.plot_rois(unseen_data, np.where(pred_tpot==0)[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data.apply_labels(pred_askl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file to check the results\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "labeled_data = loadmat('../data/unlabeled_rois_automl.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnmfe-reviewer",
   "language": "python",
   "name": "cnmfe-reviewer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
