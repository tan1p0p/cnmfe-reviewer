{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No preprocessing on spatial data\n",
      "File ../data/cr_tutorialA_cropped.npy already exists and has been loaded instead.\n",
      "No preprocessing on trace data.                   ../data/cr_tutorialCraw_normalized.npy already                   exists and has been loaded instead.\n",
      "Successfully loaded data.\n",
      "Training and test data loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11603, 6900)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cnmfereview as cr\n",
    "import config as cfg\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "MODELDIR = Path('../best_models')\n",
    "\n",
    "data = cr.Dataset(\n",
    "    data_paths=cfg.data_paths,\n",
    "    exp_id=cfg.exp_id,\n",
    "    img_shape=cfg.img_shape,\n",
    "    img_crop_size=cfg.img_crop_size,\n",
    "    max_trace=cfg.max_trace_len,\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = data.split_training_test_data(\n",
    "    test_split=.20,\n",
    "    seed=10\n",
    ")\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "**NOTE: Remove the next cell when training your own models.** This step uses fewer ROIs (only ~3000 instead of 11 000) in the tutorial dataset to speed up computation in the tutorial. Do not do this when you are training your own data. You want to use as many data samples as possible to get the best results in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 11603\n",
      "Number of samples in test set: 2901\n"
     ]
    }
   ],
   "source": [
    "# remove or comment out this cell when using on your own data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.75)\n",
    "\n",
    "print(f\"Number of samples in training set: {x_train.shape[0]}\") \n",
    "print(f\"Number of samples in test set: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the saved models on your data\n",
    "### Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from nn.model import Model\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data loaded\n"
     ]
    }
   ],
   "source": [
    "data.spatial.shape, data.trace.shape, data.targets.shape\n",
    "x_train, x_test, y_train, y_test = data.split_training_test_data(\n",
    "    test_split=.20, seed=10, for_deep=True)\n",
    "\n",
    "class datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, device):\n",
    "        self.x, self.y = x, y\n",
    "        self.device = device\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        data = (self.x[0][i].to(self.device), self.x[1][i].to(self.device))\n",
    "        return data, self.y[i].to(self.device)\n",
    "\n",
    "device = 'cuda:0'\n",
    "trainsets = datasets(x_train, y_train, device)\n",
    "testsets = datasets(x_test, y_test, device)\n",
    "train_loader = torch.utils.data.DataLoader(trainsets, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(testsets, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = F.binary_cross_entropy\n",
    "    epochs = 30\n",
    "\n",
    "    def preprocess(y):\n",
    "        return torch.round(y[0]), y[1]\n",
    "\n",
    "    precision = ignite.metrics.Precision(preprocess, average=False)\n",
    "    recall = ignite.metrics.Recall(preprocess, average=False)\n",
    "    F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    evaluator = create_supervised_evaluator(\n",
    "        model,\n",
    "        metrics={'accuracy': ignite.metrics.Accuracy(preprocess),\n",
    "                 'f1': F1,\n",
    "                 'cross_entropy': ignite.metrics.Loss(criterion)},\n",
    "        device=device)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        i = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch[{engine.state.epoch}] Iteration[{i}/{len(train_loader)}] \"\n",
    "                  f\"Loss: {engine.state.output:.2f}\")\n",
    "            writer.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)\n",
    "\n",
    "    def write_metrics(metrics, writer, mode: str, epoch: int):\n",
    "        \"\"\"print metrics & write metrics to log\"\"\"\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['cross_entropy']\n",
    "        avg_f1 = metrics['f1']\n",
    "        print(f\"{mode} Results - Epoch: {epoch}  \"\n",
    "              f\"Avg accuracy: {avg_accuracy:.2f} Avg loss: {avg_nll:.2f} \"\n",
    "              f\"Avg F1: {avg_f1:.2f}\")\n",
    "        writer.add_scalar(f\"{mode}/avg_loss\", avg_nll, epoch)\n",
    "        writer.add_scalar(f\"{mode}/avg_accuracy\", avg_accuracy, epoch)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        write_metrics(metrics, writer, 'training', engine.state.epoch)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(test_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        write_metrics(metrics, writer, 'validation', engine.state.epoch)\n",
    "\n",
    "    handler = ModelCheckpoint(dirname='./checkpoints', filename_prefix='sample',\n",
    "                              n_saved=5, create_dir=True, require_empty=False)\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED, handler, {'mymodel': model})\n",
    "\n",
    "    handler = EarlyStopping(\n",
    "        patience=5,\n",
    "        score_function=lambda x: x.state.metrics['f1'],\n",
    "        trainer=trainer)\n",
    "    evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    return handler.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9178238411484538\n",
      "2 0.9309892416688533\n",
      "3 0.9255801547079221\n",
      "4 0.9201073087744553\n",
      "5 0.9367221276038256\n"
     ]
    }
   ],
   "source": [
    "# 5 is best\n",
    "# scores = []\n",
    "# for i in range(1, 6):\n",
    "#     model = Model(\n",
    "#         s_stage='ResNet',\n",
    "#         res_block_num=i,\n",
    "#     )\n",
    "#     scores.append(train(model.to(device)))\n",
    "for i in range(5):\n",
    "    print(i+1, scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-29 01:23:31,403] A new study created in memory with name: no-name-91a4e327-ac95-47f0-beca-c62960800e7e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial feature len: 12800, temporal feature len: 300\n",
      "training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.31 Avg F1: 0.90\n",
      "validation Results - Epoch: 1  Avg accuracy: 0.87 Avg loss: 0.30 Avg F1: 0.89\n",
      "training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.91\n",
      "validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92\n",
      "training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92\n",
      "training Results - Epoch: 4  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 4  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92\n",
      "validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "training Results - Epoch: 7  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92\n",
      "validation Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "training Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 9  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.92\n",
      "validation Results - Epoch: 10  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "training Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93\n",
      "validation Results - Epoch: 11  Avg accuracy: 0.90 Avg loss: 0.25 Avg F1: 0.92\n",
      "training Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.24 Avg F1: 0.93\n",
      "validation Results - Epoch: 12  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93\n",
      "validation Results - Epoch: 13  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 14  Avg accuracy: 0.91 Avg loss: 0.23 Avg F1: 0.93\n",
      "validation Results - Epoch: 14  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 15  Avg accuracy: 0.90 Avg loss: 0.23 Avg F1: 0.93\n",
      "validation Results - Epoch: 15  Avg accuracy: 0.90 Avg loss: 0.26 Avg F1: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-29 01:42:44,537] Trial 0 finished with value: -0.9284347998153156 and parameters: {'block_num': 3, 'layer_size_hop': 5, 'kernel_size': 3}. Best is trial 0 with value: -0.9284347998153156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial feature len: 51200, temporal feature len: 300\n",
      "training Results - Epoch: 1  Avg accuracy: 0.83 Avg loss: 0.41 Avg F1: 0.88\n",
      "validation Results - Epoch: 1  Avg accuracy: 0.84 Avg loss: 0.39 Avg F1: 0.89\n",
      "training Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.35 Avg F1: 0.91\n",
      "validation Results - Epoch: 2  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.91\n",
      "training Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.91\n",
      "validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.30 Avg F1: 0.91\n",
      "training Results - Epoch: 4  Avg accuracy: 0.86 Avg loss: 0.36 Avg F1: 0.90\n",
      "validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.34 Avg F1: 0.91\n",
      "training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.91\n",
      "validation Results - Epoch: 5  Avg accuracy: 0.88 Avg loss: 0.34 Avg F1: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-29 01:44:15,296] Trial 1 finished with value: -0.914625288874216 and parameters: {'block_num': 1, 'layer_size_hop': 5, 'kernel_size': 3}. Best is trial 0 with value: -0.9284347998153156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial feature len: 6400, temporal feature len: 300\n",
      "training Results - Epoch: 1  Avg accuracy: 0.88 Avg loss: 0.30 Avg F1: 0.91\n",
      "validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 0.31 Avg F1: 0.91\n",
      "training Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.91\n",
      "validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92\n",
      "training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91\n",
      "validation Results - Epoch: 3  Avg accuracy: 0.89 Avg loss: 0.28 Avg F1: 0.92\n",
      "training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91\n",
      "validation Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.27 Avg F1: 0.91\n",
      "training Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "validation Results - Epoch: 5  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.91\n",
      "validation Results - Epoch: 6  Avg accuracy: 0.89 Avg loss: 0.27 Avg F1: 0.92\n",
      "training Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 7  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "validation Results - Epoch: 8  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 9  Avg accuracy: 0.89 Avg loss: 0.26 Avg F1: 0.92\n",
      "training Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n",
      "validation Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.25 Avg F1: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-29 02:06:55,306] Trial 2 finished with value: -0.9212089899250839 and parameters: {'block_num': 4, 'layer_size_hop': 5, 'kernel_size': 7}. Best is trial 0 with value: -0.9284347998153156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial feature len: 6400, temporal feature len: 300\n"
     ]
    }
   ],
   "source": [
    "def optimaze_san(trial):\n",
    "    block_num = trial.suggest_int('block_num', 1, 5)\n",
    "    layer_size_hop = trial.suggest_int('layer_size_hop', 2, 5)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 7, 2)\n",
    "\n",
    "    layers = [3]\n",
    "    kernels = [3]\n",
    "    for i in range(1, block_num):\n",
    "        layers.append(2 + i*layer_size_hop)\n",
    "        kernels.append(kernel_size)\n",
    "    \n",
    "    model = Model(\n",
    "        s_stage='SAN',\n",
    "        san_layers=layers,\n",
    "        san_kernels=kernels,\n",
    "    )\n",
    "    score = train(model.to(device))\n",
    "    return -score\n",
    "study = optuna.create_study()\n",
    "study.optimize(optimaze_san, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimaze_lstm(trial):\n",
    "    model = Model(\n",
    "        s_stage='ResNet',\n",
    "        res_block_num=4,\n",
    "        t_hidden_dim=trial.suggest_int('t_hidden_dim', 50, 500, 50),\n",
    "        t_output_dim=trial.suggest_int('t_output_dim', 50, 500, 50),\n",
    "    )\n",
    "    score = train(model.to(device))\n",
    "    return -score\n",
    "study = optuna.create_study()\n",
    "study.optimize(optimaze_lstm, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# this was the final TPOT exported pipeline that acheived the highest F1 score\n",
    "tpot_model = LinearSVC(C=0.1, dual=False, loss=\"squared_hinge\", penalty=\"l1\", tol=0.1)\n",
    "tpot_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_y_pred = tpot_model.predict(x_train)\n",
    "print(\"Accuracy:\", accuracy_score(y_train, tpot_y_pred))\n",
    "print(\"f1:\", f1_score(y_train, tpot_y_pred))\n",
    "dump(tpot_model, MODELDIR / f'{cfg.exp_id}_tpot.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the model finetuned on your data to use again in the future to predict without having to retrain.\n",
    "### AutoSklearn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import autosklearn\n",
    "import sklearn\n",
    "# load the AutoSklearn ensemble object\n",
    "askl = load(MODELDIR / 'cr_tutorial_askl.joblib')\n",
    "askl.refit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_automl = askl.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, results_automl))\n",
    "print(\"f1:\", f1_score(y_test, results_automl))\n",
    "dump(askl, MODELDIR / f'{cfg.exp_id}_askl.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply classifiers to unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "askl = load(MODELDIR / f'{cfg.exp_id}_askl.joblib');\n",
    "tpot_model = load(MODELDIR / f'{cfg.exp_id}_tpot.joblib')\n",
    "cfg.img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = cr.UnlabeledDataset(\n",
    "    mat_file='../data/unlabeled_rois_DM298.mat',\n",
    "    img_shape={'x': 284, 'y': 231},\n",
    "    img_crop_size=cfg.img_crop_size,\n",
    "    max_trace=cfg.max_trace_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.img_shape, cfg.img_crop_size, cfg.max_trace_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_askl = askl.predict(unseen_data.combined)\n",
    "pred_tpot = tpot_model.predict(unseen_data.combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by askl as \"positives\"\n",
    "positive_askl = np.where(pred_askl==1)[0]\n",
    "# limit to only show 10 at once, you can play around with this of course\n",
    "cr.plot_rois(unseen_data, positive_askl[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by askl as \"negatives\"\n",
    "negative_askl = np.where(pred_askl==0)[0]\n",
    "# limit to only show 10 at once, you can play around with this of course\n",
    "cr.plot_rois(unseen_data, negative_askl[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label = [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "accuracy_score(gt_label, pred_askl), f1_score(gt_label, pred_askl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ROIs labeled by TPOT as \"negatives\"\n",
    "cr.plot_rois(unseen_data, np.where(pred_tpot==0)[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data.apply_labels(pred_askl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file to check the results\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "labeled_data = loadmat('../data/unlabeled_rois_automl.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
